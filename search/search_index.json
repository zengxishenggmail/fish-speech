{"config":{"lang":["en","zh","ja","pt","ko"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"README.ja/","title":"README.ja","text":"Fish Speech  [English](../README.md) | [\u7b80\u4f53\u4e2d\u6587](README.zh.md) | [Portuguese](README.pt-BR.md) | **\u65e5\u672c\u8a9e** | [\ud55c\uad6d\uc5b4](README.ko.md) <p>\u3053\u306e\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u3068\u3059\u3079\u3066\u306e\u30e2\u30c7\u30eb\u306f\u3001CC-BY-NC-SA-4.0 \u30e9\u30a4\u30bb\u30f3\u30b9\u306e\u4e0b\u3067\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001LICENSE\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"README.ja/#_1","title":"\u6a5f\u80fd","text":"<ol> <li>\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8 &amp; \u30d5\u30e5\u30fc\u30b7\u30e7\u30c3\u30c8 TTS\uff1a10\u301c30 \u79d2\u306e\u97f3\u58f0\u30b5\u30f3\u30d7\u30eb\u3092\u5165\u529b\u3057\u3066\u3001\u9ad8\u54c1\u8cea\u306e TTS \u51fa\u529b\u3092\u751f\u6210\u3057\u307e\u3059\u3002\u8a73\u7d30\u306f \u97f3\u58f0\u30af\u30ed\u30fc\u30f3\u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</li> <li>\u591a\u8a00\u8a9e &amp; \u30af\u30ed\u30b9\u30ea\u30f3\u30ac\u30eb\u5bfe\u5fdc\uff1a\u591a\u8a00\u8a9e\u30c6\u30ad\u30b9\u30c8\u3092\u5165\u529b\u30dc\u30c3\u30af\u30b9\u306b\u30b3\u30d4\u30fc\u30da\u30fc\u30b9\u30c8\u3059\u308b\u3060\u3051\u3067\u3001\u8a00\u8a9e\u3092\u6c17\u306b\u3059\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u73fe\u5728\u3001\u82f1\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u97d3\u56fd\u8a9e\u3001\u4e2d\u56fd\u8a9e\u3001\u30d5\u30e9\u30f3\u30b9\u8a9e\u3001\u30c9\u30a4\u30c4\u8a9e\u3001\u30a2\u30e9\u30d3\u30a2\u8a9e\u3001\u30b9\u30da\u30a4\u30f3\u8a9e\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002</li> <li>\u97f3\u7d20\u4f9d\u5b58\u306a\u3057\uff1a\u3053\u306e\u30e2\u30c7\u30eb\u306f\u5f37\u529b\u306a\u6c4e\u5316\u80fd\u529b\u3092\u6301\u3061\u3001TTS \u306b\u97f3\u7d20\u3092\u5fc5\u8981\u3068\u3057\u307e\u305b\u3093\u3002\u3042\u3089\u3086\u308b\u8a00\u8a9e\u30b9\u30af\u30ea\u30d7\u30c8\u306b\u5bfe\u5fdc\u53ef\u80fd\u3067\u3059\u3002</li> <li>\u9ad8\u7cbe\u5ea6\uff1a5 \u5206\u9593\u306e\u82f1\u8a9e\u30c6\u30ad\u30b9\u30c8\u306b\u5bfe\u3057\u3001CER\uff08\u6587\u5b57\u8aa4\u308a\u7387\uff09\u3068 WER\uff08\u5358\u8a9e\u8aa4\u308a\u7387\uff09\u306f\u7d04 2%\u306e\u7cbe\u5ea6\u3092\u9054\u6210\u3057\u307e\u3059\u3002</li> <li>\u9ad8\u901f\uff1afish-tech \u30a2\u30af\u30bb\u30e9\u30ec\u30fc\u30b7\u30e7\u30f3\u306b\u3088\u308a\u3001Nvidia RTX 4060 \u30e9\u30c3\u30d7\u30c8\u30c3\u30d7\u3067\u306f\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u30d5\u30a1\u30af\u30bf\u30fc\u304c\u7d04 1:5\u3001Nvidia RTX 4090 \u3067\u306f\u7d04 1:15 \u3067\u3059\u3002</li> <li>WebUI \u63a8\u8ad6\uff1a\u4f7f\u3044\u3084\u3059\u3044 Gradio \u30d9\u30fc\u30b9\u306e Web \u30e6\u30fc\u30b6\u30fc\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u642d\u8f09\u3057\u3001Chrome\u3001Firefox\u3001Edge \u306a\u3069\u306e\u30d6\u30e9\u30a6\u30b6\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002</li> <li>GUI \u63a8\u8ad6\uff1aPyQt6 \u306e\u30b0\u30e9\u30d5\u30a3\u30ab\u30eb\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u63d0\u4f9b\u3057\u3001API \u30b5\u30fc\u30d0\u30fc\u3068\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u9023\u643a\u3057\u307e\u3059\u3002Linux\u3001Windows\u3001macOS \u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002GUI \u3092\u898b\u308b\u3002</li> <li>\u30c7\u30d7\u30ed\u30a4\u3057\u3084\u3059\u3044\uff1aLinux\u3001Windows\u3001macOS \u306b\u30cd\u30a4\u30c6\u30a3\u30d6\u5bfe\u5fdc\u3057\u305f\u63a8\u8ad6\u30b5\u30fc\u30d0\u30fc\u3092\u7c21\u5358\u306b\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3067\u304d\u3001\u901f\u5ea6\u306e\u4f4e\u4e0b\u3092\u6700\u5c0f\u9650\u306b\u6291\u3048\u307e\u3059\u3002</li> </ol>"},{"location":"README.ja/#_2","title":"\u514d\u8cac\u4e8b\u9805","text":"<p>\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u306e\u9055\u6cd5\u306a\u4f7f\u7528\u306b\u3064\u3044\u3066\u306f\u4e00\u5207\u8cac\u4efb\u3092\u8ca0\u3044\u307e\u305b\u3093\u3002DMCA\uff08\u30c7\u30b8\u30bf\u30eb\u30df\u30ec\u30cb\u30a2\u30e0\u8457\u4f5c\u6a29\u6cd5\uff09\u304a\u3088\u3073\u305d\u306e\u4ed6\u306e\u95a2\u9023\u6cd5\u306b\u3064\u3044\u3066\u306f\u3001\u5730\u57df\u306e\u6cd5\u5f8b\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"README.ja/#_3","title":"\u30aa\u30f3\u30e9\u30a4\u30f3\u30c7\u30e2","text":"<p>Fish Audio</p>"},{"location":"README.ja/#_4","title":"\u30ed\u30fc\u30ab\u30eb\u63a8\u8ad6\u306e\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8","text":"<p>inference.ipynb</p>"},{"location":"README.ja/#_5","title":"\u30d3\u30c7\u30aa","text":""},{"location":"README.ja/#v14-httpswwwbilibilicomvideobv1pu46evek7","title":"V1.4 \u30c7\u30e2\u30d3\u30c7\u30aa: https://www.bilibili.com/video/BV1pu46eVEk7","text":""},{"location":"README.ja/#v12-httpswwwbilibilicomvideobv1wz421b71d","title":"V1.2 \u30c7\u30e2\u30d3\u30c7\u30aa: https://www.bilibili.com/video/BV1wz421B71D","text":""},{"location":"README.ja/#v11-httpswwwbilibilicomvideobv1zj4m1k7cj","title":"V1.1 \u30c7\u30e2\u30d3\u30c7\u30aa: https://www.bilibili.com/video/BV1zJ4m1K7cj","text":""},{"location":"README.ja/#_6","title":"\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>\u82f1\u8a9e</li> <li>\u4e2d\u6587</li> <li>\u65e5\u672c\u8a9e</li> <li>\u30dd\u30eb\u30c8\u30ac\u30eb\u8a9e (\u30d6\u30e9\u30b8\u30eb)</li> </ul>"},{"location":"README.ja/#20241002-v14","title":"\u30b5\u30f3\u30d7\u30eb (2024/10/02 V1.4)","text":"<ul> <li>\u82f1\u8a9e</li> <li>\u4e2d\u6587</li> <li>\u65e5\u672c\u8a9e</li> <li>\u30dd\u30eb\u30c8\u30ac\u30eb\u8a9e (\u30d6\u30e9\u30b8\u30eb)</li> </ul>"},{"location":"README.ja/#_7","title":"\u30af\u30ec\u30b8\u30c3\u30c8","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>GPT-SoVITS</li> </ul>"},{"location":"README.ja/#_8","title":"\u30b9\u30dd\u30f3\u30b5\u30fc","text":"\u30c7\u30fc\u30bf\u51e6\u7406\u30b9\u30dd\u30f3\u30b5\u30fc\uff1a6Block Fish Audio\u306fLepton.AI\u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u307e\u3059"},{"location":"README.ko/","title":"README.ko","text":"Fish Speech  [English](../README.md) | [\u7b80\u4f53\u4e2d\u6587](README.zh.md) | [Portuguese](README.pt-BR.md) | [\u65e5\u672c\u8a9e](README.ja.md) | **\ud55c\uad6d\uc5b4**  <p>\uc774 \ucf54\ub4dc\ubca0\uc774\uc2a4\uc640 \ubaa8\ub4e0 \ubaa8\ub378\uc740 CC-BY-NC-SA-4.0 \ub77c\uc774\uc120\uc2a4\uc5d0 \ub530\ub77c \ubc30\ud3ec\ub429\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 LICENSE\ub97c \ucc38\uc870\ud558\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.</p>"},{"location":"README.ko/#_1","title":"\uae30\ub2a5","text":"<ol> <li> <p>Zero-shot &amp; Few-shot TTS: 10\ucd08\uc5d0\uc11c 30\ucd08\uc758 \uc74c\uc131 \uc0d8\ud50c\uc744 \uc785\ub825\ud558\uc5ec \uace0\ud488\uc9c8\uc758 TTS \ucd9c\ub825\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc790\uc138\ud55c \uac00\uc774\ub4dc\ub294 \ubaa8\ubc94 \uc0ac\ub840\ub97c \ucc38\uc870\ud558\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.</p> </li> <li> <p>\ub2e4\uad6d\uc5b4 \ubc0f \uad50\ucc28 \uc5b8\uc5b4 \uc9c0\uc6d0: \ub2e4\uad6d\uc5b4 \uac71\uc815 \uc5c6\uc774, \ud14d\uc2a4\ud2b8\ub97c \uc785\ub825\ucc3d\uc5d0 \ubcf5\uc0ac\ud558\uc5ec \ubd99\uc5ec\ub123\uae30\ub9cc \ud558\uba74 \ub429\ub2c8\ub2e4. \ud604\uc7ac \uc601\uc5b4, \uc77c\ubcf8\uc5b4, \ud55c\uad6d\uc5b4, \uc911\uad6d\uc5b4, \ud504\ub791\uc2a4\uc5b4, \ub3c5\uc77c\uc5b4, \uc544\ub78d\uc5b4, \uc2a4\ud398\uc778\uc5b4\ub97c \uc9c0\uc6d0\ud569\ub2c8\ub2e4.</p> </li> <li> <p>\uc74c\uc18c \uc758\uc874\uc131 \uc81c\uac70: \uc774 \ubaa8\ub378\uc740 \uac15\ub825\ud55c \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \uac00\uc9c0\uace0 \uc788\uc73c\uba70, TTS\uac00 \uc74c\uc18c\uc5d0 \uc758\uc874\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \ubaa8\ub4e0 \uc5b8\uc5b4 \uc2a4\ud06c\ub9bd\ud2b8 \ud14d\uc2a4\ud2b8\ub97c \uc190\uc27d\uac8c \ucc98\ub9ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> </li> <li> <p>\ub192\uc740 \uc815\ud655\ub3c4: \uc601\uc5b4 \ud14d\uc2a4\ud2b8 \uae30\uc900 5\ubd84 \uae30\uc900\uc5d0\uc11c \ub2e8, 2%\uc758 \ubb38\uc790 \uc624\ub958\uc728(CER)\uacfc \ub2e8\uc5b4 \uc624\ub958\uc728(WER)\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.</p> </li> <li> <p>\ube60\ub978 \uc18d\ub3c4: fish-tech \uac00\uc18d\uc744 \ud1b5\ud574 \uc2e4\uc2dc\uac04 \uc778\uc790(RTF)\ub294 Nvidia RTX 4060 \ub178\ud2b8\ubd81\uc5d0\uc11c\ub294 \uc57d 1:5, Nvidia RTX 4090\uc5d0\uc11c\ub294 1:15\uc785\ub2c8\ub2e4.</p> </li> <li> <p>\uc6f9 UI \ucd94\ub860: Chrome, Firefox, Edge \ub4f1 \ub2e4\uc591\ud55c \ube0c\ub77c\uc6b0\uc800\uc5d0\uc11c \ud638\ud658\ub418\ub294 Gradio \uae30\ubc18\uc758 \uc0ac\uc6a9\ud558\uae30 \uc26c\uc6b4 \uc6f9 UI\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.</p> </li> <li> <p>GUI \ucd94\ub860: PyQt6 \uadf8\ub798\ud53d \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc81c\uacf5\ud558\uc5ec API \uc11c\ubc84\uc640 \uc6d0\ud65c\ud558\uac8c \uc791\ub3d9\ud569\ub2c8\ub2e4. Linux, Windows \ubc0f macOS\ub97c \uc9c0\uc6d0\ud569\ub2c8\ub2e4. GUI \ucc38\uc870.</p> </li> <li> <p>\ubc30\ud3ec \uce5c\ud654\uc801: Linux, Windows, macOS\uc5d0\uc11c \ub124\uc774\ud2f0\ube0c\ub85c \uc9c0\uc6d0\ub418\ub294 \ucd94\ub860 \uc11c\ubc84\ub97c \uc27d\uac8c \uc124\uc815\ud560 \uc218 \uc788\uc5b4 \uc18d\ub3c4 \uc190\uc2e4\uc744 \ucd5c\uc18c\ud654\ud569\ub2c8\ub2e4.</p> </li> </ol>"},{"location":"README.ko/#_2","title":"\uba74\ucc45 \uc870\ud56d","text":"<p>\uc774 \ucf54\ub4dc\ubca0\uc774\uc2a4\uc758 \ubd88\ubc95\uc801 \uc0ac\uc6a9\uc5d0 \ub300\ud574 \uc5b4\ub5a0\ud55c \ucc45\uc784\ub3c4 \uc9c0\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. DMCA \ubc0f \uad00\ub828 \ubc95\ub960\uc5d0 \ub300\ud55c \ub85c\uceec \ubc95\ub960\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.</p>"},{"location":"README.ko/#_3","title":"\uc628\ub77c\uc778 \ub370\ubaa8","text":"<p>Fish Audio</p>"},{"location":"README.ko/#_4","title":"\ub85c\uceec \ucd94\ub860\uc744 \uc704\ud55c \ube60\ub978 \uc2dc\uc791","text":"<p>inference.ipynb</p>"},{"location":"README.ko/#_5","title":"\uc601\uc0c1","text":""},{"location":"README.ko/#v14-youtube","title":"V1.4 \ub370\ubaa8 \uc601\uc0c1: Youtube","text":""},{"location":"README.ko/#_6","title":"\ubb38\uc11c","text":"<ul> <li>English</li> <li>\u4e2d\u6587</li> <li>\u65e5\u672c\u8a9e</li> <li>Portuguese (Brazil)</li> <li>\ud55c\uad6d\uc5b4</li> </ul>"},{"location":"README.ko/#samples-20241002-v14","title":"Samples (2024/10/02 V1.4)","text":"<ul> <li>English</li> <li>\u4e2d\u6587</li> <li>\u65e5\u672c\u8a9e</li> <li>Portuguese (Brazil)</li> <li>\ud55c\uad6d\uc5b4</li> </ul>"},{"location":"README.ko/#credits","title":"Credits","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>GPT-SoVITS</li> </ul>"},{"location":"README.ko/#sponsor","title":"Sponsor","text":"\ub370\uc774\ud130 \ucc98\ub9ac \ud6c4\uc6d0: 6Block Fish Audio\ub294 Lepton.AI\uc5d0\uc11c \uc81c\uacf5\ub429\ub2c8\ub2e4"},{"location":"README.pt-BR/","title":"README.pt BR","text":"Fish Speech  [English](../README.md) | [\u7b80\u4f53\u4e2d\u6587](README.zh.md) | **Portuguese** | [\u65e5\u672c\u8a9e](README.ja.md) | [\ud55c\uad6d\uc5b4](README.ko.md) <p>Este c\u00f3digo-fonte e os modelos s\u00e3o publicados sob a licen\u00e7a CC-BY-NC-SA-4.0. Consulte LICENSE para mais detalhes.</p>"},{"location":"README.pt-BR/#funcionalidades","title":"Funcionalidades","text":"<ol> <li> <p>TTS Zero-shot &amp; Few-shot: Insira uma amostra vocal de 10 a 30 segundos para gerar sa\u00edda de TTS de alta qualidade. Para diretrizes detalhadas, veja Melhores Pr\u00e1ticas para Clonagem de Voz.</p> </li> <li> <p>Suporte Multil\u00edngue e Interlingual: Basta copiar e colar o texto multil\u00edngue na caixa de entrada\u2014n\u00e3o se preocupe com o idioma. Atualmente suporta ingl\u00eas, japon\u00eas, coreano, chin\u00eas, franc\u00eas, alem\u00e3o, \u00e1rabe e espanhol.</p> </li> <li> <p>Sem Depend\u00eancia de Fonemas: O modelo tem forte capacidade de generaliza\u00e7\u00e3o e n\u00e3o depende de fonemas para TTS. Ele pode lidar com textos em qualquer script de idioma.</p> </li> <li> <p>Alta Precis\u00e3o: Alcan\u00e7a uma CER (Taxa de Erro de Caracteres) e WER (Taxa de Erro de Palavras) de cerca de 2% para textos de 5 minutos em ingl\u00eas.</p> </li> <li> <p>R\u00e1pido: Com a acelera\u00e7\u00e3o fish-tech, o fator de tempo real \u00e9 de aproximadamente 1:5 em um laptop Nvidia RTX 4060 e 1:15 em uma Nvidia RTX 4090.</p> </li> <li> <p>Infer\u00eancia WebUI: Apresenta uma interface de usu\u00e1rio web baseada em Gradio, f\u00e1cil de usar e compat\u00edvel com navegadores como Chrome, Firefox e Edge.</p> </li> <li> <p>Infer\u00eancia GUI: Oferece uma interface gr\u00e1fica PyQt6 que funciona perfeitamente com o servidor API. Suporta Linux, Windows e macOS. Veja o GUI.</p> </li> <li> <p>F\u00e1cil de Implantar: Configura facilmente um servidor de infer\u00eancia com suporte nativo para Linux, Windows e macOS, minimizando a perda de velocidade.</p> </li> </ol>"},{"location":"README.pt-BR/#isencao-de-responsabilidade","title":"Isen\u00e7\u00e3o de Responsabilidade","text":"<p>N\u00e3o nos responsabilizamos por qualquer uso ilegal do c\u00f3digo-fonte. Consulte as leis locais sobre DMCA (Digital Millennium Copyright Act) e outras leis relevantes em sua regi\u00e3o.</p>"},{"location":"README.pt-BR/#demonstracao-online","title":"Demonstra\u00e7\u00e3o Online","text":"<p>Fish Audio</p>"},{"location":"README.pt-BR/#inicio-rapido-de-inferencia-local","title":"In\u00edcio R\u00e1pido de Infer\u00eancia Local","text":"<p>inference.ipynb</p>"},{"location":"README.pt-BR/#videos","title":"V\u00eddeos","text":""},{"location":"README.pt-BR/#14-introducao-httpswwwbilibilicomvideobv1pu46evek7","title":"1.4 Introdu\u00e7\u00e3o: https://www.bilibili.com/video/BV1pu46eVEk7","text":""},{"location":"README.pt-BR/#12-introducao-httpswwwbilibilicomvideobv1wz421b71d","title":"1.2 Introdu\u00e7\u00e3o: https://www.bilibili.com/video/BV1wz421B71D","text":""},{"location":"README.pt-BR/#11-apresentacao-tecnica-httpswwwbilibilicomvideobv1zj4m1k7cj","title":"1.1 Apresenta\u00e7\u00e3o T\u00e9cnica: https://www.bilibili.com/video/BV1zJ4m1K7cj","text":""},{"location":"README.pt-BR/#documentacao","title":"Documenta\u00e7\u00e3o","text":"<ul> <li>Ingl\u00eas</li> <li>Chin\u00eas</li> <li>Japon\u00eas</li> <li>Portugu\u00eas (Brasil)</li> </ul>"},{"location":"README.pt-BR/#exemplos","title":"Exemplos","text":"<ul> <li>Ingl\u00eas</li> <li>Chin\u00eas</li> <li>Japon\u00eas</li> <li>Portugu\u00eas (Brasil)</li> </ul>"},{"location":"README.pt-BR/#agradecimentos","title":"Agradecimentos","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>GPT-SoVITS</li> </ul>"},{"location":"README.pt-BR/#patrocinadores","title":"Patrocinadores","text":"Servidores de processamento de dados fornecidos por 6Block Infer\u00eancia online do Fish Audio em parceria com a Lepton"},{"location":"README.zh/","title":"README.zh","text":"Fish Speech  [English](../README.md) | **\u7b80\u4f53\u4e2d\u6587** | [Portuguese](README.pt-BR.md) | [\u65e5\u672c\u8a9e](README.ja.md) | [\ud55c\uad6d\uc5b4](README.ko.md) <p>\u6b64\u4ee3\u7801\u5e93\u53ca\u6a21\u578b\u6839\u636e CC-BY-NC-SA-4.0 \u8bb8\u53ef\u8bc1\u53d1\u5e03\u3002\u8bf7\u53c2\u9605 LICENSE \u4e86\u89e3\u66f4\u591a\u7ec6\u8282.</p>"},{"location":"README.zh/#_1","title":"\u7279\u6027","text":"<ol> <li>\u96f6\u6837\u672c &amp; \u5c0f\u6837\u672c TTS\uff1a\u8f93\u5165 10 \u5230 30 \u79d2\u7684\u58f0\u97f3\u6837\u672c\u5373\u53ef\u751f\u6210\u9ad8\u8d28\u91cf\u7684 TTS \u8f93\u51fa\u3002\u8be6\u89c1 \u8bed\u97f3\u514b\u9686\u6700\u4f73\u5b9e\u8df5\u6307\u5357\u3002</li> <li>\u591a\u8bed\u8a00 &amp; \u8de8\u8bed\u8a00\u652f\u6301\uff1a\u53ea\u9700\u590d\u5236\u5e76\u7c98\u8d34\u591a\u8bed\u8a00\u6587\u672c\u5230\u8f93\u5165\u6846\u4e2d\uff0c\u65e0\u9700\u62c5\u5fc3\u8bed\u8a00\u95ee\u9898\u3002\u76ee\u524d\u652f\u6301\u82f1\u8bed\u3001\u65e5\u8bed\u3001\u97e9\u8bed\u3001\u4e2d\u6587\u3001\u6cd5\u8bed\u3001\u5fb7\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u548c\u897f\u73ed\u7259\u8bed\u3002</li> <li>\u65e0\u97f3\u7d20\u4f9d\u8d56\uff1a\u6a21\u578b\u5177\u5907\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e0d\u4f9d\u8d56\u97f3\u7d20\u8fdb\u884c TTS\uff0c\u80fd\u591f\u5904\u7406\u4efb\u4f55\u6587\u5b57\u8868\u793a\u7684\u8bed\u8a00\u3002</li> <li>\u9ad8\u51c6\u786e\u7387\uff1a\u5728 5 \u5206\u949f\u7684\u82f1\u6587\u6587\u672c\u4e0a\uff0c\u8fbe\u5230\u4e86\u7ea6 2% \u7684 CER\uff08\u5b57\u7b26\u9519\u8bef\u7387\uff09\u548c WER\uff08\u8bcd\u9519\u8bef\u7387\uff09\u3002</li> <li>\u5feb\u901f\uff1a\u901a\u8fc7 fish-tech \u52a0\u901f\uff0c\u5728 Nvidia RTX 4060 \u7b14\u8bb0\u672c\u4e0a\u7684\u5b9e\u65f6\u56e0\u5b50\u7ea6\u4e3a 1:5\uff0c\u5728 Nvidia RTX 4090 \u4e0a\u7ea6\u4e3a 1:15\u3002</li> <li>WebUI \u63a8\u7406\uff1a\u63d0\u4f9b\u6613\u4e8e\u4f7f\u7528\u7684\u57fa\u4e8e Gradio \u7684\u7f51\u9875\u7528\u6237\u754c\u9762\uff0c\u517c\u5bb9 Chrome\u3001Firefox\u3001Edge \u7b49\u6d4f\u89c8\u5668\u3002</li> <li>GUI \u63a8\u7406\uff1a\u63d0\u4f9b PyQt6 \u56fe\u5f62\u754c\u9762\uff0c\u4e0e API \u670d\u52a1\u5668\u65e0\u7f1d\u534f\u4f5c\u3002\u652f\u6301 Linux\u3001Windows \u548c macOS\u3002\u67e5\u770b GUI\u3002</li> <li>\u6613\u4e8e\u90e8\u7f72\uff1a\u8f7b\u677e\u8bbe\u7f6e\u63a8\u7406\u670d\u52a1\u5668\uff0c\u539f\u751f\u652f\u6301 Linux\u3001Windows \u548c macOS\uff0c\u6700\u5927\u7a0b\u5ea6\u51cf\u5c11\u901f\u5ea6\u635f\u5931\u3002</li> </ol>"},{"location":"README.zh/#_2","title":"\u514d\u8d23\u58f0\u660e","text":"<p>\u6211\u4eec\u4e0d\u5bf9\u4ee3\u7801\u5e93\u7684\u4efb\u4f55\u975e\u6cd5\u4f7f\u7528\u627f\u62c5\u4efb\u4f55\u8d23\u4efb. \u8bf7\u53c2\u9605\u60a8\u5f53\u5730\u5173\u4e8e DMCA (\u6570\u5b57\u5343\u5e74\u6cd5\u6848) \u548c\u5176\u4ed6\u76f8\u5173\u6cd5\u5f8b\u6cd5\u89c4.</p>"},{"location":"README.zh/#demo","title":"\u5728\u7ebf DEMO","text":"<p>Fish Audio</p>"},{"location":"README.zh/#_3","title":"\u5feb\u901f\u5f00\u59cb\u672c\u5730\u63a8\u7406","text":"<p>inference.ipynb</p>"},{"location":"README.zh/#_4","title":"\u89c6\u9891","text":""},{"location":"README.zh/#14-httpswwwbilibilicomvideobv1pu46evek7","title":"1.4 \u4ecb\u7ecd: https://www.bilibili.com/video/BV1pu46eVEk7","text":""},{"location":"README.zh/#12-httpswwwbilibilicomvideobv1wz421b71d","title":"1.2 \u4ecb\u7ecd: https://www.bilibili.com/video/BV1wz421B71D","text":""},{"location":"README.zh/#11-httpswwwbilibilicomvideobv1zj4m1k7cj","title":"1.1 \u4ecb\u7ecd: https://www.bilibili.com/video/BV1zJ4m1K7cj","text":""},{"location":"README.zh/#_5","title":"\u6587\u6863","text":"<ul> <li>English</li> <li>\u4e2d\u6587</li> <li>\u65e5\u672c\u8a9e</li> <li>Portuguese (Brazil)</li> </ul>"},{"location":"README.zh/#20241002-v14","title":"\u4f8b\u5b50 (2024/10/02 V1.4)","text":"<ul> <li>English</li> <li>\u4e2d\u6587</li> <li>\u65e5\u672c\u8a9e</li> <li>Portuguese (Brazil)</li> </ul>"},{"location":"README.zh/#_6","title":"\u9e23\u8c22","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>GPT-SoVITS</li> </ul>"},{"location":"README.zh/#_7","title":"\u8d5e\u52a9","text":"\u6570\u636e\u5904\u7406\u670d\u52a1\u5668\u7531 6Block \u63d0\u4f9b Fish Audio \u5728\u7ebf\u63a8\u7406\u4e0e Lepton \u5408\u4f5c"},{"location":"","title":"Introduction","text":"<p>Warning</p> <p>We assume no responsibility for any illegal use of the codebase. Please refer to the local laws regarding DMCA (Digital Millennium Copyright Act) and other relevant laws in your area.  This codebase and all models are released under the CC-BY-NC-SA-4.0 license.</p> <p> </p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>GPU Memory: 4GB (for inference), 8GB (for fine-tuning)</li> <li>System: Linux, Windows</li> </ul>"},{"location":"#windows-setup","title":"Windows Setup","text":"<p>Professional Windows users may consider using WSL2 or Docker to run the codebase.</p> <pre><code># Create a python 3.10 virtual environment, you can also use virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# Install pytorch\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n\n# Install fish-speech\npip3 install -e .\n\n# (Enable acceleration) Install triton-windows\npip install https://github.com/AnyaCoder/fish-speech/releases/download/v0.1.0/triton_windows-0.1.0-py3-none-any.whl\n</code></pre> <p>Non-professional Windows users can consider the following basic methods to run the project without a Linux environment (with model compilation capabilities, i.e., <code>torch.compile</code>):</p> <ol> <li>Extract the project package.</li> <li>Click <code>install_env.bat</code> to install the environment.</li> <li>If you want to enable compilation acceleration, follow this step:<ol> <li>Download the LLVM compiler from the following links:<ul> <li>LLVM-17.0.6 (Official Site Download)</li> <li>LLVM-17.0.6 (Mirror Site Download)</li> <li>After downloading <code>LLVM-17.0.6-win64.exe</code>, double-click to install, select an appropriate installation location, and most importantly, check the <code>Add Path to Current User</code> option to add the environment variable.</li> <li>Confirm that the installation is complete.</li> </ul> </li> <li>Download and install the Microsoft Visual C++ Redistributable to solve potential .dll missing issues:<ul> <li>MSVC++ 14.40.33810.0 Download</li> </ul> </li> <li>Download and install Visual Studio Community Edition to get MSVC++ build tools and resolve LLVM's header file dependencies:<ul> <li>Visual Studio Download</li> <li>After installing Visual Studio Installer, download Visual Studio Community 2022.</li> <li>As shown below, click the <code>Modify</code> button and find the <code>Desktop development with C++</code> option to select and download.</li> </ul> </li> <li>Download and install CUDA Toolkit 12.x</li> </ol> </li> <li>Double-click <code>start.bat</code> to open the training inference WebUI management interface. If needed, you can modify the <code>API_FLAGS</code> as prompted below.</li> </ol> <p>Optional</p> <p>Want to start the inference WebUI?</p> <p>Edit the <code>API_FLAGS.txt</code> file in the project root directory and modify the first three lines as follows: <pre><code> --infer\n # --api\n # --listen ...\n ...\n</code></pre></p> <p>Optional</p> <p>Want to start the API server?</p> <p>Edit the <code>API_FLAGS.txt</code> file in the project root directory and modify the first three lines as follows:</p> <pre><code># --infer\n--api\n--listen ...\n...\n</code></pre> <p>Optional</p> <p>Double-click <code>run_cmd.bat</code> to enter the conda/python command line environment of this project.</p>"},{"location":"#linux-setup","title":"Linux Setup","text":"<p>See pyproject.toml for details. <pre><code># Create a python 3.10 virtual environment, you can also use virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# Install pytorch\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n\n# (Ubuntu / Debian User) Install sox + ffmpeg\napt install libsox-dev ffmpeg \n\n# (Ubuntu / Debian User) Install pyaudio \napt install build-essential \\\n    cmake \\\n    libasound-dev \\\n    portaudio19-dev \\\n    libportaudio2 \\\n    libportaudiocpp0\n\n# Install fish-speech\npip3 install -e .[stable]\n</code></pre></p>"},{"location":"#macos-setup","title":"macos setup","text":"<p>If you want to perform inference on MPS, please add the <code>--device mps</code> flag. Please refer to this PR for a comparison of inference speeds.</p> <p>Warning</p> <p>The <code>compile</code> option is not officially supported on Apple Silicon devices, so there is no guarantee that inference speed will improve.</p> <pre><code># create a python 3.10 virtual environment, you can also use virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n# install pytorch\npip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n# install fish-speech\npip install -e .[stable]\n</code></pre>"},{"location":"#docker-setup","title":"Docker Setup","text":"<ol> <li> <p>Install NVIDIA Container Toolkit:</p> <p>To use GPU for model training and inference in Docker, you need to install NVIDIA Container Toolkit:</p> <p>For Ubuntu users:</p> <pre><code># Add repository\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n# Install nvidia-container-toolkit\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n# Restart Docker service\nsudo systemctl restart docker\n</code></pre> <p>For users of other Linux distributions, please refer to: NVIDIA Container Toolkit Install-guide.</p> </li> <li> <p>Pull and run the fish-speech image</p> <pre><code># Pull the image\ndocker pull fishaudio/fish-speech:latest-dev\n# Run the image\ndocker run -it \\\n    --name fish-speech \\\n    --gpus all \\\n    -p 7860:7860 \\\n    fishaudio/fish-speech:latest-dev \\\n    zsh\n# If you need to use a different port, please modify the -p parameter to YourPort:7860\n</code></pre> </li> <li> <p>Download model dependencies</p> <p>Make sure you are in the terminal inside the docker container, then download the required <code>vqgan</code> and <code>llama</code> models from our huggingface repository.</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> </li> <li> <p>Configure environment variables and access WebUI</p> <p>In the terminal inside the docker container, enter <code>export GRADIO_SERVER_NAME=\"0.0.0.0\"</code> to allow external access to the gradio service inside docker. Then in the terminal inside the docker container, enter <code>python tools/webui.py</code> to start the WebUI service.</p> <p>If you're using WSL or MacOS, visit http://localhost:7860 to open the WebUI interface.</p> <p>If it's deployed on a server, replace localhost with your server's IP.</p> </li> </ol>"},{"location":"#changelog","title":"Changelog","text":"<ul> <li>2024/09/10: Updated Fish-Speech to 1.4 version, with an increase in dataset size and a change in the quantizer's n_groups from 4 to 8.</li> <li>2024/07/02: Updated Fish-Speech to 1.2 version, remove VITS Decoder, and greatly enhanced zero-shot ability.</li> <li>2024/05/10: Updated Fish-Speech to 1.1 version, implement VITS decoder to reduce WER and improve timbre similarity.</li> <li>2024/04/22: Finished Fish-Speech 1.0 version, significantly modified VQGAN and LLAMA models.</li> <li>2023/12/28: Added <code>lora</code> fine-tuning support.</li> <li>2023/12/27: Add <code>gradient checkpointing</code>, <code>causual sampling</code>, and <code>flash-attn</code> support.</li> <li>2023/12/19: Updated webui and HTTP API.</li> <li>2023/12/18: Updated fine-tuning documentation and related examples.</li> <li>2023/12/17: Updated <code>text2semantic</code> model, supporting phoneme-free mode.</li> <li>2023/12/13: Beta version released, includes VQGAN model and a language model based on LLAMA (phoneme support only).</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"finetune/","title":"Fine-tuning","text":"<p>Obviously, when you opened this page, you were not satisfied with the performance of the few-shot pre-trained model. You want to fine-tune a model to improve its performance on your dataset.</p> <p>In current version, you only need to finetune the 'LLAMA' part.</p>"},{"location":"finetune/#fine-tuning-llama","title":"Fine-tuning LLAMA","text":""},{"location":"finetune/#1-prepare-the-dataset","title":"1. Prepare the dataset","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>You need to convert your dataset into the above format and place it under <code>data</code>. The audio file can have the extensions <code>.mp3</code>, <code>.wav</code>, or <code>.flac</code>, and the annotation file should have the extensions <code>.lab</code>.</p> <p>Dataset Format</p> <p>The <code>.lab</code> annotation file only needs to contain the transcription of the audio, with no special formatting required. For example, if <code>hi.mp3</code> says \"Hello, goodbye,\" then the <code>hi.lab</code> file would contain a single line of text: \"Hello, goodbye.\"</p> <p>Warning</p> <p>It's recommended to apply loudness normalization to the dataset. You can use fish-audio-preprocess to do this.</p> <pre><code>fap loudness-norm data-raw data --clean\n</code></pre>"},{"location":"finetune/#2-batch-extraction-of-semantic-tokens","title":"2. Batch extraction of semantic tokens","text":"<p>Make sure you have downloaded the VQGAN weights. If not, run the following command:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>You can then run the following command to extract semantic tokens:</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p>You can adjust <code>--num-workers</code> and <code>--batch-size</code> to increase extraction speed, but please make sure not to exceed your GPU memory limit. For the VITS format, you can specify a file list using <code>--filelist xxx.list</code>.</p> <p>This command will create <code>.npy</code> files in the <code>data</code> directory, as shown below:</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"finetune/#3-pack-the-dataset-into-protobuf","title":"3. Pack the dataset into protobuf","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>After the command finishes executing, you should see the <code>quantized-dataset-ft.protos</code> file in the <code>data</code> directory.</p>"},{"location":"finetune/#4-finally-fine-tuning-with-lora","title":"4. Finally, fine-tuning with LoRA","text":"<p>Similarly, make sure you have downloaded the <code>LLAMA</code> weights. If not, run the following command:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>Finally, you can start the fine-tuning by running the following command:</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p>You can modify the training parameters such as <code>batch_size</code>, <code>gradient_accumulation_steps</code>, etc. to fit your GPU memory by modifying <code>fish_speech/configs/text2semantic_finetune.yaml</code>.</p> <p>Note</p> <p>For Windows users, you can use <code>trainer.strategy.process_group_backend=gloo</code> to avoid <code>nccl</code> issues.</p> <p>After training is complete, you can refer to the inference section to generate speech.</p> <p>Info</p> <p>By default, the model will only learn the speaker's speech patterns and not the timbre. You still need to use prompts to ensure timbre stability. If you want to learn the timbre, you can increase the number of training steps, but this may lead to overfitting.</p> <p>After training, you need to convert the LoRA weights to regular weights before performing inference.</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>You may also try other checkpoints. We suggest using the earliest checkpoint that meets your requirements, as they often perform better on out-of-distribution (OOD) data.</p>"},{"location":"inference/","title":"Inference","text":"<p>Inference support command line, HTTP API and web UI.</p> <p>Note</p> <p>Overall, reasoning consists of several parts:</p> <ol> <li>Encode a given ~10 seconds of voice using VQGAN.</li> <li>Input the encoded semantic tokens and the corresponding text into the language model as an example.</li> <li>Given a new piece of text, let the model generate the corresponding semantic tokens.</li> <li>Input the generated semantic tokens into VITS / VQGAN to decode and generate the corresponding voice.</li> </ol>"},{"location":"inference/#command-line-inference","title":"Command Line Inference","text":"<p>Download the required <code>vqgan</code> and <code>llama</code> models from our Hugging Face repository.</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"inference/#1-generate-prompt-from-voice","title":"1. Generate prompt from voice:","text":"<p>Note</p> <p>If you plan to let the model randomly choose a voice timbre, you can skip this step.</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>You should get a <code>fake.npy</code> file.</p>"},{"location":"inference/#2-generate-semantic-tokens-from-text","title":"2. Generate semantic tokens from text:","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"The text you want to convert\" \\\n    --prompt-text \"Your reference text\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>This command will create a <code>codes_N</code> file in the working directory, where N is an integer starting from 0.</p> <p>Note</p> <p>You may want to use <code>--compile</code> to fuse CUDA kernels for faster inference (~30 tokens/second -&gt; ~500 tokens/second). Correspondingly, if you do not plan to use acceleration, you can comment out the <code>--compile</code> parameter.</p> <p>Info</p> <p>For GPUs that do not support bf16, you may need to use the <code>--half</code> parameter.</p>"},{"location":"inference/#3-generate-vocals-from-semantic-tokens","title":"3. Generate vocals from semantic tokens:","text":""},{"location":"inference/#vqgan-decoder","title":"VQGAN Decoder","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"inference/#http-api-inference","title":"HTTP API Inference","text":"<p>We provide a HTTP API for inference. You can use the following command to start the server:</p> <pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>If you want to speed up inference, you can add the <code>--compile</code> parameter.</p> <p>After that, you can view and test the API at http://127.0.0.1:8080/.</p> <p>Below is an example of sending a request using <code>tools/post_api.py</code>.</p> <pre><code>python -m tools.post_api \\\n    --text \"Text to be input\" \\\n    --reference_audio \"Path to reference audio\" \\\n    --reference_text \"Text content of the reference audio\" \\\n    --streaming True\n</code></pre> <p>The above command indicates synthesizing the desired audio according to the reference audio information and returning it in a streaming manner.</p> <p>The following example demonstrates that you can use multiple reference audio paths and reference audio texts at once. Separate them with spaces in the command.</p> <pre><code>python -m tools.post_api \\\n    --text \"Text to input\" \\\n    --reference_audio \"reference audio path1\" \"reference audio path2\" \\\n    --reference_text \"reference audio text1\" \"reference audio text2\"\\\n    --streaming False \\\n    --output \"generated\" \\\n    --format \"mp3\"\n</code></pre> <p>The above command synthesizes the desired <code>MP3</code> format audio based on the information from multiple reference audios and saves it as <code>generated.mp3</code> in the current directory.</p> <p>You can also use <code>--reference_id</code> (only one can be used) instead of <code>--reference-audio</code> and <code>--reference_text</code>, provided that you create a <code>references/&lt;your reference_id&gt;</code> folder in the project root directory, which contains any audio and annotation text.  The currently supported reference audio has a maximum total duration of 90 seconds.</p> <p>Info</p> <p>To learn more about available parameters, you can use the command <code>python -m tools.post_api -h</code></p>"},{"location":"inference/#gui-inference","title":"GUI Inference","text":"<p>Download client</p>"},{"location":"inference/#webui-inference","title":"WebUI Inference","text":"<p>You can start the WebUI using the following command:</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>If you want to speed up inference, you can add the <code>--compile</code> parameter.</p> <p>Note</p> <p>You can save the label file and reference audio file in advance to the <code>references</code> folder in the main directory (which you need to create yourself), so that you can directly call them in the WebUI.</p> <p>Note</p> <p>You can use Gradio environment variables, such as <code>GRADIO_SHARE</code>, <code>GRADIO_SERVER_PORT</code>, <code>GRADIO_SERVER_NAME</code> to configure WebUI.</p> <p>Enjoy!</p>"},{"location":"samples/","title":"Samples","text":"<p>ver 1.4</p>"},{"location":"samples/#credits","title":"Credits","text":"<p>Special thanks to Seed-TTS (2024)  for providing the evaluation data for demonstration.</p> <p>All prompt audio is from the Seed-TTS effect demo page, and all generated audio is from the first generation of fish-speech version 1.4.</p>"},{"location":"samples/#zero-shot-in-context-learning","title":"Zero-shot In-context Learning","text":"Language  Prompt  Same Language Generation Cross-linugal Generation EN Your browser does not support the audio element. Your browser does not support the audio element.I don't really care what you call me. I've been a silent spectator, watching species evolve, empires rise and fall. But always remember, I am mighty and enduring. Respect me and I'll nurture you; ignore me and you shall face the consequences. Your browser does not support the audio element.\u987f\u65f6\uff0c\u6c14\u6c1b\u53d8\u5f97\u6c89\u90c1\u8d77\u6765\u3002\u4e4d\u770b\u4e4b\u4e0b\uff0c\u4e00\u5207\u7684\u56f0\u6270\u4eff\u4f5b\u90fd\u56f4\u7ed5\u5728\u6211\u8eab\u8fb9\u3002\u6211\u76b1\u7740\u7709\u5934\uff0c\u611f\u53d7\u7740\u90a3\u4efd\u538b\u529b\uff0c\u4f46\u6211\u77e5\u9053\u6211\u4e0d\u80fd\u653e\u5f03\uff0c\u4e0d\u80fd\u8ba4\u8f93\u3002\u4e8e\u662f\uff0c\u6211\u6df1\u5438\u4e00\u53e3\u6c14\uff0c\u5fc3\u5e95\u7684\u58f0\u97f3\u544a\u8bc9\u6211\uff1a\u201c\u65e0\u8bba\u5982\u4f55\uff0c\u90fd\u8981\u51b7\u9759\u4e0b\u6765\uff0c\u91cd\u65b0\u5f00\u59cb\u3002\u201d Your browser does not support the audio element. Your browser does not support the audio element.Dealing with family secrets is never easy. Yet, sometimes, omission is a form of protection, intending to safeguard some from the harsh truths. One day, I hope you understand the reasons behind my actions. Until then, Anna, please, bear with me. Your browser does not support the audio element.\u5904\u7406\u5bb6\u5ead\u79d8\u5bc6\u4ece\u6765\u90fd\u4e0d\u662f\u4e00\u4ef6\u5bb9\u6613\u7684\u4e8b\u3002\u7136\u800c\uff0c\u6709\u65f6\u5019\uff0c\u9690\u7792\u662f\u4e00\u79cd\u4fdd\u62a4\u5f62\u5f0f\uff0c\u65e8\u5728\u4fdd\u62a4\u4e00\u4e9b\u4eba\u514d\u53d7\u6b8b\u9177\u7684\u771f\u76f8\u4f24\u5bb3\u3002\u6709\u4e00\u5929\uff0c\u6211\u5e0c\u671b\u4f60\u80fd\u7406\u89e3\u6211\u884c\u4e3a\u80cc\u540e\u7684\u539f\u56e0\u3002\u5728\u90a3\u4e4b\u524d\uff0c\u5b89\u5a1c\uff0c\u8bf7\u5bb9\u5fcd\u6211\u3002 Your browser does not support the audio element. Your browser does not support the audio element.The combinations of different textures and flavors create a perfect harmony. The succulence of the steak, the tartness of the cranberries, the crunch of pine nuts, and creaminess of blue cheese make it a truly delectable delight. Enjoy your culinary adventure! Your browser does not support the audio element.\u542c\u7740\u4f60\u7684\u8bdd\uff0c\u6211\u5fc3\u91cc\u4e94\u5473\u6742\u9648\u3002\u867d\u7136\u6211\u613f\u610f\u4e00\u76f4\u5728\u4f60\u8eab\u8fb9\uff0c\u627f\u62c5\u4e00\u5207\u4e0d\u5e78\uff0c\u4f46\u6211\u77e5\u9053\u53ea\u6709\u8ba9\u4f60\u81ea\u5df1\u9762\u5bf9\uff0c\u624d\u80fd\u771f\u6b63\u8ba9\u4f60\u53d8\u5f97\u66f4\u5f3a\u5927\u3002\u6240\u4ee5\uff0c\u4f60\u8981\u8bb0\u5f97\uff0c\u65e0\u8bba\u9762\u5bf9\u4f55\u79cd\u56f0\u96be\uff0c\u90fd\u8bf7\u4f60\u575a\u5f3a\uff0c\u6211\u4f1a\u5728\u5fc3\u91cc\u4e00\u76f4\u652f\u6301\u4f60\u7684\u3002 ZH Your browser does not support the audio element. Your browser does not support the audio element.\u7a81\u7136\uff0c\u8eab\u8fb9\u4e00\u9635\u7b11\u58f0\u3002\u6211\u770b\u7740\u4ed6\u4eec\uff0c\u610f\u6c14\u98ce\u53d1\u5730\u633a\u76f4\u4e86\u80f8\u819b\uff0c\u7529\u4e86\u7529\u90a3\u7a0d\u663e\u8089\u611f\u7684\u53cc\u81c2\uff0c\u8f7b\u7b11\u9053\uff1a\"\u6211\u8eab\u4e0a\u7684\u8089\uff0c\u662f\u4e3a\u4e86\u63a9\u9970\u6211\u7206\u68da\u7684\u9b45\u529b\uff0c\u5426\u5219\uff0c\u5c82\u4e0d\u5413\u574f\u4e86\u4f60\u4eec\u5462\uff1f\" Your browser does not support the audio element.Suddenly, there was a burst of laughter beside me. I looked at them, stood up straight with high spirit, shook the slightly fleshy arms, and smiled lightly, saying, \"The flesh on my body is to hide my bursting charm. Otherwise, wouldn't it scare you?\" Your browser does not support the audio element. Your browser does not support the audio element.\u4ed6\u95ed\u4e0a\u773c\u775b\uff0c\u671f\u671b\u8fd9\u4e00\u5207\u90fd\u80fd\u8fc7\u53bb\u3002\u7136\u800c\uff0c\u5f53\u4ed6\u518d\u6b21\u7741\u5f00\u773c\u775b\uff0c\u773c\u524d\u7684\u666f\u8c61\u8ba9\u4ed6\u4e0d\u7981\u5012\u5438\u4e00\u53e3\u6c14\u3002\u96fe\u6c14\u4e2d\u51fa\u73b0\u7684\u7981\u95ed\u5c9b\uff0c\u964c\u751f\u53c8\u719f\u6089\uff0c\u5145\u6ee1\u672a\u77e5\u7684\u5371\u9669\u3002\u4ed6\u63e1\u7d27\u62f3\u5934\uff0c\u5fc3\u77e5\u4ed6\u7684\u751f\u6d3b\u5373\u5c06\u53d1\u751f\u7ffb\u5929\u8986\u5730\u7684\u6539\u53d8\u3002 Your browser does not support the audio element.He closed his eyes, expecting that all of this could pass. However, when he opened his eyes again, the sight in front of him made him couldn't help but take a deep breath. The closed island that appeared in the fog, strange and familiar, was full of unknown dangers. He tightened his fist, knowing that his life was about to undergo earth-shaking changes.  Your browser does not support the audio element. Your browser does not support the audio element.\u987f\u65f6\uff0c\u6c14\u6c1b\u53d8\u5f97\u6c89\u90c1\u8d77\u6765\u3002\u4e4d\u770b\u4e4b\u4e0b\uff0c\u4e00\u5207\u7684\u56f0\u6270\u4eff\u4f5b\u90fd\u56f4\u7ed5\u5728\u6211\u8eab\u8fb9\u3002\u6211\u76b1\u7740\u7709\u5934\uff0c\u611f\u53d7\u7740\u90a3\u4efd\u538b\u529b\uff0c\u4f46\u6211\u77e5\u9053\u6211\u4e0d\u80fd\u653e\u5f03\uff0c\u4e0d\u80fd\u8ba4\u8f93\u3002\u4e8e\u662f\uff0c\u6211\u6df1\u5438\u4e00\u53e3\u6c14\uff0c\u5fc3\u5e95\u7684\u58f0\u97f3\u544a\u8bc9\u6211\uff1a\u201c\u65e0\u8bba\u5982\u4f55\uff0c\u90fd\u8981\u51b7\u9759\u4e0b\u6765\uff0c\u91cd\u65b0\u5f00\u59cb\u3002\u201d Your browser does not support the audio element.Suddenly, the atmosphere became gloomy. At first glance, all the troubles seemed to surround me. I frowned, feeling that pressure, but I know I can't give up, can't admit defeat. So, I took a deep breath, and the voice in my heart told me, \"Anyway, must calm down and start again.\""},{"location":"samples/#speaker-fine-tune","title":"Speaker Fine-tune","text":"Text  Generated Speaker1 \u597d\u5440\uff0c\u54c8\u54c8\u54c8\u54c8\u54c8\uff0c\u559c\u6b22\u7b11\u7684\u4eba\u8fd0\u6c14\u90fd\u4e0d\u4f1a\u5dee\u54e6\uff0c\u5e0c\u671b\u4f60\u6bcf\u5929\u7b11\u53e3\u5e38\u5f00~ Your browser does not support the audio element. \u54c7\uff01\u606d\u559c\u4f60\u4e2d\u4e86\u5927\u4e50\u900f\uff0c\u516b\u767e\u4e07\u53ef\u771f\u4e0d\u5c11\u5462\uff01\u6709\u4ec0\u4e48\u7279\u522b\u7684\u8ba1\u5212\u6216\u60f3\u6cd5\u5417\uff1f Your browser does not support the audio element. \u54fc\uff0c\u4f60\u8fd9\u4e48\u95ee\u662f\u60f3\u8bf7\u672c\u5c0f\u59d0\u5403\u996d\u5417\uff1f\u5982\u679c\u5bf9\u8c61\u662f\u4f60\u7684\u8bdd\uff0c\u90a3\u4e5f\u4e0d\u662f\u4e0d\u53ef\u4ee5\u3002 Your browser does not support the audio element. Speaker2 \u662f\u5440\uff0c\u4ed6\u8fd8\u60f3\u6362\u4e2a\u5730\u7403\u4eea\u54c8\u54c8\u54c8\uff0c\u770b\u6765\u7ed9\u4f60\u79ef\u7d2f\u4e86\u4e00\u4e9b\u5feb\u4e50\u503c\u4e86\uff0c\u4f60\u8fd8\u60f3\u4e0d\u60f3\u518d\u542c\u4e00\u4e2a\u5176\u4ed6\u7684\u7b11\u8bdd\u5440\uff1f Your browser does not support the audio element. \u563f\u563f\uff0c\u4f60\u662f\u4e0d\u662f\u4e5f\u60f3\u62e5\u6709\u751c\u751c\u7684\u604b\u7231\u5462\uff1f\u300a\u5fae\u5fae\u4e00\u7b11\u5f88\u503e\u57ce\u300b\u662f\u4f60\u7684\u4e0d\u4e8c\u9009\u62e9\uff0c\u7537\u5973\u4e3b\u662f\u6821\u82b1\u6821\u8349\u7c7b\u578b\uff0c\u4ed6\u4eec\u901a\u8fc7\u6e38\u620f\u7ed3\u8bc6\uff0c\u518d\u5230\u4e24\u4eba\u89c1\u9762\uff0c\u5168\u7a0b\u6ca1\u6709\u4e00\u70b9\u8bef\u4f1a\uff0c\u771f\u7684\u9f41\u751c\uff0c\u60f3\u60f3\u90fd\u5fcd\u4e0d\u4f4f\u201c\u59e8\u5988\u7b11\u201d~ Your browser does not support the audio element. \u5c0f\u50bb\u74dc\uff0c\u55ef\u2026\u2026\u7b97\u662f\u4e2a\u5f88\u53ef\u7231\u5f88\u4eb2\u5207\u7684\u540d\u5b57\uff0c\u6709\u70b9\u201c\u72ec\u7279\u201d\u54e6\uff0c\u4e0d\u8fc7\u6211\u6709\u4e9b\u597d\u5947\uff0c\u4f60\u4e3a\u4ec0\u4e48\u4f1a\u7ed9\u6211\u9009\u8fd9\u4e2a\u6635\u79f0\u5462\uff1f Your browser does not support the audio element."},{"location":"samples/#content-editing","title":"Content Editing","text":"Language Original Text Original Audio Target Text Edited Audio EN They can't order me to stop dreaming. If you dream a thing more than once, it's sure to come true. Have faith in your dreams, and someday your rainbow will come shining through. Your browser does not support the audio element. They can't require me to stop imagining. If you envision a thing more than once, it's bound to come about. Have trust in your visions, and someday your radiance will come beaming through. Your browser does not support the audio element. Are you familiar with it? Slice the steak and place the strips on top, then garnish with the dried cranberries, pine nuts, and blue cheese. I wonder how people rationalise the decision? Your browser does not support the audio element. Are you acquainted with it? Cut the pork and place the strips on top, then garnish with the dried cherries, almonds, and feta cheese. I query how people justify the choice? Your browser does not support the audio element. ZH \u81ea\u53e4\u4ee5\u6765\uff0c\u5eb8\u541b\u6700\u6015\u515a\u653f\u4e86\uff0c\u53ef\u5723\u541b\u4ed6\u5c31\u4e0d\u6015\uff0c\u4e0d\u4f46\u4e0d\u6015\uff0c\u53cd\u80fd\u5229\u7528\u3002\u8981\u6211\u8bf4\uff0c\u4f60\u5c31\u8ba9\u660e\u73e0\u7d22\u989d\u56fe\u4e92\u76f8\u4e89\u5ba0\uff0c\u53ea\u8981\u4f60\u5fc3\u91cc\u660e\u767d\uff0c\u5de6\u53f3\u9022\u6e90\uff0c\u4f60\u5c31\u80fd\u7acb\u4e8e\u4e0d\u8d25\u4e4b\u5730\u3002 Your browser does not support the audio element. \u4ece\u53e4\u81f3\u4eca\uff0c\u5eb8\u541b\u6700\u6015\u671d\u7eb2\u4e86\uff0c\u53ef\u660e\u541b\u4ed6\u5c31\u4e0d\u6015\uff0c\u4e0d\u4f46\u4e0d\u6015\uff0c\u53cd\u80fd\u501f\u52a9\u3002\u8981\u6211\u8bf4\uff0c\u4f60\u5c31\u8ba9\u674e\u56db\u5f20\u4e09\u4e92\u76f8\u4e89\u5ba0\uff0c\u53ea\u8981\u4f60\u5fc3\u91cc\u6e05\u695a\uff0c\u5de6\u53f3\u5468\u65cb\uff0c\u4f60\u5c31\u80fd\u5904\u4e8e\u4e0d\u8d25\u4e4b\u5883\u3002 Your browser does not support the audio element. \u5bf9\uff0c\u8fd9\u5c31\u662f\u6211\uff0c\u4e07\u4eba\u656c\u4ef0\u7684\u592a\u4e59\u771f\u4eba\uff0c\u867d\u7136\u6709\u70b9\u5a74\u513f\u80a5\uff0c\u4f46\u4e5f\u63a9\u4e0d\u4f4f\u6211\u903c\u4eba\u7684\u5e05\u6c14\u3002 Your browser does not support the audio element. \u5bf9\uff0c\u8fd9\u5c31\u662f\u6211\uff0c\u4f17\u4eba\u5c0a\u5d07\u7684\u592a\u767d\u91d1\u661f\uff0c\u867d\u7136\u6709\u70b9\u5a03\u5a03\u8138\uff0c\u4f46\u4e5f\u906e\u4e0d\u4f4f\u6211\u8ff7\u4eba\u7684\u9b45\u529b\u3002 Your browser does not support the audio element."},{"location":"start_agent/","title":"Start Agent","text":""},{"location":"start_agent/#requirements","title":"Requirements","text":"<ul> <li>GPU memory: At least 8GB(under quanization), 16GB or more is recommanded.</li> <li>Disk usage: 10GB</li> </ul>"},{"location":"start_agent/#download-model","title":"Download Model","text":"<p>You can get the model by:</p> <pre><code>huggingface-cli download fishaudio/fish-agent-v0.1-3b --local-dir checkpoints/fish-agent-v0.1-3b\n</code></pre> <p>Put them in the 'checkpoints' folder.</p> <p>You also need the fish-speech model which you can download instructed by inference.</p> <p>So there will be 2 folder in the checkpoints.</p> <p>The <code>checkpoints/fish-speech-1.4</code> and <code>checkpoints/fish-agent-v0.1-3b</code></p>"},{"location":"start_agent/#environment-prepare","title":"Environment Prepare","text":"<p>If you already have Fish-speech, you can directly use by adding the follow instruction: <pre><code>pip install cachetools\n</code></pre></p> <p>Note</p> <p>Please use the Python version below 3.12 for compile.</p> <p>If you don't have, please use the below commands to build yout environment:</p> <pre><code>sudo apt-get install portaudio19-dev\n\npip install -e .[stable]\n</code></pre>"},{"location":"start_agent/#launch-the-agent-demo","title":"Launch The Agent Demo.","text":"<p>To build fish-agent, please use the command below under the main folder:</p> <pre><code>python -m tools.api --llama-checkpoint-path checkpoints/fish-agent-v0.1-3b/ --mode agent --compile\n</code></pre> <p>The <code>--compile</code> args only support Python &lt; 3.12 , which will greatly speed up the token generation.</p> <p>It won't compile at once (remember).</p> <p>Then open another terminal and use the command:</p> <pre><code>python -m tools.e2e_webui\n</code></pre> <p>This will create a Gradio WebUI on the device.</p> <p>When you first use the model, it will come to compile (if the <code>--compile</code> is True) for a short time, so please wait with patience.</p>"},{"location":"start_agent/#gradio-webui","title":"Gradio Webui","text":"<p>Have a good time!</p>"},{"location":"start_agent/#performance","title":"Performance","text":"<p>Under our test, a 4060 laptop just barely runs, but is very stretched, which is only about 8 tokens/s. The 4090 is around 95 tokens/s under compile, which is what we recommend.</p>"},{"location":"start_agent/#about-agent","title":"About Agent","text":"<p>The demo is an early alpha test version, the inference speed needs to be optimised, and there are a lot of bugs waiting to be fixed. If you've found a bug or want to fix it, we'd be very happy to receive an issue or a pull request.</p>"},{"location":"zh/","title":"\u4ecb\u7ecd","text":"<p>\u8b66\u544a</p> <p>\u6211\u4eec\u4e0d\u5bf9\u4ee3\u7801\u5e93\u7684\u4efb\u4f55\u975e\u6cd5\u4f7f\u7528\u627f\u62c5\u4efb\u4f55\u8d23\u4efb. \u8bf7\u53c2\u9605\u60a8\u5f53\u5730\u5173\u4e8e DMCA (\u6570\u5b57\u5343\u5e74\u6cd5\u6848) \u548c\u5176\u4ed6\u76f8\u5173\u6cd5\u5f8b\u6cd5\u89c4.  \u6b64\u4ee3\u7801\u5e93\u4e0e\u6240\u6709\u6a21\u578b\u6839\u636e CC-BY-NC-SA-4.0 \u8bb8\u53ef\u8bc1\u53d1\u5e03.</p> <p> </p>"},{"location":"zh/#_2","title":"\u8981\u6c42","text":"<ul> <li>GPU \u5185\u5b58: 4GB (\u7528\u4e8e\u63a8\u7406), 8GB (\u7528\u4e8e\u5fae\u8c03)</li> <li>\u7cfb\u7edf: Linux, Windows</li> </ul>"},{"location":"zh/#windows","title":"Windows \u914d\u7f6e","text":"<p>Windows \u4e13\u4e1a\u7528\u6237\u53ef\u4ee5\u8003\u8651 WSL2 \u6216 docker \u6765\u8fd0\u884c\u4ee3\u7801\u5e93\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a python 3.10 \u865a\u62df\u73af\u5883, \u4f60\u4e5f\u53ef\u4ee5\u7528 virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# \u5b89\u88c5 pytorch\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n\n# \u5b89\u88c5 fish-speech\npip3 install -e .\n\n# (\u5f00\u542f\u7f16\u8bd1\u52a0\u901f) \u5b89\u88c5 triton-windows\npip install https://github.com/AnyaCoder/fish-speech/releases/download/v0.1.0/triton_windows-0.1.0-py3-none-any.whl\n</code></pre> <p>Windows \u975e\u4e13\u4e1a\u7528\u6237\u53ef\u8003\u8651\u4ee5\u4e0b\u4e3a\u514d Linux \u73af\u5883\u7684\u57fa\u7840\u8fd0\u884c\u65b9\u6cd5\uff08\u9644\u5e26\u6a21\u578b\u7f16\u8bd1\u529f\u80fd\uff0c\u5373 <code>torch.compile</code>\uff09\uff1a</p> <ol> <li>\u89e3\u538b\u9879\u76ee\u538b\u7f29\u5305\u3002</li> <li>\u70b9\u51fb <code>install_env.bat</code> \u5b89\u88c5\u73af\u5883\u3002</li> <li>\u82e5\u9700\u8981\u5f00\u542f\u7f16\u8bd1\u52a0\u901f\u5219\u6267\u884c\u8fd9\u4e00\u6b65:<ol> <li>\u4f7f\u7528\u5982\u4e0b\u94fe\u63a5\u4e0b\u8f7d LLVM \u7f16\u8bd1\u5668\u3002<ul> <li>LLVM-17.0.6\uff08\u539f\u7ad9\u7ad9\u70b9\u4e0b\u8f7d\uff09</li> <li>LLVM-17.0.6\uff08\u955c\u50cf\u7ad9\u70b9\u4e0b\u8f7d\uff09</li> <li>\u4e0b\u8f7d\u5b8c <code>LLVM-17.0.6-win64.exe</code> \u540e\uff0c\u53cc\u51fb\u8fdb\u884c\u5b89\u88c5\uff0c\u9009\u62e9\u5408\u9002\u7684\u5b89\u88c5\u4f4d\u7f6e\uff0c\u6700\u91cd\u8981\u7684\u662f\u52fe\u9009 <code>Add Path to Current User</code> \u6dfb\u52a0\u73af\u5883\u53d8\u91cf\u3002</li> <li>\u786e\u8ba4\u5b89\u88c5\u5b8c\u6210\u3002</li> </ul> </li> <li>\u4e0b\u8f7d\u5b89\u88c5 Microsoft Visual C++ \u53ef\u518d\u53d1\u884c\u7a0b\u5e8f\u5305\uff0c\u89e3\u51b3\u6f5c\u5728 .dll \u4e22\u5931\u95ee\u9898\u3002<ul> <li>MSVC++ 14.40.33810.0 \u4e0b\u8f7d</li> </ul> </li> <li>\u4e0b\u8f7d\u5b89\u88c5 Visual Studio \u793e\u533a\u7248\u4ee5\u83b7\u53d6 MSVC++ \u7f16\u8bd1\u5de5\u5177, \u89e3\u51b3 LLVM \u7684\u5934\u6587\u4ef6\u4f9d\u8d56\u95ee\u9898\u3002<ul> <li>Visual Studio \u4e0b\u8f7d</li> <li>\u5b89\u88c5\u597d Visual Studio Installer \u4e4b\u540e\uff0c\u4e0b\u8f7d Visual Studio Community 2022</li> <li>\u5982\u4e0b\u56fe\u70b9\u51fb<code>\u4fee\u6539</code>\u6309\u94ae\uff0c\u627e\u5230<code>\u4f7f\u7528C++\u7684\u684c\u9762\u5f00\u53d1</code>\u9879\uff0c\u52fe\u9009\u4e0b\u8f7d</li> </ul> </li> <li>\u4e0b\u8f7d\u5b89\u88c5 CUDA Toolkit 12.x</li> </ol> </li> <li>\u53cc\u51fb <code>start.bat</code> \u6253\u5f00\u8bad\u7ec3\u63a8\u7406 WebUI \u7ba1\u7406\u754c\u9762. \u5982\u6709\u9700\u8981\uff0c\u53ef\u7167\u4e0b\u5217\u63d0\u793a\u4fee\u6539<code>API_FLAGS</code>.</li> </ol> <p>\u53ef\u9009</p> <p>\u60f3\u542f\u52a8 \u63a8\u7406 WebUI \u754c\u9762\uff1f\u7f16\u8f91\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\u7684 <code>API_FLAGS.txt</code>, \u524d\u4e09\u884c\u4fee\u6539\u6210\u5982\u4e0b\u683c\u5f0f: <pre><code>--infer\n# --api\n# --listen ...\n...\n</code></pre></p> <p>\u53ef\u9009</p> <p>\u60f3\u542f\u52a8 API \u670d\u52a1\u5668\uff1f\u7f16\u8f91\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\u7684 <code>API_FLAGS.txt</code>, \u524d\u4e09\u884c\u4fee\u6539\u6210\u5982\u4e0b\u683c\u5f0f: <pre><code># --infer\n--api\n--listen ...\n...\n</code></pre></p> <p>\u53ef\u9009</p> <p>\u53cc\u51fb <code>run_cmd.bat</code> \u8fdb\u5165\u672c\u9879\u76ee\u7684 conda/python \u547d\u4ee4\u884c\u73af\u5883</p>"},{"location":"zh/#linux","title":"Linux \u914d\u7f6e","text":"<p>\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1 pyproject.toml\u3002 <pre><code># \u521b\u5efa\u4e00\u4e2a python 3.10 \u865a\u62df\u73af\u5883, \u4f60\u4e5f\u53ef\u4ee5\u7528 virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# \u5b89\u88c5 pytorch\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n\n# (Ubuntu / Debian \u7528\u6237) \u5b89\u88c5 sox + ffmpeg\napt install libsox-dev ffmpeg\n\n# (Ubuntu / Debian \u7528\u6237) \u5b89\u88c5 pyaudio\napt install build-essential \\\n    cmake \\\n    libasound-dev \\\n    portaudio19-dev \\\n    libportaudio2 \\\n    libportaudiocpp0\n\n# \u5b89\u88c5 fish-speech\npip3 install -e .[stable]\n</code></pre></p>"},{"location":"zh/#macos","title":"macos \u914d\u7f6e","text":"<p>\u5982\u679c\u60a8\u60f3\u5728 MPS \u4e0a\u8fdb\u884c\u63a8\u7406\uff0c\u8bf7\u6dfb\u52a0 <code>--device mps</code> \u6807\u5fd7\u3002 \u6709\u5173\u63a8\u7406\u901f\u5ea6\u7684\u6bd4\u8f83\uff0c\u8bf7\u53c2\u8003 \u6b64 PR\u3002</p> <p>\u8b66\u544a</p> <p><code>compile</code> \u9009\u9879\u5728 Apple Silicon \u8bbe\u5907\u4e0a\u5c1a\u672a\u6b63\u5f0f\u652f\u6301\uff0c\u56e0\u6b64\u63a8\u7406\u901f\u5ea6\u6ca1\u6709\u63d0\u5347\u7684\u4fdd\u8bc1\u3002</p> <pre><code># create a python 3.10 virtual environment, you can also use virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n# install pytorch\npip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n# install fish-speech\npip install -e .[stable]\n</code></pre>"},{"location":"zh/#docker","title":"Docker \u914d\u7f6e","text":"<ol> <li> <p>\u5b89\u88c5 NVIDIA Container Toolkit\uff1a</p> <p>Docker \u5982\u679c\u60f3\u4f7f\u7528 GPU \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u9700\u8981\u5b89\u88c5 NVIDIA Container Toolkit \uff1a</p> <p>\u5bf9\u4e8e Ubuntu \u7528\u6237\uff1a</p> <pre><code># \u6dfb\u52a0\u8fdc\u7a0b\u4ed3\u5e93\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n# \u5b89\u88c5 nvidia-container-toolkit\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n# \u91cd\u542f Docker \u670d\u52a1\nsudo systemctl restart docker\n</code></pre> <p>\u5bf9\u4e8e\u4f7f\u7528\u5176\u4ed6 Linux \u53d1\u884c\u7248\u7684\u7528\u6237\uff0c\u5b89\u88c5\u6307\u5357\u8bf7\u53c2\u8003\uff1aNVIDIA Container Toolkit Install-guide\u3002</p> <p>\u6ce8\uff1a\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7684\u7528\u6237\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u4f7f\u7528\u4ee3\u7406\u6765\u5b8c\u6210\u76f8\u5173\u5de5\u5177\u7684\u5b89\u88c5\u3002</p> </li> <li> <p>\u62c9\u53d6\u5e76\u8fd0\u884c fish-speech \u955c\u50cf</p> <pre><code># \u62c9\u53d6\u955c\u50cf\ndocker pull fishaudio/fish-speech:latest-dev\n# \u8fd0\u884c\u955c\u50cf\ndocker run -it \\\n    --name fish-speech \\\n    --gpus all \\\n    -p 7860:7860 \\\n    fishaudio/fish-speech:latest-dev \\\n    zsh\n# \u5982\u679c\u9700\u8981\u4f7f\u7528\u5176\u4ed6\u7aef\u53e3\uff0c\u8bf7\u4fee\u6539 -p \u53c2\u6570\u4e3a YourPort:7860\n</code></pre> </li> <li> <p>\u4e0b\u8f7d\u6a21\u578b\u4f9d\u8d56</p> <p>\u786e\u4fdd\u60a8\u5728 docker \u5bb9\u5668\u5185\u7684\u7ec8\u7aef\uff0c\u7136\u540e\u518d\u4ece\u6211\u4eec\u7684 huggingface \u4ed3\u5e93\u4e0b\u8f7d\u6240\u9700\u7684 <code>vqgan</code> \u548c <code>llama</code> \u6a21\u578b\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7528\u6237\uff0c\u53ef\u4ee5\u901a\u8fc7\u955c\u50cf\u7ad9\u4e0b\u8f7d\u3002</p> <pre><code>HF_ENDPOINT=https://hf-mirror.com huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> </li> <li> <p>\u914d\u7f6e\u73af\u5883\u53d8\u91cf\uff0c\u8bbf\u95ee WebUI</p> <p>\u5728 docker \u5bb9\u5668\u5185\u7684\u7ec8\u7aef\uff0c\u8f93\u5165 <code>export GRADIO_SERVER_NAME=\"0.0.0.0\"</code> \uff0c\u4ece\u800c\u8ba9\u5916\u90e8\u53ef\u4ee5\u8bbf\u95ee docker \u5185\u7684 gradio \u670d\u52a1\u3002 \u63a5\u7740\u5728 docker \u5bb9\u5668\u5185\u7684\u7ec8\u7aef\uff0c\u8f93\u5165 <code>python tools/webui.py</code> \u5373\u53ef\u5f00\u542f WebUI \u670d\u52a1\u3002</p> <p>\u5982\u679c\u662f WSL \u6216\u8005\u662f MacOS \uff0c\u8bbf\u95ee http://localhost:7860 \u5373\u53ef\u6253\u5f00 WebUI \u754c\u9762\u3002</p> <p>\u5982\u679c\u662f\u90e8\u7f72\u5728\u670d\u52a1\u5668\u4e0a\uff0c\u66f4\u6362 localhost \u4e3a\u60a8\u7684\u670d\u52a1\u5668 ip \u5373\u53ef\u3002</p> </li> </ol>"},{"location":"zh/#_3","title":"\u66f4\u65b0\u65e5\u5fd7","text":"<ul> <li>2024/09/10: \u66f4\u65b0\u4e86 Fish-Speech \u5230 1.4, \u589e\u52a0\u4e86\u6570\u636e\u96c6\u5927\u5c0f\uff0c quantizer n_groups 4 -&gt; 8.</li> <li>2024/07/02: \u66f4\u65b0\u4e86 Fish-Speech \u5230 1.2 \u7248\u672c\uff0c\u79fb\u9664 VITS Decoder\uff0c\u540c\u65f6\u6781\u5927\u5e45\u5ea6\u63d0\u5347 zero-shot \u80fd\u529b.</li> <li>2024/05/10: \u66f4\u65b0\u4e86 Fish-Speech \u5230 1.1 \u7248\u672c\uff0c\u5f15\u5165\u4e86 VITS Decoder \u6765\u964d\u4f4e\u53e3\u80e1\u548c\u63d0\u9ad8\u97f3\u8272\u76f8\u4f3c\u5ea6.</li> <li>2024/04/22: \u5b8c\u6210\u4e86 Fish-Speech 1.0 \u7248\u672c, \u5927\u5e45\u4fee\u6539\u4e86 VQGAN \u548c LLAMA \u6a21\u578b.</li> <li>2023/12/28: \u6dfb\u52a0\u4e86 <code>lora</code> \u5fae\u8c03\u652f\u6301.</li> <li>2023/12/27: \u6dfb\u52a0\u4e86 <code>gradient checkpointing</code>, <code>causual sampling</code> \u548c <code>flash-attn</code> \u652f\u6301.</li> <li>2023/12/19: \u66f4\u65b0\u4e86 Webui \u548c HTTP API.</li> <li>2023/12/18: \u66f4\u65b0\u4e86\u5fae\u8c03\u6587\u6863\u548c\u76f8\u5173\u4f8b\u5b50.</li> <li>2023/12/17: \u66f4\u65b0\u4e86 <code>text2semantic</code> \u6a21\u578b, \u652f\u6301\u65e0\u97f3\u7d20\u6a21\u5f0f.</li> <li>2023/12/13: \u6d4b\u8bd5\u7248\u53d1\u5e03, \u5305\u542b VQGAN \u6a21\u578b\u548c\u4e00\u4e2a\u57fa\u4e8e LLAMA \u7684\u8bed\u8a00\u6a21\u578b (\u53ea\u652f\u6301\u97f3\u7d20).</li> </ul>"},{"location":"zh/#_4","title":"\u81f4\u8c22","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"zh/finetune/","title":"\u5fae\u8c03","text":"<p>\u663e\u7136, \u5f53\u4f60\u6253\u5f00\u8fd9\u4e2a\u9875\u9762\u7684\u65f6\u5019, \u4f60\u5df2\u7ecf\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b zero-shot \u7684\u6548\u679c\u4e0d\u7b97\u6ee1\u610f. \u4f60\u60f3\u8981\u5fae\u8c03\u4e00\u4e2a\u6a21\u578b, \u4f7f\u5f97\u5b83\u5728\u4f60\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d.  </p> <p>\u5728\u76ee\u524d\u7248\u672c\uff0c\u4f60\u53ea\u9700\u8981\u5fae\u8c03'LLAMA'\u90e8\u5206\u5373\u53ef.</p>"},{"location":"zh/finetune/#llama","title":"LLAMA \u5fae\u8c03","text":""},{"location":"zh/finetune/#1","title":"1. \u51c6\u5907\u6570\u636e\u96c6","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>\u4f60\u9700\u8981\u5c06\u6570\u636e\u96c6\u8f6c\u4e3a\u4ee5\u4e0a\u683c\u5f0f, \u5e76\u653e\u5230 <code>data</code> \u4e0b, \u97f3\u9891\u540e\u7f00\u53ef\u4ee5\u4e3a <code>.mp3</code>, <code>.wav</code> \u6216 <code>.flac</code>, \u6807\u6ce8\u6587\u4ef6\u540e\u7f00\u5efa\u8bae\u4e3a <code>.lab</code>.</p> <p>Info</p> <p>\u6807\u6ce8\u6587\u4ef6 <code>.lab</code> \u4ec5\u9700\u5305\u542b\u97f3\u9891\u7684\u8f6c\u5199\u6587\u672c\uff0c\u65e0\u9700\u9075\u5faa\u7279\u6b8a\u683c\u5f0f\u8981\u6c42\u3002\u4f8b\u5982\uff0c\u5982\u679c <code>hi.mp3</code> \u4e2d\u7684\u5185\u5bb9\u662f\u201c\u4f60\u597d\uff0c\u518d\u89c1\u3002\u201d\uff0c\u90a3\u4e48 <code>hi.lab</code> \u6587\u4ef6\u4e2d\u53ea\u9700\u5305\u542b\u4e00\u884c\u6587\u672c\uff1a\u201c\u4f60\u597d\uff0c\u518d\u89c1\u201d\u3002    </p> <p>Warning</p> <p>\u5efa\u8bae\u5148\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u54cd\u5ea6\u5339\u914d, \u4f60\u53ef\u4ee5\u4f7f\u7528 fish-audio-preprocess \u6765\u5b8c\u6210\u8fd9\u4e00\u6b65\u9aa4.  <pre><code>fap loudness-norm data-raw data --clean\n</code></pre></p>"},{"location":"zh/finetune/#2-token","title":"2. \u6279\u91cf\u63d0\u53d6\u8bed\u4e49 token","text":"<p>\u786e\u4fdd\u4f60\u5df2\u7ecf\u4e0b\u8f7d\u4e86 vqgan \u6743\u91cd, \u5982\u679c\u6ca1\u6709, \u8bf7\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7528\u6237, \u53ef\u4f7f\u7528 mirror \u4e0b\u8f7d.</p> <pre><code>HF_ENDPOINT=https://hf-mirror.com huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u968f\u540e\u53ef\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u63d0\u53d6\u8bed\u4e49 token:</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p>\u4f60\u53ef\u4ee5\u8c03\u6574 <code>--num-workers</code> \u548c <code>--batch-size</code> \u6765\u63d0\u9ad8\u63d0\u53d6\u901f\u5ea6, \u4f46\u662f\u8bf7\u6ce8\u610f\u4e0d\u8981\u8d85\u8fc7\u4f60\u7684\u663e\u5b58\u9650\u5236.  </p> <p>\u8be5\u547d\u4ee4\u4f1a\u5728 <code>data</code> \u76ee\u5f55\u4e0b\u521b\u5efa <code>.npy</code> \u6587\u4ef6, \u5982\u4e0b\u6240\u793a:</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"zh/finetune/#3-protobuf","title":"3. \u6253\u5305\u6570\u636e\u96c6\u4e3a protobuf","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>\u547d\u4ee4\u6267\u884c\u5b8c\u6bd5\u540e, \u4f60\u5e94\u8be5\u80fd\u5728 <code>data</code> \u76ee\u5f55\u4e0b\u770b\u5230 <code>protos</code> \u6587\u4ef6.</p>"},{"location":"zh/finetune/#4-lora","title":"4. \u6700\u540e, \u4f7f\u7528 LoRA \u8fdb\u884c\u5fae\u8c03","text":"<p>\u540c\u6837\u7684, \u8bf7\u786e\u4fdd\u4f60\u5df2\u7ecf\u4e0b\u8f7d\u4e86 <code>LLAMA</code> \u6743\u91cd, \u5982\u679c\u6ca1\u6709, \u8bf7\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7528\u6237, \u53ef\u4f7f\u7528 mirror \u4e0b\u8f7d.</p> <pre><code>HF_ENDPOINT=https://hf-mirror.com huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u6700\u540e, \u4f60\u53ef\u4ee5\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8\u5fae\u8c03:</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p>\u4f60\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539 <code>fish_speech/configs/text2semantic_finetune.yaml</code> \u6765\u4fee\u6539\u8bad\u7ec3\u53c2\u6570\u5982 <code>batch_size</code>, <code>gradient_accumulation_steps</code> \u7b49, \u6765\u9002\u5e94\u4f60\u7684\u663e\u5b58.</p> <p>Note</p> <p>\u5bf9\u4e8e Windows \u7528\u6237, \u4f60\u53ef\u4ee5\u4f7f\u7528 <code>trainer.strategy.process_group_backend=gloo</code> \u6765\u907f\u514d <code>nccl</code> \u7684\u95ee\u9898.</p> <p>\u8bad\u7ec3\u7ed3\u675f\u540e, \u4f60\u53ef\u4ee5\u53c2\u8003 \u63a8\u7406 \u90e8\u5206\u6765\u6d4b\u8bd5\u4f60\u7684\u6a21\u578b.</p> <p>Info</p> <p>\u9ed8\u8ba4\u914d\u7f6e\u4e0b, \u57fa\u672c\u53ea\u4f1a\u5b66\u5230\u8bf4\u8bdd\u4eba\u7684\u53d1\u97f3\u65b9\u5f0f, \u800c\u4e0d\u5305\u542b\u97f3\u8272, \u4f60\u4f9d\u7136\u9700\u8981\u4f7f\u7528 prompt \u6765\u4fdd\u8bc1\u97f3\u8272\u7684\u7a33\u5b9a\u6027. \u5982\u679c\u4f60\u60f3\u8981\u5b66\u5230\u97f3\u8272, \u8bf7\u5c06\u8bad\u7ec3\u6b65\u6570\u8c03\u5927, \u4f46\u8fd9\u6709\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8fc7\u62df\u5408. </p> <p>\u8bad\u7ec3\u5b8c\u6210\u540e, \u4f60\u9700\u8981\u5148\u5c06 loRA \u7684\u6743\u91cd\u8f6c\u4e3a\u666e\u901a\u6743\u91cd, \u7136\u540e\u518d\u8fdb\u884c\u63a8\u7406.</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>\u4f60\u4e5f\u53ef\u4ee5\u5c1d\u8bd5\u5176\u4ed6\u7684 checkpoint, \u6211\u4eec\u5efa\u8bae\u4f60\u4f7f\u7528\u6700\u65e9\u7684\u6ee1\u8db3\u4f60\u8981\u6c42\u7684 checkpoint, \u4ed6\u4eec\u901a\u5e38\u5728 OOD \u4e0a\u8868\u73b0\u66f4\u597d.</p>"},{"location":"zh/inference/","title":"\u63a8\u7406","text":"<p>\u63a8\u7406\u652f\u6301\u547d\u4ee4\u884c, http api, \u4ee5\u53ca webui \u4e09\u79cd\u65b9\u5f0f.</p> <p>Note</p> <p>\u603b\u7684\u6765\u8bf4, \u63a8\u7406\u5206\u4e3a\u51e0\u4e2a\u90e8\u5206:</p> <ol> <li>\u7ed9\u5b9a\u4e00\u6bb5 ~10 \u79d2\u7684\u8bed\u97f3, \u5c06\u5b83\u7528 VQGAN \u7f16\u7801.</li> <li>\u5c06\u7f16\u7801\u540e\u7684\u8bed\u4e49 token \u548c\u5bf9\u5e94\u6587\u672c\u8f93\u5165\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4f8b\u5b50.</li> <li>\u7ed9\u5b9a\u4e00\u6bb5\u65b0\u6587\u672c, \u8ba9\u6a21\u578b\u751f\u6210\u5bf9\u5e94\u7684\u8bed\u4e49 token.</li> <li>\u5c06\u751f\u6210\u7684\u8bed\u4e49 token \u8f93\u5165 VQGAN \u89e3\u7801, \u751f\u6210\u5bf9\u5e94\u7684\u8bed\u97f3.</li> </ol>"},{"location":"zh/inference/#_2","title":"\u547d\u4ee4\u884c\u63a8\u7406","text":"<p>\u4ece\u6211\u4eec\u7684 huggingface \u4ed3\u5e93\u4e0b\u8f7d\u6240\u9700\u7684 <code>vqgan</code> \u548c <code>llama</code> \u6a21\u578b\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7528\u6237\uff0c\u53ef\u4f7f\u7528 mirror \u4e0b\u8f7d\u3002</p> <pre><code>HF_ENDPOINT=https://hf-mirror.com huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"zh/inference/#1-prompt","title":"1. \u4ece\u8bed\u97f3\u751f\u6210 prompt:","text":"<p>Note</p> <p>\u5982\u679c\u4f60\u6253\u7b97\u8ba9\u6a21\u578b\u968f\u673a\u9009\u62e9\u97f3\u8272, \u4f60\u53ef\u4ee5\u8df3\u8fc7\u8fd9\u4e00\u6b65.</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>\u4f60\u5e94\u8be5\u80fd\u5f97\u5230\u4e00\u4e2a <code>fake.npy</code> \u6587\u4ef6.</p>"},{"location":"zh/inference/#2-token","title":"2. \u4ece\u6587\u672c\u751f\u6210\u8bed\u4e49 token:","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"\u8981\u8f6c\u6362\u7684\u6587\u672c\" \\\n    --prompt-text \"\u4f60\u7684\u53c2\u8003\u6587\u672c\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>\u8be5\u547d\u4ee4\u4f1a\u5728\u5de5\u4f5c\u76ee\u5f55\u4e0b\u521b\u5efa <code>codes_N</code> \u6587\u4ef6, \u5176\u4e2d N \u662f\u4ece 0 \u5f00\u59cb\u7684\u6574\u6570.</p> <p>Note</p> <p>\u60a8\u53ef\u80fd\u5e0c\u671b\u4f7f\u7528 <code>--compile</code> \u6765\u878d\u5408 cuda \u5185\u6838\u4ee5\u5b9e\u73b0\u66f4\u5feb\u7684\u63a8\u7406 (~30 \u4e2a token/\u79d2 -&gt; ~500 \u4e2a token/\u79d2). \u5bf9\u5e94\u7684, \u5982\u679c\u4f60\u4e0d\u6253\u7b97\u4f7f\u7528\u52a0\u901f, \u4f60\u53ef\u4ee5\u6ce8\u91ca\u6389 <code>--compile</code> \u53c2\u6570.</p> <p>Info</p> <p>\u5bf9\u4e8e\u4e0d\u652f\u6301 bf16 \u7684 GPU, \u4f60\u53ef\u80fd\u9700\u8981\u4f7f\u7528 <code>--half</code> \u53c2\u6570.</p>"},{"location":"zh/inference/#3-token","title":"3. \u4ece\u8bed\u4e49 token \u751f\u6210\u4eba\u58f0:","text":""},{"location":"zh/inference/#vqgan","title":"VQGAN \u89e3\u7801","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"zh/inference/#http-api","title":"HTTP API \u63a8\u7406","text":"<p>\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8 HTTP \u670d\u52a1:</p> <pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>\u5982\u679c\u4f60\u60f3\u8981\u52a0\u901f\u63a8\u7406\uff0c\u53ef\u4ee5\u52a0\u4e0a<code>--compile</code>\u53c2\u6570\u3002</p> <p>\u63a8\u8350\u4e2d\u56fd\u5927\u9646\u7528\u6237\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8 HTTP \u670d\u52a1: <pre><code>HF_ENDPOINT=https://hf-mirror.com python -m ...(\u540c\u4e0a)\n</code></pre></p> <p>\u968f\u540e, \u4f60\u53ef\u4ee5\u5728 <code>http://127.0.0.1:8080/</code> \u4e2d\u67e5\u770b\u5e76\u6d4b\u8bd5 API.</p> <p>\u4e0b\u9762\u662f\u4f7f\u7528<code>tools/post_api.py</code>\u53d1\u9001\u8bf7\u6c42\u7684\u793a\u4f8b\u3002</p> <pre><code>python -m tools.post_api \\\n    --text \"\u8981\u8f93\u5165\u7684\u6587\u672c\" \\\n    --reference_audio \"\u53c2\u8003\u97f3\u9891\u8def\u5f84\" \\\n    --reference_text \"\u53c2\u8003\u97f3\u9891\u7684\u6587\u672c\u5185\u5bb9\" \\\n    --streaming True\n</code></pre> <p>\u4e0a\u9762\u7684\u547d\u4ee4\u8868\u793a\u6309\u7167\u53c2\u8003\u97f3\u9891\u7684\u4fe1\u606f\uff0c\u5408\u6210\u6240\u9700\u7684\u97f3\u9891\u5e76\u6d41\u5f0f\u8fd4\u56de.</p> <p>\u4e0b\u9762\u7684\u793a\u4f8b\u5c55\u793a\u4e86\uff0c \u53ef\u4ee5\u4e00\u6b21\u4f7f\u7528\u591a\u4e2a <code>\u53c2\u8003\u97f3\u9891\u8def\u5f84</code> \u548c <code>\u53c2\u8003\u97f3\u9891\u7684\u6587\u672c\u5185\u5bb9</code>\u3002\u5728\u547d\u4ee4\u91cc\u7528\u7a7a\u683c\u9694\u5f00\u5373\u53ef\u3002 <pre><code>python -m tools.post_api \\\n    --text \"\u8981\u8f93\u5165\u7684\u6587\u672c\" \\\n    --reference_audio \"\u53c2\u8003\u97f3\u9891\u8def\u5f841\" \"\u53c2\u8003\u97f3\u9891\u8def\u5f842\" \\\n    --reference_text \"\u53c2\u8003\u97f3\u9891\u7684\u6587\u672c\u5185\u5bb91\" \"\u53c2\u8003\u97f3\u9891\u7684\u6587\u672c\u5185\u5bb92\"\\\n    --streaming False \\\n    --output \"generated\" \\\n    --format \"mp3\"\n</code></pre></p> <p>\u4e0a\u9762\u7684\u547d\u4ee4\u8868\u793a\u6309\u7167\u591a\u4e2a\u53c2\u8003\u97f3\u9891\u7684\u4fe1\u606f\uff0c\u5408\u6210\u6240\u9700\u7684<code>MP3</code>\u683c\u5f0f\u97f3\u9891\uff0c\u5e76\u4fdd\u5b58\u4e3a\u5f53\u524d\u76ee\u5f55\u7684<code>generated.mp3</code>\u6587\u4ef6\u3002</p> <p>\u8fd8\u53ef\u4ee5\u7528<code>--reference_id</code>(\u4ec5\u80fd\u7528\u4e00\u4e2a)\u6765\u4ee3\u66ff<code>--reference_audio</code>\u548c<code>--reference_text</code>, \u524d\u63d0\u662f\u5728\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\u521b\u5efa<code>references/&lt;your reference_id&gt;</code>\u6587\u4ef6\u5939\uff0c \u91cc\u9762\u653e\u4e0a\u4efb\u610f\u5bf9\u97f3\u9891\u4e0e\u6807\u6ce8\u6587\u672c\u3002 \u76ee\u524d\u652f\u6301\u7684\u53c2\u8003\u97f3\u9891\u6700\u591a\u52a0\u8d77\u6765\u603b\u65f6\u957f90s\u3002</p> <p>Info</p> <p>\u8981\u4e86\u89e3\u6709\u5173\u53ef\u7528\u53c2\u6570\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u53ef\u4ee5\u4f7f\u7528\u547d\u4ee4<code>python -m tools.post_api -h</code></p>"},{"location":"zh/inference/#gui","title":"GUI \u63a8\u7406","text":"<p>\u4e0b\u8f7d\u5ba2\u6237\u7aef</p>"},{"location":"zh/inference/#webui","title":"WebUI \u63a8\u7406","text":"<p>\u4f60\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8 WebUI:</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>\u5982\u679c\u4f60\u60f3\u8981\u52a0\u901f\u63a8\u7406\uff0c\u53ef\u4ee5\u52a0\u4e0a<code>--compile</code>\u53c2\u6570\u3002</p> <p>Note</p> <p>\u4f60\u53ef\u4ee5\u63d0\u524d\u5c06label\u6587\u4ef6\u548c\u53c2\u8003\u97f3\u9891\u6587\u4ef6\u4fdd\u5b58\u5230\u4e3b\u76ee\u5f55\u4e0b\u7684 <code>references</code> \u6587\u4ef6\u5939\uff08\u9700\u8981\u81ea\u884c\u521b\u5efa\uff09\uff0c\u8fd9\u6837\u4f60\u53ef\u4ee5\u76f4\u63a5\u5728WebUI\u4e2d\u8c03\u7528\u5b83\u4eec\u3002</p> <p>Note</p> <p>\u4f60\u53ef\u4ee5\u4f7f\u7528 Gradio \u73af\u5883\u53d8\u91cf, \u5982 <code>GRADIO_SHARE</code>, <code>GRADIO_SERVER_PORT</code>, <code>GRADIO_SERVER_NAME</code> \u6765\u914d\u7f6e WebUI.</p> <p>\u795d\u5927\u5bb6\u73a9\u5f97\u5f00\u5fc3!</p>"},{"location":"zh/samples/","title":"\u4f8b\u5b50","text":"<p>v1.4 \u6f14\u793a\u5df2\u66f4\u65b0\u81f3\u6b64\u5904\u3002</p> <p>v1.2 \u7684\u6837\u672c\u53ef\u4ee5\u5728 Bilibili \u89c2\u770b\u3002</p> <p>\u4ee5\u4e0b\u6837\u672c\u6765\u81ea v1.1 \u7248\u672c\u7684\u6a21\u578b\u3002</p>"},{"location":"zh/samples/#1","title":"\u4e2d\u6587\u53e5\u5b50 1","text":"<pre><code>\u4eba\u95f4\u706f\u706b\u5012\u6620\u6e56\u4e2d\uff0c\u5979\u7684\u6e34\u671b\u8ba9\u9759\u6c34\u6cdb\u8d77\u6d9f\u6f2a\u3002\u82e5\u4ee3\u4ef7\u53ea\u662f\u5b64\u72ec\uff0c\u90a3\u5c31\u8ba9\u8fd9\u4efd\u613f\u671b\u8086\u610f\u6d41\u6dcc\u3002\n\u6d41\u5165\u5979\u6240\u6ce8\u89c6\u7684\u4e16\u95f4\uff0c\u4e5f\u6d41\u5165\u5979\u5982\u6e56\u6c34\u822c\u6f84\u6f88\u7684\u76ee\u5149\u3002\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u7eb3\u897f\u59b2 (\u539f\u795e) \u949f\u79bb (\u539f\u795e) \u8299\u5b81\u5a1c (\u539f\u795e) \u968f\u673a\u8bf4\u8bdd\u4eba 1  -  \u968f\u673a\u8bf4\u8bdd\u4eba 2  -"},{"location":"zh/samples/#2","title":"\u4e2d\u6587\u53e5\u5b50 2","text":"<pre><code>\u4f60\u4eec\u8fd9\u4e2a\u662f\u4ec0\u4e48\u7fa4\u554a\uff0c\u4f60\u4eec\u8fd9\u662f\u5bb3\u4eba\u4e0d\u6d45\u554a\u4f60\u4eec\u8fd9\u4e2a\u7fa4\uff01\u8c01\u662f\u7fa4\u4e3b\uff0c\u51fa\u6765\uff01\u771f\u7684\u592a\u8fc7\u5206\u4e86\u3002\u4f60\u4eec\u641e\u8fd9\u4e2a\u7fa4\u5e72\u4ec0\u4e48\uff1f\n\u6211\u513f\u5b50\u6bcf\u4e00\u79d1\u7684\u6210\u7ee9\u90fd\u4e0d\u8fc7\u90a3\u4e2a\u5e73\u5747\u5206\u5450\uff0c\u4ed6\u73b0\u5728\u521d\u4e8c\uff0c\u4f60\u53eb\u6211\u513f\u5b50\u600e\u4e48\u529e\u554a\uff1f\u4ed6\u73b0\u5728\u8fd8\u4e0d\u5230\u9ad8\u4e2d\u554a\uff1f\n\u4f60\u4eec\u5bb3\u6b7b\u6211\u513f\u5b50\u4e86\uff01\u5feb\u70b9\u51fa\u6765\u4f60\u8fd9\u4e2a\u7fa4\u4e3b\uff01\u518d\u8fd9\u6837\u6211\u53bb\u62a5\u8b66\u4e86\u554a\uff01\u6211\u8ddf\u4f60\u4eec\u8bf4\u4f60\u4eec\u8fd9\u4e00\u5e2e\u4eba\u554a\uff0c\u4e00\u5929\u5230\u665a\u554a\uff0c\n\u641e\u8fd9\u4e9b\u4ec0\u4e48\u6e38\u620f\u554a\uff0c\u52a8\u6f2b\u554a\uff0c\u4f1a\u5bb3\u6b7b\u4f60\u4eec\u7684\uff0c\u4f60\u4eec\u6ca1\u6709\u524d\u9014\u6211\u8ddf\u4f60\u8bf4\u3002\u4f60\u4eec\u8fd9\u4e5d\u767e\u591a\u4e2a\u4eba\uff0c\u597d\u597d\u5b66\u4e60\u4e0d\u597d\u5417\uff1f\n\u4e00\u5929\u5230\u665a\u5728\u4e0a\u7f51\u3002\u6709\u4ec0\u4e48\u610f\u601d\u554a\uff1f\u9ebb\u70e6\u4f60\u91cd\u89c6\u4e00\u4e0b\u4f60\u4eec\u7684\u751f\u6d3b\u7684\u76ee\u6807\u554a\uff1f\u6709\u4e00\u70b9\u5b66\u4e60\u76ee\u6807\u884c\u4e0d\u884c\uff1f\u4e00\u5929\u5230\u665a\u4e0a\u7f51\u662f\u4e0d\u662f\u4eba\u554a\uff1f\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u7eb3\u897f\u59b2 (\u539f\u795e) \u968f\u673a\u8bf4\u8bdd\u4eba  -"},{"location":"zh/samples/#3","title":"\u4e2d\u6587\u53e5\u5b50 3","text":"<pre><code>\u5927\u5bb6\u597d\uff0c\u6211\u662f Fish Audio \u5f00\u53d1\u7684\u5f00\u6e90\u6587\u672c\u8f6c\u8bed\u97f3\u6a21\u578b\u3002\u7ecf\u8fc7\u5341\u4e94\u4e07\u5c0f\u65f6\u7684\u6570\u636e\u8bad\u7ec3\uff0c\n\u6211\u5df2\u7ecf\u80fd\u591f\u719f\u7ec3\u638c\u63e1\u4e2d\u6587\u3001\u65e5\u8bed\u548c\u82f1\u8bed\uff0c\u6211\u7684\u8bed\u8a00\u5904\u7406\u80fd\u529b\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u58f0\u97f3\u8868\u73b0\u5f62\u5f0f\u4e30\u5bcc\u591a\u53d8\u3002\n\u4f5c\u4e3a\u4e00\u4e2a\u4ec5\u6709\u4ebf\u7ea7\u53c2\u6570\u7684\u6a21\u578b\uff0c\u6211\u76f8\u4fe1\u793e\u533a\u6210\u5458\u80fd\u591f\u5728\u4e2a\u4eba\u8bbe\u5907\u4e0a\u8f7b\u677e\u8fd0\u884c\u548c\u5fae\u8c03\uff0c\u8ba9\u6211\u6210\u4e3a\u60a8\u7684\u79c1\u4eba\u8bed\u97f3\u52a9\u624b\u3002\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba  -"},{"location":"zh/samples/#1_1","title":"\u82f1\u6587\u53e5\u5b50 1","text":"<pre><code>In the realm of advanced technology, the evolution of artificial intelligence stands as a \nmonumental achievement. This dynamic field, constantly pushing the boundaries of what \nmachines can do, has seen rapid growth and innovation. From deciphering complex data \npatterns to driving cars autonomously, AI's applications are vast and diverse.\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba 1  -  \u968f\u673a\u8bf4\u8bdd\u4eba 2  -"},{"location":"zh/samples/#2_1","title":"\u82f1\u6587\u53e5\u5b50 2","text":"<pre><code>Hello everyone, I am an open-source text-to-speech model developed by \nFish Audio. After training with 150,000 hours of data, I have become proficient \nin Chinese, Japanese, and English, and my language processing abilities \nare close to human level. My voice is capable of a wide range of expressions. \nAs a model with only hundreds of millions of parameters, I believe community \nmembers can easily run and fine-tune me on their personal devices, allowing \nme to serve as your personal voice assistant.\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba  -"},{"location":"zh/samples/#1_2","title":"\u65e5\u6587\u53e5\u5b50 1","text":"<pre><code>\u5148\u9032\u6280\u8853\u306e\u9818\u57df\u306b\u304a\u3044\u3066\u3001\u4eba\u5de5\u77e5\u80fd\u306e\u9032\u5316\u306f\u753b\u671f\u7684\u306a\u6210\u679c\u3068\u3057\u3066\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\u5e38\u306b\u6a5f\u68b0\u304c\u3067\u304d\u308b\u3053\u3068\u306e\u9650\u754c\u3092\n\u62bc\u3057\u5e83\u3052\u3066\u3044\u308b\u3053\u306e\u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u5206\u91ce\u306f\u3001\u6025\u901f\u306a\u6210\u9577\u3068\u9769\u65b0\u3092\u898b\u305b\u3066\u3044\u307e\u3059\u3002\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30d1\u30bf\u30fc\u30f3\u306e\u89e3\u8aad\u304b\n\u3089\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u64cd\u7e26\u307e\u3067\u3001AI\u306e\u5fdc\u7528\u306f\u5e83\u7bc4\u56f2\u306b\u53ca\u3073\u307e\u3059\u3002\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba 1  -  \u968f\u673a\u8bf4\u8bdd\u4eba 2  -"},{"location":"zh/samples/#2_2","title":"\u65e5\u6587\u53e5\u5b50 2","text":"<pre><code>\u7686\u3055\u3093\u3001\u3053\u3093\u306b\u3061\u306f\u3002\u79c1\u306f\u30d5\u30a3\u30c3\u30b7\u30e5\u30aa\u30fc\u30c7\u30a3\u30aa\u306b\u3088\u3063\u3066\u958b\u767a\u3055\u308c\u305f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u30c6\n\u30ad\u30b9\u30c8\u304b\u3089\u97f3\u58f0\u3078\u306e\u5909\u63db\u30e2\u30c7\u30eb\u3067\u3059\u300215\u4e07\u6642\u9593\u306e\u30c7\u30fc\u30bf\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u7d4c\u3066\u3001\n\u4e2d\u56fd\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u82f1\u8a9e\u3092\u719f\u77e5\u3057\u3066\u304a\u308a\u3001\u8a00\u8a9e\u51e6\u7406\u80fd\u529b\u306f\u4eba\u9593\u306b\u8fd1\u3044\u30ec\u30d9\u30eb\u3067\u3059\u3002\n\u58f0\u306e\u8868\u73fe\u3082\u591a\u5f69\u3067\u8c4a\u304b\u3067\u3059\u3002\u6570\u5104\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u3053\u306e\u30e2\u30c7\u30eb\u306f\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\n\u306e\u30e1\u30f3\u30d0\u30fc\u304c\u500b\u4eba\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u7c21\u5358\u306b\u5b9f\u884c\u3057\u3001\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\n\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u79c1\u3092\u500b\u4eba\u306e\u97f3\u58f0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u6d3b\u7528\u3067\u304d\u307e\u3059\u3002\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba  -"},{"location":"zh/start_agent/","title":"\u542f\u52a8 Agent","text":""},{"location":"zh/start_agent/#_1","title":"\u8981\u6c42","text":"<ul> <li>GPU \u663e\u5b58: \u81f3\u5c11 8GB\uff08\u5728\u91cf\u5316\u7684\u6761\u4ef6\u4e0b\uff09\uff0c\u63a8\u8350 16GB \u53ca\u4ee5\u4e0a</li> <li>\u786c\u76d8\u4f7f\u7528\u91cf: 10GB</li> </ul>"},{"location":"zh/start_agent/#_2","title":"\u4e0b\u8f7d\u6a21\u578b","text":"<p>\u4f60\u53ef\u4ee5\u6267\u884c\u4e0b\u9762\u7684\u8bed\u53e5\u6765\u83b7\u53d6\u6a21\u578b:</p> <pre><code>huggingface-cli download fishaudio/fish-agent-v0.1-3b --local-dir checkpoints/fish-agent-v0.1-3b\n</code></pre> <p>\u5982\u679c\u4f60\u5904\u4e8e\u56fd\u5185\u7f51\u7edc\uff0c\u9996\u5148\u6267\u884c:</p> <pre><code>export HF_ENDPOINT=https://hf-mirror.com\n</code></pre> <p>\u628a\u4ed6\u4eec\u653e\u8fdb\u540d\u4e3a 'checkpoints' \u7684\u6587\u4ef6\u5939\u5185\u3002</p> <p>\u4f60\u540c\u6837\u9700\u8981 fish-speech \u7684\u6a21\u578b\uff0c\u5173\u4e8e\u5982\u4f55\u83b7\u53d6 fish-speech \u6a21\u578b\u8bf7\u67e5\u770binference\u3002</p> <p>\u5b8c\u6210\u540e\u4f60\u7684 checkpoints \u6587\u4ef6\u5939\u4e2d\u4f1a\u6709\u4e24\u4e2a\u5b50\u6587\u4ef6\u5939\uff1a<code>checkpoints/fish-speech-1.4</code> \u548c <code>checkpoints/fish-agent-v0.1-3b</code>\u3002</p>"},{"location":"zh/start_agent/#environment-prepare","title":"Environment Prepare","text":"<p>\u5982\u679c\u4f60\u5df2\u7ecf\u6709\u4e86 Fish-Speech \u73af\u5883\uff0c\u4f60\u53ef\u4ee5\u5728\u5b89\u88c5\u4e0b\u9762\u7684\u5305\u7684\u524d\u63d0\u4e0b\u76f4\u63a5\u4f7f\u7528\uff1a</p> <pre><code>pip install cachetools\n</code></pre> <p>Note</p> <p>\u8bf7\u4f7f\u7528\u5c0f\u4e8e 3.12 \u7684 python \u7248\u672c\u4f7f compile \u53ef\u7528</p> <p>\u5982\u679c\u4f60\u6ca1\u6709 Fish-Speech \u73af\u5883\uff0c\u8bf7\u6267\u884c\u4e0b\u9762\u7684\u8bed\u53e5\u6765\u6784\u9020\u4f60\u7684\u73af\u5883\uff1a</p> <pre><code>sudo apt-get install portaudio19-dev\n\npip install -e .[stable]\n</code></pre>"},{"location":"zh/start_agent/#agent_1","title":"\u94fe\u63a5 Agent.","text":"<p>\u4f60\u9700\u8981\u4f7f\u7528\u4ee5\u4e0b\u6307\u4ee4\u6765\u6784\u5efa fish-agent</p> <pre><code>python -m tools.api --llama-checkpoint-path checkpoints/fish-agent-v0.1-3b/ --mode agent --compile\n</code></pre> <p><code>--compile</code>\u53ea\u80fd\u5728\u5c0f\u4e8e 3.12 \u7248\u672c\u7684 Python \u4f7f\u7528\uff0c\u8fd9\u4e2a\u529f\u80fd\u53ef\u4ee5\u6781\u5927\u7a0b\u5ea6\u4e0a\u63d0\u9ad8\u751f\u6210\u901f\u5ea6\u3002</p> <p>\u4f60\u9700\u8981\u54e6\u6ce8\u610f compile \u9700\u8981\u8fdb\u884c\u4e00\u6bb5\u65f6\u95f4.</p> <p>\u7136\u540e\u542f\u52a8\u53e6\u4e00\u4e2a\u7ec8\u7aef\u5e76\u6267\u884c:</p> <pre><code>python -m tools.e2e_webui\n</code></pre> <p>\u8fd9\u4f1a\u5728\u8bbe\u5907\u4e0a\u521b\u5efa\u4e00\u4e2a Gradio WebUI\u3002</p> <p>\u6bcf\u5f53\u8fdb\u884c\u7b2c\u4e00\u8f6e\u5bf9\u8bdd\u7684\u65f6\u5019\uff0c\u6a21\u578b\u9700\u8981 compile \u4e00\u6bb5\u65f6\u95f4\uff0c\u8bf7\u8010\u5fc3\u7b49\u5f85</p>"},{"location":"zh/start_agent/#gradio-webui","title":"Gradio Webui","text":"<p>\u73a9\u5f97\u5f00\u5fc3\uff01</p>"},{"location":"zh/start_agent/#performance","title":"Performance","text":"<p>\u5728\u6211\u4eec\u7684\u6d4b\u8bd5\u73af\u5883\u4e0b\uff0c 4060 laptop GPU \u53ea\u80fd\u521a\u521a\u8fd0\u884c\u8be5\u6a21\u578b\uff0c\u53ea\u6709\u5927\u6982 8 tokens/s\u3002 4090 CPU \u53ef\u4ee5\u5728\u7f16\u8bd1\u540e\u8fbe\u5230 95 tokens/s\uff0c\u6211\u4eec\u63a8\u8350\u4f7f\u7528\u81f3\u5c11 4080 \u4ee5\u4e0a\u7ea7\u522b\u7684 GPU \u6765\u8fbe\u5230\u8f83\u597d\u4f53\u9a8c\u3002</p>"},{"location":"zh/start_agent/#about-agent","title":"About Agent","text":"<p>\u8be5\u6a21\u578b\u4ecd\u5904\u4e8e\u6d4b\u8bd5\u9636\u6bb5\u3002\u5982\u679c\u4f60\u53d1\u73b0\u4e86\u95ee\u9898\uff0c\u8bf7\u7ed9\u6211\u4eec\u63d0 issue \u6216\u8005 pull request\uff0c\u6211\u4eec\u975e\u5e38\u611f\u8c22\u3002</p>"},{"location":"ja/","title":"Fish Speech \u306e\u7d39\u4ecb","text":"<p>Warning</p> <p>\u79c1\u305f\u3061\u306f\u3001\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u306e\u9055\u6cd5\u306a\u4f7f\u7528\u306b\u3064\u3044\u3066\u4e00\u5207\u306e\u8cac\u4efb\u3092\u8ca0\u3044\u307e\u305b\u3093\u3002\u304a\u4f4f\u307e\u3044\u306e\u5730\u57df\u306e DMCA\uff08\u30c7\u30b8\u30bf\u30eb\u30df\u30ec\u30cb\u30a2\u30e0\u8457\u4f5c\u6a29\u6cd5\uff09\u304a\u3088\u3073\u305d\u306e\u4ed6\u306e\u95a2\u9023\u6cd5\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002  \u3053\u306e\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u3068\u30e2\u30c7\u30eb\u306f\u3001CC-BY-NC-SA-4.0 \u30e9\u30a4\u30bb\u30f3\u30b9\u4e0b\u3067\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p> <p> </p>"},{"location":"ja/#_1","title":"\u8981\u4ef6","text":"<ul> <li>GPU \u30e1\u30e2\u30ea: 4GB\uff08\u63a8\u8ad6\u7528\uff09\u30018GB\uff08\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u7528\uff09</li> <li>\u30b7\u30b9\u30c6\u30e0: Linux\u3001Windows</li> </ul>"},{"location":"ja/#windows","title":"Windows\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<p>\u30d7\u30ed\u30d5\u30a7\u30c3\u30b7\u30e7\u30ca\u30eb\u306aWindows\u30e6\u30fc\u30b6\u30fc\u306f\u3001WSL2\u307e\u305f\u306fDocker\u3092\u4f7f\u7528\u3057\u3066\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u3092\u5b9f\u884c\u3059\u308b\u3053\u3068\u3092\u691c\u8a0e\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code># Python 3.10\u306e\u4eee\u60f3\u74b0\u5883\u3092\u4f5c\u6210\uff08virtualenv\u3082\u4f7f\u7528\u53ef\u80fd\uff09\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# PyTorch\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n\n# fish-speech\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\npip3 install -e .\n\n# (\u30a2\u30af\u30bb\u30e9\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u6709\u52b9\u306b\u3059\u308b) triton-windows\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\npip install https://github.com/AnyaCoder/fish-speech/releases/download/v0.1.0/triton_windows-0.1.0-py3-none-any.whl\n</code></pre> <p>\u975e\u30d7\u30ed\u30d5\u30a7\u30c3\u30b7\u30e7\u30ca\u30eb\u306aWindows\u30e6\u30fc\u30b6\u30fc\u306f\u3001Linux\u74b0\u5883\u306a\u3057\u3067\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u4ee5\u4e0b\u306e\u57fa\u672c\u7684\u306a\u65b9\u6cd5\u3092\u691c\u8a0e\u3067\u304d\u307e\u3059\uff08\u30e2\u30c7\u30eb\u30b3\u30f3\u30d1\u30a4\u30eb\u6a5f\u80fd\u3001\u3064\u307e\u308a<code>torch.compile</code>\u3092\u4f7f\u7528\u53ef\u80fd\uff09\uff1a</p> <ol> <li>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u89e3\u51cd\u3059\u308b\u3002</li> <li><code>install_env.bat</code>\u3092\u30af\u30ea\u30c3\u30af\u3057\u3066\u74b0\u5883\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002</li> <li>\u30b3\u30f3\u30d1\u30a4\u30eb\u30a2\u30af\u30bb\u30e9\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u6709\u52b9\u306b\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e\u30b9\u30c6\u30c3\u30d7\u306b\u5f93\u3063\u3066\u304f\u3060\u3055\u3044\uff1a<ol> <li>\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u304b\u3089LLVM\u30b3\u30f3\u30d1\u30a4\u30e9\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\uff1a<ul> <li>LLVM-17.0.6\uff08\u516c\u5f0f\u30b5\u30a4\u30c8\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\uff09</li> <li>LLVM-17.0.6\uff08\u30df\u30e9\u30fc\u30b5\u30a4\u30c8\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\uff09</li> <li><code>LLVM-17.0.6-win64.exe</code>\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u5f8c\u3001\u30c0\u30d6\u30eb\u30af\u30ea\u30c3\u30af\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3001\u9069\u5207\u306a\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5834\u6240\u3092\u9078\u629e\u3057\u3001\u6700\u3082\u91cd\u8981\u306a\u306e\u306f<code>Add Path to Current User</code>\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u9078\u629e\u3057\u3066\u74b0\u5883\u5909\u6570\u3092\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3067\u3059\u3002</li> <li>\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5b8c\u4e86\u3057\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002</li> </ul> </li> <li>\u6b20\u843d\u3057\u3066\u3044\u308b .dll \u306e\u554f\u984c\u3092\u89e3\u6c7a\u3059\u308b\u305f\u3081\u3001Microsoft Visual C++ Redistributable \u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\uff1a<ul> <li>MSVC++ 14.40.33810.0 \u30c0\u30a6\u30f3\u30ed\u30fc\u30c9</li> </ul> </li> <li>Visual Studio Community Edition\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3001MSVC++\u30d3\u30eb\u30c9\u30c4\u30fc\u30eb\u3092\u53d6\u5f97\u3057\u3001LLVM\u306e\u30d8\u30c3\u30c0\u30fc\u30d5\u30a1\u30a4\u30eb\u306e\u4f9d\u5b58\u95a2\u4fc2\u3092\u89e3\u6c7a\u3059\u308b\uff1a<ul> <li>Visual Studio \u30c0\u30a6\u30f3\u30ed\u30fc\u30c9</li> <li>Visual Studio Installer\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u5f8c\u3001Visual Studio Community 2022\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3002</li> <li>\u4e0b\u8a18\u306e\u3088\u3046\u306b\u3001<code>Modify</code>\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3057\u3001<code>C++\u306b\u3088\u308b\u30c7\u30b9\u30af\u30c8\u30c3\u30d7\u958b\u767a</code>\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u9078\u629e\u3057\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3002</li> <li></li> </ul> </li> <li>CUDA Toolkit 12.x\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002</li> </ol> </li> <li><code>start.bat</code>\u3092\u30c0\u30d6\u30eb\u30af\u30ea\u30c3\u30af\u3057\u3066\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u63a8\u8ad6WebUI\u7ba1\u7406\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u958b\u304d\u307e\u3059\u3002\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u3001\u4ee5\u4e0b\u306b\u793a\u3059\u3088\u3046\u306b<code>API_FLAGS</code>\u3092\u4fee\u6b63\u3067\u304d\u307e\u3059\u3002</li> </ol> <p>\u30aa\u30d7\u30b7\u30e7\u30f3</p> <p>\u63a8\u8ad6WebUI\u3092\u8d77\u52d5\u3057\u307e\u3059\u304b\uff1f \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3042\u308b <code>API_FLAGS.txt</code> \u30d5\u30a1\u30a4\u30eb\u3092\u7de8\u96c6\u3057\u3001\u6700\u521d\u306e3\u884c\u3092\u6b21\u306e\u3088\u3046\u306b\u5909\u66f4\u3057\u307e\u3059\uff1a <pre><code>--infer\n# --api\n# --listen ...\n...\n</code></pre></p> <p>\u30aa\u30d7\u30b7\u30e7\u30f3</p> <p>API\u30b5\u30fc\u30d0\u30fc\u3092\u8d77\u52d5\u3057\u307e\u3059\u304b\uff1f \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3042\u308b <code>API_FLAGS.txt</code> \u30d5\u30a1\u30a4\u30eb\u3092\u7de8\u96c6\u3057\u3001\u6700\u521d\u306e3\u884c\u3092\u6b21\u306e\u3088\u3046\u306b\u5909\u66f4\u3057\u307e\u3059\uff1a <pre><code># --infer\n--api\n--listen ...\n...\n</code></pre></p> <p>\u30aa\u30d7\u30b7\u30e7\u30f3</p> <p><code>run_cmd.bat</code> \u3092\u30c0\u30d6\u30eb\u30af\u30ea\u30c3\u30af\u3057\u3066\u3001\u3053\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e conda/python \u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u74b0\u5883\u306b\u5165\u308a\u307e\u3059\u3002</p>"},{"location":"ja/#linux","title":"Linux \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<p>\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001pyproject.toml  \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 <pre><code># python 3.10\u306e\u4eee\u60f3\u74b0\u5883\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002virtualenv\u3082\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# pytorch\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n\n# (Ubuntu / Debian\u30e6\u30fc\u30b6\u30fc) sox + ffmpeg\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\napt install libsox-dev ffmpeg\n\n# (Ubuntu / Debian\u30e6\u30fc\u30b6\u30fc) pyaudio \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\napt install build-essential \\\n    cmake \\\n    libasound-dev \\\n    portaudio19-dev \\\n    libportaudio2 \\\n    libportaudiocpp0\n\n# fish-speech\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\npip3 install -e .[stable]\n</code></pre></p>"},{"location":"ja/#macos-setup","title":"macos setup","text":"<p>\u63a8\u8ad6\u3092MPS\u4e0a\u3067\u884c\u3046\u5834\u5408\u306f\u3001<code>--device mps</code>\u30d5\u30e9\u30b0\u3092\u8ffd\u52a0\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u63a8\u8ad6\u901f\u5ea6\u306e\u6bd4\u8f03\u306f\u3053\u3061\u3089\u306ePR\u3092\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <p>Warning</p> <p>AppleSilicon\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u306f\u3001compile\u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u6b63\u5f0f\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u305b\u3093\u306e\u3067\u3001\u63a8\u8ad6\u901f\u5ea6\u304c\u5411\u4e0a\u3059\u308b\u4fdd\u8a3c\u306f\u3042\u308a\u307e\u305b\u3093\u3002</p> <pre><code># create a python 3.10 virtual environment, you can also use virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n# install pytorch\npip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n# install fish-speech\npip install -e .[stable]\n</code></pre>"},{"location":"ja/#docker","title":"Docker \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<ol> <li> <p>NVIDIA Container Toolkit \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff1a</p> <p>Docker \u3067 GPU \u3092\u4f7f\u7528\u3057\u3066\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3068\u63a8\u8ad6\u3092\u884c\u3046\u306b\u306f\u3001NVIDIA Container Toolkit \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff1a</p> <p>Ubuntu \u30e6\u30fc\u30b6\u30fc\u306e\u5834\u5408\uff1a</p> <pre><code># \u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u8ffd\u52a0\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n# nvidia-container-toolkit \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n# Docker \u30b5\u30fc\u30d3\u30b9\u306e\u518d\u8d77\u52d5\nsudo systemctl restart docker\n</code></pre> <p>\u4ed6\u306e Linux \u30c7\u30a3\u30b9\u30c8\u30ea\u30d3\u30e5\u30fc\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30ac\u30a4\u30c9\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\uff1aNVIDIA Container Toolkit Install-guide\u3002</p> </li> <li> <p>fish-speech \u30a4\u30e1\u30fc\u30b8\u306e\u30d7\u30eb\u3068\u5b9f\u884c</p> <pre><code># \u30a4\u30e1\u30fc\u30b8\u306e\u30d7\u30eb\ndocker pull fishaudio/fish-speech:latest-dev\n# \u30a4\u30e1\u30fc\u30b8\u306e\u5b9f\u884c\ndocker run -it \\\n    --name fish-speech \\\n    --gpus all \\\n    -p 7860:7860 \\\n    fishaudio/fish-speech:latest-dev \\\n    zsh\n# \u4ed6\u306e\u30dd\u30fc\u30c8\u3092\u4f7f\u7528\u3059\u308b\u5834\u5408\u306f\u3001-p \u30d1\u30e9\u30e1\u30fc\u30bf\u3092 YourPort:7860 \u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\n</code></pre> </li> <li> <p>\u30e2\u30c7\u30eb\u306e\u4f9d\u5b58\u95a2\u4fc2\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9</p> <p>Docker \u30b3\u30f3\u30c6\u30ca\u5185\u306e\u30bf\u30fc\u30df\u30ca\u30eb\u306b\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3001huggingface \u30ea\u30dd\u30b8\u30c8\u30ea\u304b\u3089\u5fc5\u8981\u306a <code>vqgan</code> \u3068 <code>llama</code> \u30e2\u30c7\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> </li> <li> <p>\u74b0\u5883\u5909\u6570\u306e\u8a2d\u5b9a\u3068 WebUI \u3078\u306e\u30a2\u30af\u30bb\u30b9</p> <p>Docker \u30b3\u30f3\u30c6\u30ca\u5185\u306e\u30bf\u30fc\u30df\u30ca\u30eb\u3067\u3001<code>export GRADIO_SERVER_NAME=\"0.0.0.0\"</code> \u3068\u5165\u529b\u3057\u3066\u3001\u5916\u90e8\u304b\u3089 Docker \u5185\u306e gradio \u30b5\u30fc\u30d3\u30b9\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u307e\u3059\u3002 \u6b21\u306b\u3001Docker \u30b3\u30f3\u30c6\u30ca\u5185\u306e\u30bf\u30fc\u30df\u30ca\u30eb\u3067 <code>python tools/webui.py</code> \u3068\u5165\u529b\u3057\u3066 WebUI \u30b5\u30fc\u30d3\u30b9\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002</p> <p>WSL \u307e\u305f\u306f MacOS \u306e\u5834\u5408\u306f\u3001http://localhost:7860 \u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066 WebUI \u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u958b\u304f\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <p>\u30b5\u30fc\u30d0\u30fc\u306b\u30c7\u30d7\u30ed\u30a4\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3001localhost \u3092\u30b5\u30fc\u30d0\u30fc\u306e IP \u306b\u7f6e\u304d\u63db\u3048\u3066\u304f\u3060\u3055\u3044\u3002</p> </li> </ol>"},{"location":"ja/#_2","title":"\u5909\u66f4\u5c65\u6b74","text":"<ul> <li>2024/09/10: Fish-Speech \u3092 Ver.1.4 \u306b\u66f4\u65b0\u3057\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30b5\u30a4\u30ba\u3092\u5897\u52a0\u3055\u305b\u3001quantizer n_groups \u3092 4 \u304b\u3089 8 \u306b\u5909\u66f4\u3057\u307e\u3057\u305f\u3002</li> <li>2024/07/02: Fish-Speech \u3092 Ver.1.2 \u306b\u66f4\u65b0\u3057\u3001VITS \u30c7\u30b3\u30fc\u30c0\u30fc\u3092\u524a\u9664\u3057\u3001\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u80fd\u529b\u3092\u5927\u5e45\u306b\u5f37\u5316\u3057\u307e\u3057\u305f\u3002</li> <li>2024/05/10: Fish-Speech \u3092 Ver.1.1 \u306b\u66f4\u65b0\u3057\u3001VITS \u30c7\u30b3\u30fc\u30c0\u30fc\u3092\u5b9f\u88c5\u3057\u3066 WER \u3092\u6e1b\u5c11\u3055\u305b\u3001\u97f3\u8272\u306e\u985e\u4f3c\u6027\u3092\u5411\u4e0a\u3055\u305b\u307e\u3057\u305f\u3002</li> <li>2024/04/22: Fish-Speech Ver.1.0 \u3092\u5b8c\u6210\u3055\u305b\u3001VQGAN \u304a\u3088\u3073 LLAMA \u30e2\u30c7\u30eb\u3092\u5927\u5e45\u306b\u4fee\u6b63\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/28: <code>lora</code>\u5fae\u8abf\u6574\u30b5\u30dd\u30fc\u30c8\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/27: <code>gradient checkpointing</code>\u3001<code>causual sampling</code>\u3001\u304a\u3088\u3073<code>flash-attn</code>\u30b5\u30dd\u30fc\u30c8\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/19: webui \u304a\u3088\u3073 HTTP API \u3092\u66f4\u65b0\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/18: \u5fae\u8abf\u6574\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304a\u3088\u3073\u95a2\u9023\u4f8b\u3092\u66f4\u65b0\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/17: <code>text2semantic</code>\u30e2\u30c7\u30eb\u3092\u66f4\u65b0\u3057\u3001\u81ea\u7531\u97f3\u7d20\u30e2\u30fc\u30c9\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/13: \u30d9\u30fc\u30bf\u7248\u3092\u30ea\u30ea\u30fc\u30b9\u3057\u3001VQGAN \u30e2\u30c7\u30eb\u304a\u3088\u3073 LLAMA \u306b\u57fa\u3065\u304f\u8a00\u8a9e\u30e2\u30c7\u30eb\uff08\u97f3\u7d20\u306e\u307f\u30b5\u30dd\u30fc\u30c8\uff09\u3092\u542b\u307f\u307e\u3059\u3002</li> </ul>"},{"location":"ja/#_3","title":"\u8b1d\u8f9e","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"ja/finetune/","title":"\u5fae\u8abf\u6574","text":"<p>\u660e\u3089\u304b\u306b\u3001\u3053\u306e\u30da\u30fc\u30b8\u3092\u958b\u3044\u305f\u3068\u304d\u3001few-shot \u4e8b\u524d\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30e2\u30c7\u30eb\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u6e80\u8db3\u3057\u3066\u3044\u306a\u304b\u3063\u305f\u3053\u3068\u3067\u3057\u3087\u3046\u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4e0a\u3067\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5411\u4e0a\u3055\u305b\u308b\u305f\u3081\u306b\u30e2\u30c7\u30eb\u3092\u5fae\u8abf\u6574\u3057\u305f\u3044\u3068\u8003\u3048\u3066\u3044\u307e\u3059\u3002</p> <p>\u73fe\u5728\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u306f\u3001\u300cLLAMA\u300d\u90e8\u5206\u306e\u307f\u3092\u5fae\u8abf\u6574\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p>"},{"location":"ja/finetune/#llama","title":"LLAMA\u306e\u5fae\u8abf\u6574","text":""},{"location":"ja/finetune/#1","title":"1. \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6e96\u5099","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4e0a\u8a18\u306e\u5f62\u5f0f\u306b\u5909\u63db\u3057\u3001\u300cdata\u300d\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u914d\u7f6e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u306e\u62e1\u5f35\u5b50\u306f\u300c.mp3\u300d\u3001\u300c.wav\u300d\u3001\u307e\u305f\u306f\u300c.flac\u300d\u306b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3001\u6ce8\u91c8\u30d5\u30a1\u30a4\u30eb\u306e\u62e1\u5f35\u5b50\u306f\u300c.lab\u300d\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>Info</p> <p>\u6a19\u6e96\u30d5\u30a1\u30a4\u30eb <code>.lab</code> \u306b\u306f\u3001\u97f3\u58f0\u306e\u8ee2\u5199\u30c6\u30ad\u30b9\u30c8\u306e\u307f\u3092\u542b\u3081\u3001\u7279\u5225\u306a\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306f\u5fc5\u8981\u3042\u308a\u307e\u305b\u3093\u3002\u4f8b\u3048\u3070\u3001<code>hi.mp3</code> \u3067\u300c\u3053\u3093\u306b\u3061\u306f\u3001\u3055\u3088\u3046\u306a\u3089\u300d\u3068\u8a00\u3063\u3066\u3044\u308b\u5834\u5408\u3001<code>hi.lab</code> \u30d5\u30a1\u30a4\u30eb\u306b\u306f\u300c\u3053\u3093\u306b\u3061\u306f\u3001\u3055\u3088\u3046\u306a\u3089\u300d\u3068\u3044\u3046\u4e00\u884c\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u542b\u3081\u308b\u3060\u3051\u3067\u3059\u3002</p> <p>Warning</p> <p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u30e9\u30a6\u30c9\u30cd\u30b9\u6b63\u898f\u5316\u3092\u9069\u7528\u3059\u308b\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\u3053\u308c\u3092\u884c\u3046\u306b\u306f\u3001fish-audio-preprocess \u3092\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002</p> <pre><code>fap loudness-norm data-raw data --clean\n</code></pre>"},{"location":"ja/finetune/#2","title":"2. \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u306e\u30d0\u30c3\u30c1\u62bd\u51fa","text":"<p>VQGAN\u306e\u91cd\u307f\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u307e\u3060\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u6b21\u306b\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3092\u62bd\u51fa\u3067\u304d\u307e\u3059\u3002</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p><code>--num-workers</code> \u3068 <code>--batch-size</code> \u3092\u8abf\u6574\u3057\u3066\u62bd\u51fa\u901f\u5ea6\u3092\u4e0a\u3052\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u304c\u3001GPU\u30e1\u30e2\u30ea\u306e\u5236\u9650\u3092\u8d85\u3048\u306a\u3044\u3088\u3046\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002 VITS\u5f62\u5f0f\u306e\u5834\u5408\u3001<code>--filelist xxx.list</code> \u3092\u4f7f\u7528\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u30ea\u30b9\u30c8\u3092\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002</p> <p>\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001<code>data</code>\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b<code>.npy</code>\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"ja/finetune/#3-protobuf","title":"3. \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092protobuf\u306b\u30d1\u30c3\u30af\u3059\u308b","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u304c\u5b8c\u4e86\u3059\u308b\u3068\u3001<code>data</code>\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b<code>quantized-dataset-ft.protos</code>\u30d5\u30a1\u30a4\u30eb\u304c\u8868\u793a\u3055\u308c\u307e\u3059\u3002</p>"},{"location":"ja/finetune/#4-lora","title":"4. \u6700\u5f8c\u306b\u3001LoRA\u3092\u4f7f\u7528\u3057\u3066\u5fae\u8abf\u6574\u3059\u308b","text":"<p>\u540c\u69d8\u306b\u3001<code>LLAMA</code>\u306e\u91cd\u307f\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u307e\u3060\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u6700\u5f8c\u306b\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u5fae\u8abf\u6574\u3092\u958b\u59cb\u3067\u304d\u307e\u3059\u3002</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p><code>fish_speech/configs/text2semantic_finetune.yaml</code> \u3092\u5909\u66f4\u3057\u3066\u3001<code>batch_size</code>\u3001<code>gradient_accumulation_steps</code> \u306a\u3069\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5909\u66f4\u3057\u3001GPU\u30e1\u30e2\u30ea\u306b\u9069\u5408\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <p>Note</p> <p>Windows\u30e6\u30fc\u30b6\u30fc\u306e\u5834\u5408\u3001<code>trainer.strategy.process_group_backend=gloo</code> \u3092\u4f7f\u7528\u3057\u3066 <code>nccl</code> \u306e\u554f\u984c\u3092\u56de\u907f\u3067\u304d\u307e\u3059\u3002</p> <p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u304c\u5b8c\u4e86\u3057\u305f\u3089\u3001\u63a8\u8ad6\u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3001\u97f3\u58f0\u3092\u751f\u6210\u3057\u307e\u3059\u3002</p> <p>Info</p> <p>\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u3001\u30e2\u30c7\u30eb\u306f\u8a71\u8005\u306e\u767a\u8a71\u30d1\u30bf\u30fc\u30f3\u306e\u307f\u3092\u5b66\u7fd2\u3057\u3001\u97f3\u8272\u306f\u5b66\u7fd2\u3057\u307e\u305b\u3093\u3002\u97f3\u8272\u306e\u5b89\u5b9a\u6027\u3092\u78ba\u4fdd\u3059\u308b\u305f\u3081\u306b\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u97f3\u8272\u3092\u5b66\u7fd2\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b9\u30c6\u30c3\u30d7\u6570\u3092\u5897\u3084\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u304c\u3001\u3053\u308c\u306b\u3088\u308a\u904e\u5b66\u7fd2\u304c\u767a\u751f\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u304c\u5b8c\u4e86\u3057\u305f\u3089\u3001\u63a8\u8ad6\u3092\u884c\u3046\u524d\u306bLoRA\u306e\u91cd\u307f\u3092\u901a\u5e38\u306e\u91cd\u307f\u306b\u5909\u63db\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>\u4ed6\u306e\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u3092\u8a66\u3059\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\u8981\u4ef6\u3092\u6e80\u305f\u3059\u6700\u3082\u65e9\u3044\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\u3053\u308c\u3089\u306f\u901a\u5e38\u3001\u5206\u5e03\u5916\uff08OOD\uff09\u30c7\u30fc\u30bf\u3067\u3088\u308a\u826f\u3044\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u767a\u63ee\u3057\u307e\u3059\u3002</p>"},{"location":"ja/inference/","title":"\u63a8\u8ad6","text":"<p>\u63a8\u8ad6\u306f\u3001\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u3001HTTP API\u3001\u304a\u3088\u3073 Web UI \u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>Note</p> <p>\u5168\u4f53\u3068\u3057\u3066\u3001\u63a8\u8ad6\u306f\u6b21\u306e\u3044\u304f\u3064\u304b\u306e\u90e8\u5206\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u307e\u3059\uff1a</p> <ol> <li>VQGAN\u3092\u4f7f\u7528\u3057\u3066\u3001\u4e0e\u3048\u3089\u308c\u305f\u7d0410\u79d2\u306e\u97f3\u58f0\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\u3057\u307e\u3059\u3002</li> <li>\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u305f\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3068\u5bfe\u5fdc\u3059\u308b\u30c6\u30ad\u30b9\u30c8\u3092\u4f8b\u3068\u3057\u3066\u8a00\u8a9e\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3057\u307e\u3059\u3002</li> <li>\u65b0\u3057\u3044\u30c6\u30ad\u30b9\u30c8\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u30e2\u30c7\u30eb\u306b\u5bfe\u5fdc\u3059\u308b\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3092\u751f\u6210\u3055\u305b\u307e\u3059\u3002</li> <li>\u751f\u6210\u3055\u308c\u305f\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3092VITS / VQGAN\u306b\u5165\u529b\u3057\u3066\u30c7\u30b3\u30fc\u30c9\u3057\u3001\u5bfe\u5fdc\u3059\u308b\u97f3\u58f0\u3092\u751f\u6210\u3057\u307e\u3059\u3002</li> </ol>"},{"location":"ja/inference/#_2","title":"\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u63a8\u8ad6","text":"<p>\u5fc5\u8981\u306a<code>vqgan</code>\u304a\u3088\u3073<code>llama</code>\u30e2\u30c7\u30eb\u3092 Hugging Face \u30ea\u30dd\u30b8\u30c8\u30ea\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"ja/inference/#1","title":"1. \u97f3\u58f0\u304b\u3089\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u751f\u6210\u3059\u308b\uff1a","text":"<p>Note</p> <p>\u30e2\u30c7\u30eb\u306b\u30e9\u30f3\u30c0\u30e0\u306b\u97f3\u58f0\u306e\u97f3\u8272\u3092\u9078\u3070\u305b\u308b\u5834\u5408\u3001\u3053\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u30b9\u30ad\u30c3\u30d7\u3067\u304d\u307e\u3059\u3002</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p><code>fake.npy</code>\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u308b\u306f\u305a\u3067\u3059\u3002</p>"},{"location":"ja/inference/#2","title":"2. \u30c6\u30ad\u30b9\u30c8\u304b\u3089\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3092\u751f\u6210\u3059\u308b\uff1a","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"\u5909\u63db\u3057\u305f\u3044\u30c6\u30ad\u30b9\u30c8\" \\\n    --prompt-text \"\u53c2\u7167\u30c6\u30ad\u30b9\u30c8\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001\u4f5c\u696d\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b<code>codes_N</code>\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u3053\u3053\u3067\u3001N \u306f 0 \u304b\u3089\u59cb\u307e\u308b\u6574\u6570\u3067\u3059\u3002</p> <p>Note</p> <p><code>--compile</code>\u3092\u4f7f\u7528\u3057\u3066 CUDA \u30ab\u30fc\u30cd\u30eb\u3092\u878d\u5408\u3057\u3001\u3088\u308a\u9ad8\u901f\u306a\u63a8\u8ad6\u3092\u5b9f\u73fe\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff08\u7d04 30 \u30c8\u30fc\u30af\u30f3/\u79d2 -&gt; \u7d04 500 \u30c8\u30fc\u30af\u30f3/\u79d2\uff09\u3002 \u305d\u308c\u306b\u5bfe\u5fdc\u3057\u3066\u3001\u52a0\u901f\u3092\u4f7f\u7528\u3057\u306a\u3044\u5834\u5408\u306f\u3001<code>--compile</code>\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3067\u304d\u307e\u3059\u3002</p> <p>Info</p> <p>bf16 \u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u306a\u3044 GPU \u306e\u5834\u5408\u3001<code>--half</code>\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002</p>"},{"location":"ja/inference/#3","title":"3. \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u304b\u3089\u97f3\u58f0\u3092\u751f\u6210\u3059\u308b\uff1a","text":""},{"location":"ja/inference/#vqgan","title":"VQGAN \u30c7\u30b3\u30fc\u30c0\u30fc","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"ja/inference/#http-api","title":"HTTP API \u63a8\u8ad6","text":"<p>\u63a8\u8ad6\u306e\u305f\u3081\u306e HTTP API \u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\u3002\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u7528\u3057\u3066\u30b5\u30fc\u30d0\u30fc\u3092\u8d77\u52d5\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>\u63a8\u8ad6\u3092\u9ad8\u901f\u5316\u3057\u305f\u3044\u5834\u5408\u306f\u3001<code>--compile</code> \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8ffd\u52a0\u3067\u304d\u307e\u3059\u3002</p> <p>\u305d\u306e\u5f8c\u3001<code>http://127.0.0.1:8080/</code>\u3067 API \u3092\u8868\u793a\u304a\u3088\u3073\u30c6\u30b9\u30c8\u3067\u304d\u307e\u3059\u3002</p> <p>\u4ee5\u4e0b\u306f\u3001<code>tools/post_api.py</code> \u3092\u4f7f\u7528\u3057\u3066\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u9001\u4fe1\u3059\u308b\u4f8b\u3067\u3059\u3002</p> <pre><code>python -m tools.post_api \\\n    --text \"\u5165\u529b\u3059\u308b\u30c6\u30ad\u30b9\u30c8\" \\\n    --reference_audio \"\u53c2\u7167\u97f3\u58f0\u3078\u306e\u30d1\u30b9\" \\\n    --reference_text \"\u53c2\u7167\u97f3\u58f0\u30c6\u30ad\u30b9\u30c8\" \\\n    --streaming True\n</code></pre> <p>\u4e0a\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001\u53c2\u7167\u97f3\u58f0\u306e\u60c5\u5831\u306b\u57fa\u3065\u3044\u3066\u5fc5\u8981\u306a\u97f3\u58f0\u3092\u5408\u6210\u3057\u3001\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u65b9\u5f0f\u3067\u8fd4\u3059\u3053\u3068\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>Info</p> <p>\u4f7f\u7528\u53ef\u80fd\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001\u30b3\u30de\u30f3\u30c9<code>python -m tools.post_api -h</code>\u3092\u4f7f\u7528\u3057\u3066\u304f\u3060\u3055\u3044</p>"},{"location":"ja/inference/#webui","title":"WebUI \u63a8\u8ad6","text":"<p>\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u7528\u3057\u3066 WebUI \u3092\u8d77\u52d5\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>\u63a8\u8ad6\u3092\u9ad8\u901f\u5316\u3057\u305f\u3044\u5834\u5408\u306f\u3001<code>--compile</code> \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8ffd\u52a0\u3067\u304d\u307e\u3059\u3002</p> <p>Note</p> <p>\u30e9\u30d9\u30eb\u30d5\u30a1\u30a4\u30eb\u3068\u53c2\u7167\u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u3092\u30e1\u30a4\u30f3\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e <code>references</code> \u30d5\u30a9\u30eb\u30c0\uff08\u81ea\u5206\u3067\u4f5c\u6210\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff09\u306b\u4e8b\u524d\u306b\u4fdd\u5b58\u3057\u3066\u304a\u304f\u3053\u3068\u3067\u3001WebUI \u3067\u76f4\u63a5\u547c\u3073\u51fa\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <p>Note</p> <p>Gradio \u74b0\u5883\u5909\u6570\uff08<code>GRADIO_SHARE</code>\u3001<code>GRADIO_SERVER_PORT</code>\u3001<code>GRADIO_SERVER_NAME</code>\u306a\u3069\uff09\u3092\u4f7f\u7528\u3057\u3066 WebUI \u3092\u69cb\u6210\u3067\u304d\u307e\u3059\u3002</p> <p>\u304a\u697d\u3057\u307f\u304f\u3060\u3055\u3044\uff01</p>"},{"location":"ja/samples/","title":"\u30b5\u30f3\u30d7\u30eb","text":"<p>v1.4\u30c7\u30e2\u306f\u3053\u3061\u3089\u306b\u66f4\u65b0\u3055\u308c\u3066\u3044\u307e\u3059</p> <p>v1.2\u306e\u30b5\u30f3\u30d7\u30eb\u306fBilibili\u3067\u5229\u7528\u53ef\u80fd\u3067\u3059\u3002</p> <p>\u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u306fv1.1\u30e2\u30c7\u30eb\u304b\u3089\u306e\u3082\u306e\u3067\u3059\u3002</p>"},{"location":"ja/samples/#1","title":"\u4e2d\u56fd\u8a9e\u306e\u65871","text":"<pre><code>\u4eba\u9593\u706f\u706b\u5012\u6620\u6e56\u4e2d\uff0c\u5979\u7684\u6e34\u671b\u8ba9\u9759\u6c34\u6cdb\u8d77\u6d9f\u6f2a\u3002\u82e5\u4ee3\u4ef7\u53ea\u662f\u5b64\u72ec\uff0c\u90a3\u5c31\u8ba9\u8fd9\u4efd\u613f\u671b\u8086\u610f\u6d41\u6dcc\u3002\n\u6d41\u5165\u5979\u6240\u6ce8\u89c6\u7684\u4e16\u95f4\uff0c\u4e5f\u6d41\u5165\u5979\u5982\u6e56\u6c34\u822c\u6f84\u6f88\u7684\u76ee\u5149\u3002\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30ca\u30d2\u30fc\u30c0 (\u539f\u795e) \u937e\u96e2 (\u539f\u795e) \u30d5\u30ea\u30ca (\u539f\u795e) \u30e9\u30f3\u30c0\u30e0\u8a71\u80051  -  \u30e9\u30f3\u30c0\u30e0\u8a71\u80052  -"},{"location":"ja/samples/#2","title":"\u4e2d\u56fd\u8a9e\u306e\u65872","text":"<pre><code>\u4f60\u4eec\u8fd9\u4e2a\u662f\u4ec0\u4e48\u7fa4\u554a\uff0c\u4f60\u4eec\u8fd9\u662f\u5bb3\u4eba\u4e0d\u6d45\u554a\u4f60\u4eec\u8fd9\u4e2a\u7fa4\uff01\u8c01\u662f\u7fa4\u4e3b\uff0c\u51fa\u6765\uff01\u771f\u7684\u592a\u8fc7\u5206\u4e86\u3002\u4f60\u4eec\u641e\u8fd9\u4e2a\u7fa4\u5e72\u4ec0\u4e48\uff1f\n\u6211\u513f\u5b50\u6bcf\u4e00\u79d1\u7684\u6210\u7ee9\u90fd\u4e0d\u8fc7\u90a3\u4e2a\u5e73\u5747\u5206\u5450\uff0c\u4ed6\u73b0\u5728\u521d\u4e8c\uff0c\u4f60\u53eb\u6211\u513f\u5b50\u600e\u4e48\u529e\u554a\uff1f\u4ed6\u73b0\u5728\u8fd8\u4e0d\u5230\u9ad8\u4e2d\u554a\uff1f\n\u4f60\u4eec\u5bb3\u6b7b\u6211\u513f\u5b50\u4e86\uff01\u5feb\u70b9\u51fa\u6765\u4f60\u8fd9\u4e2a\u7fa4\u4e3b\uff01\u518d\u8fd9\u6837\u6211\u53bb\u62a5\u8b66\u4e86\u554a\uff01\u6211\u8ddf\u4f60\u4eec\u8bf4\u4f60\u4eec\u8fd9\u4e00\u5e2e\u4eba\u554a\uff0c\u4e00\u5929\u5230\u665a\u554a\uff0c\n\u641e\u8fd9\u4e9b\u4ec0\u4e48\u6e38\u620f\u554a\uff0c\u52a8\u6f2b\u554a\uff0c\u4f1a\u5bb3\u6b7b\u4f60\u4eec\u7684\uff0c\u4f60\u4eec\u6ca1\u6709\u524d\u9014\u6211\u8ddf\u4f60\u8bf4\u3002\u4f60\u4eec\u8fd9\u4e5d\u767e\u591a\u4e2a\u4eba\uff0c\u597d\u597d\u5b66\u4e60\u4e0d\u597d\u5417\uff1f\n\u4e00\u5929\u5230\u665a\u5728\u4e0a\u7f51\u3002\u6709\u4ec0\u4e48\u610f\u601d\u554a\uff1f\u9ebb\u70e6\u4f60\u91cd\u89c6\u4e00\u4e0b\u4f60\u4eec\u7684\u751f\u6d3b\u7684\u76ee\u6807\u554a\uff1f\u6709\u4e00\u70b9\u5b66\u4e60\u76ee\u6807\u884c\u4e0d\u884c\uff1f\u4e00\u5929\u5230\u665a\u4e0a\u7f51\u662f\u4e0d\u662f\u4eba\u554a\uff1f\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30ca\u30d2\u30fc\u30c0 (\u539f\u795e) \u30e9\u30f3\u30c0\u30e0\u8a71\u8005  -"},{"location":"ja/samples/#3","title":"\u4e2d\u56fd\u8a9e\u306e\u65873","text":"<pre><code>\u5927\u5bb6\u597d\uff0c\u6211\u662f Fish Audio \u5f00\u53d1\u7684\u5f00\u6e90\u6587\u672c\u8f6c\u8bed\u97f3\u6a21\u578b\u3002\u7ecf\u8fc7\u5341\u4e94\u4e07\u5c0f\u65f6\u7684\u6570\u636e\u8bad\u7ec3\uff0c\n\u6211\u5df2\u7ecf\u80fd\u591f\u719f\u7ec3\u638c\u63e1\u4e2d\u6587\u3001\u65e5\u8bed\u548c\u82f1\u8bed\uff0c\u6211\u7684\u8bed\u8a00\u5904\u7406\u80fd\u529b\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u58f0\u97f3\u8868\u73b0\u5f62\u5f0f\u4e30\u5bcc\u591a\u53d8\u3002\n\u4f5c\u4e3a\u4e00\u4e2a\u4ec5\u6709\u4ebf\u7ea7\u53c2\u6570\u7684\u6a21\u578b\uff0c\u6211\u76f8\u4fe1\u793e\u533a\u6210\u5458\u80fd\u591f\u5728\u4e2a\u4eba\u8bbe\u5907\u4e0a\u8f7b\u677e\u8fd0\u884c\u548c\u5fae\u8c03\uff0c\u8ba9\u6211\u6210\u4e3a\u60a8\u7684\u79c1\u4eba\u8bed\u97f3\u52a9\u624b\u3002\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u8005  -"},{"location":"ja/samples/#1_1","title":"\u82f1\u8a9e\u306e\u65871","text":"<pre><code>In the realm of advanced technology, the evolution of artificial intelligence stands as a \nmonumental achievement. This dynamic field, constantly pushing the boundaries of what \nmachines can do, has seen rapid growth and innovation. From deciphering complex data \npatterns to driving cars autonomously, AI's applications are vast and diverse.\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u80051  -  \u30e9\u30f3\u30c0\u30e0\u8a71\u80052  -"},{"location":"ja/samples/#2_1","title":"\u82f1\u8a9e\u306e\u65872","text":"<pre><code>Hello everyone, I am an open-source text-to-speech model developed by \nFish Audio. After training with 150,000 hours of data, I have become proficient \nin Chinese, Japanese, and English, and my language processing abilities \nare close to human level. My voice is capable of a wide range of expressions. \nAs a model with only hundreds of millions of parameters, I believe community \nmembers can easily run and fine-tune me on their personal devices, allowing \nme to serve as your personal voice assistant.\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u8005  -"},{"location":"ja/samples/#1_2","title":"\u65e5\u672c\u8a9e\u306e\u65871","text":"<pre><code>\u5148\u9032\u6280\u8853\u306e\u9818\u57df\u306b\u304a\u3044\u3066\u3001\u4eba\u5de5\u77e5\u80fd\u306e\u9032\u5316\u306f\u753b\u671f\u7684\u306a\u6210\u679c\u3068\u3057\u3066\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\u5e38\u306b\u6a5f\u68b0\u304c\u3067\u304d\u308b\u3053\u3068\u306e\u9650\u754c\u3092\n\u62bc\u3057\u5e83\u3052\u3066\u3044\u308b\u3053\u306e\u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u5206\u91ce\u306f\u3001\u6025\u901f\u306a\u6210\u9577\u3068\u9769\u65b0\u3092\u898b\u305b\u3066\u3044\u307e\u3059\u3002\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30d1\u30bf\u30fc\u30f3\u306e\u89e3\u8aad\u304b\n\u3089\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u64cd\u7e26\u307e\u3067\u3001AI\u306e\u5fdc\u7528\u306f\u5e83\u7bc4\u56f2\u306b\u53ca\u3073\u307e\u3059\u3002\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u80051  -  \u30e9\u30f3\u30c0\u30e0\u8a71\u80052  -"},{"location":"ja/samples/#2_2","title":"\u65e5\u672c\u8a9e\u306e\u65872","text":"<pre><code>\u7686\u3055\u3093\u3001\u3053\u3093\u306b\u3061\u306f\u3002\u79c1\u306f\u30d5\u30a3\u30c3\u30b7\u30e5\u30aa\u30fc\u30c7\u30a3\u30aa\u306b\u3088\u3063\u3066\u958b\u767a\u3055\u308c\u305f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u30c6\n\u30ad\u30b9\u30c8\u304b\u3089\u97f3\u58f0\u3078\u306e\u5909\u63db\u30e2\u30c7\u30eb\u3067\u3059\u300215\u4e07\u6642\u9593\u306e\u30c7\u30fc\u30bf\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u7d4c\u3066\u3001\n\u4e2d\u56fd\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u82f1\u8a9e\u3092\u719f\u77e5\u3057\u3066\u304a\u308a\u3001\u8a00\u8a9e\u51e6\u7406\u80fd\u529b\u306f\u4eba\u9593\u306b\u8fd1\u3044\u30ec\u30d9\u30eb\u3067\u3059\u3002\n\u58f0\u306e\u8868\u73fe\u3082\u591a\u5f69\u3067\u8c4a\u304b\u3067\u3059\u3002\u6570\u5104\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u3053\u306e\u30e2\u30c7\u30eb\u306f\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\n\u306e\u30e1\u30f3\u30d0\u30fc\u304c\u500b\u4eba\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u7c21\u5358\u306b\u5b9f\u884c\u3057\u3001\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\n\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u79c1\u3092\u500b\u4eba\u306e\u97f3\u58f0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u6d3b\u7528\u3067\u304d\u307e\u3059\u3002\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u8005  -"},{"location":"pt/","title":"Introdu\u00e7\u00e3o","text":"<p>Warning</p> <p>N\u00e3o nos responsabilizamos por qualquer uso ilegal do c\u00f3digo-fonte. Consulte as leis locais sobre DMCA (Digital Millennium Copyright Act) e outras leis relevantes em sua regi\u00e3o.  Este reposit\u00f3rio de c\u00f3digo e os modelos s\u00e3o distribu\u00eddos sob a licen\u00e7a CC-BY-NC-SA-4.0.</p> <p> </p>"},{"location":"pt/#requisitos","title":"Requisitos","text":"<ul> <li>Mem\u00f3ria da GPU: 4GB (para infer\u00eancia), 8GB (para ajuste fino)</li> <li>Sistema: Linux, Windows</li> </ul>"},{"location":"pt/#configuracao-do-windows","title":"Configura\u00e7\u00e3o do Windows","text":"<p>Usu\u00e1rios profissionais do Windows podem considerar o uso do WSL2 ou Docker para executar a base de c\u00f3digo.</p> <pre><code># Crie um ambiente virtual Python 3.10, tamb\u00e9m \u00e9 poss\u00edvel usar o virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# Instale o pytorch\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n\n# Instale o fish-speech\npip3 install -e .\n\n# (Ativar acelera\u00e7\u00e3o) Instalar triton-windows\npip install https://github.com/AnyaCoder/fish-speech/releases/download/v0.1.0/triton_windows-0.1.0-py3-none-any.whl\n</code></pre> <p>Usu\u00e1rios n\u00e3o profissionais do Windows podem considerar os seguintes m\u00e9todos b\u00e1sicos para executar o projeto sem um ambiente Linux (com capacidades de compila\u00e7\u00e3o de modelo, ou seja, <code>torch.compile</code>):</p> <ol> <li>Extraia o pacote do projeto.</li> <li>Clique em <code>install_env.bat</code> para instalar o ambiente.</li> <li>Se voc\u00ea quiser ativar a acelera\u00e7\u00e3o de compila\u00e7\u00e3o, siga estas etapas:<ol> <li>Baixe o compilador LLVM nos seguintes links:<ul> <li>LLVM-17.0.6 (Download do site oficial)</li> <li>LLVM-17.0.6 (Download do site espelho)</li> <li>Ap\u00f3s baixar o <code>LLVM-17.0.6-win64.exe</code>, clique duas vezes para instalar, selecione um local de instala\u00e7\u00e3o apropriado e, o mais importante, marque a op\u00e7\u00e3o <code>Add Path to Current User</code> para adicionar a vari\u00e1vel de ambiente.</li> <li>Confirme que a instala\u00e7\u00e3o foi conclu\u00edda.</li> </ul> </li> <li>Baixe e instale o Microsoft Visual C++ Redistributable para resolver poss\u00edveis problemas de arquivos .dll ausentes:<ul> <li>Download do MSVC++ 14.40.33810.0</li> </ul> </li> <li>Baixe e instale o Visual Studio Community Edition para obter as ferramentas de compila\u00e7\u00e3o do MSVC++ e resolver as depend\u00eancias dos arquivos de cabe\u00e7alho do LLVM:<ul> <li>Download do Visual Studio</li> <li>Ap\u00f3s instalar o Visual Studio Installer, baixe o Visual Studio Community 2022.</li> <li>Conforme mostrado abaixo, clique no bot\u00e3o <code>Modificar</code>, encontre a op\u00e7\u00e3o <code>Desenvolvimento de \u00e1rea de trabalho com C++</code> e selecione para fazer o download.</li> </ul> </li> <li>Baixe e instale o CUDA Toolkit 12.x</li> </ol> </li> <li>Clique duas vezes em <code>start.bat</code> para abrir a interface de gerenciamento WebUI de infer\u00eancia de treinamento. Se necess\u00e1rio, voc\u00ea pode modificar as <code>API_FLAGS</code> conforme mostrado abaixo.</li> </ol> <p>Opcional</p> <p>Voc\u00ea quer iniciar o WebUI de infer\u00eancia? Edite o arquivo <code>API_FLAGS.txt</code> no diret\u00f3rio raiz do projeto e modifique as tr\u00eas primeiras linhas como segue: <pre><code>--infer\n# --api\n# --listen ...\n...\n</code></pre></p> <p>Opcional</p> <p>Voc\u00ea quer iniciar o servidor de API? Edite o arquivo <code>API_FLAGS.txt</code> no diret\u00f3rio raiz do projeto e modifique as tr\u00eas primeiras linhas como segue:</p> <pre><code># --infer\n--api\n--listen ...\n...\n</code></pre> <p>Opcional</p> <p>Clique duas vezes em <code>run_cmd.bat</code> para entrar no ambiente de linha de comando conda/python deste projeto.</p>"},{"location":"pt/#configuracao-para-linux","title":"Configura\u00e7\u00e3o para Linux","text":"<p>Para mais detalhes, consulte pyproject.toml. <pre><code># Crie um ambiente virtual python 3.10, voc\u00ea tamb\u00e9m pode usar virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# Instale o pytorch\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n\n# Para os Usu\u00e1rio do Ubuntu / Debian: Instale o sox + ffmpeg\napt install libsox-dev ffmpeg\n\n# Para os Usu\u00e1rio do Ubuntu / Debian: Instale o pyaudio\napt install build-essential \\\n    cmake \\\n    libasound-dev \\\n    portaudio19-dev \\\n    libportaudio2 \\\n    libportaudiocpp0\n\n# Instale o fish-speech\npip3 install -e .[stable]\n</code></pre></p>"},{"location":"pt/#configuracao-para-macos","title":"Configura\u00e7\u00e3o para macos","text":"<p>Se voc\u00ea quiser realizar infer\u00eancias no MPS, adicione a flag <code>--device mps</code>. Para uma compara\u00e7\u00e3o das velocidades de infer\u00eancia, consulte este PR.</p> <p>Aviso</p> <p>A op\u00e7\u00e3o <code>compile</code> n\u00e3o \u00e9 oficialmente suportada em dispositivos Apple Silicon, ent\u00e3o n\u00e3o h\u00e1 garantia de que a velocidade de infer\u00eancia ir\u00e1 melhorar.</p> <pre><code># create a python 3.10 virtual environment, you can also use virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n# install pytorch\npip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n# install fish-speech\npip install -e .[stable]\n</code></pre>"},{"location":"pt/#configuracao-do-docker","title":"Configura\u00e7\u00e3o do Docker","text":"<ol> <li> <p>Instale o NVIDIA Container Toolkit:</p> <p>Para usar a GPU com Docker para treinamento e infer\u00eancia de modelos, voc\u00ea precisa instalar o NVIDIA Container Toolkit:</p> <p>Para usu\u00e1rios Ubuntu:</p> <pre><code># Adicione o reposit\u00f3rio remoto\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n# Instale o nvidia-container-toolkit\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n# Reinicie o servi\u00e7o Docker\nsudo systemctl restart docker\n</code></pre> <p>Para usu\u00e1rios de outras distribui\u00e7\u00f5es Linux, consulte o guia de instala\u00e7\u00e3o: NVIDIA Container Toolkit Install-guide.</p> </li> <li> <p>Baixe e execute a imagem fish-speech</p> <pre><code># Baixe a imagem\ndocker pull fishaudio/fish-speech:latest-dev\n# Execute a imagem\ndocker run -it \\\n    --name fish-speech \\\n    --gpus all \\\n    -p 7860:7860 \\\n    fishaudio/fish-speech:latest-dev \\\n    zsh\n# Se precisar usar outra porta, modifique o par\u00e2metro -p para YourPort:7860\n</code></pre> </li> <li> <p>Baixe as depend\u00eancias do modelo</p> <p>Certifique-se de estar no terminal do cont\u00eainer Docker e, em seguida, baixe os modelos necess\u00e1rios <code>vqgan</code> e <code>llama</code> do nosso reposit\u00f3rio HuggingFace.</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> </li> <li> <p>Configure as vari\u00e1veis de ambiente e acesse a WebUI</p> <p>No terminal do cont\u00eainer Docker, digite <code>export GRADIO_SERVER_NAME=\"0.0.0.0\"</code> para permitir o acesso externo ao servi\u00e7o gradio dentro do Docker. Em seguida, no terminal do cont\u00eainer Docker, digite <code>python tools/webui.py</code> para iniciar o servi\u00e7o WebUI.</p> <p>Se estiver usando WSL ou MacOS, acesse http://localhost:7860 para abrir a interface WebUI.</p> <p>Se estiver implantando em um servidor, substitua localhost pelo IP do seu servidor.</p> </li> </ol>"},{"location":"pt/#historico-de-alteracoes","title":"Hist\u00f3rico de Altera\u00e7\u00f5es","text":"<ul> <li>10/09/2024: Fish-Speech atualizado para a vers\u00e3o 1.4, aumentado o tamanho do conjunto de dados, quantizer n_groups 4 -&gt; 8.</li> <li>02/07/2024: Fish-Speech atualizado para a vers\u00e3o 1.2, removido o Decodificador VITS e aprimorado consideravelmente a capacidade de zero-shot.</li> <li>10/05/2024: Fish-Speech atualizado para a vers\u00e3o 1.1, implementado o decodificador VITS para reduzir a WER e melhorar a similaridade de timbre.</li> <li>22/04/2024: Finalizada a vers\u00e3o 1.0 do Fish-Speech, modificados significativamente os modelos VQGAN e LLAMA.</li> <li>28/12/2023: Adicionado suporte para ajuste fino <code>lora</code>.</li> <li>27/12/2023: Adicionado suporte para <code>gradient checkpointing</code>, <code>causual sampling</code> e <code>flash-attn</code>.</li> <li>19/12/2023: Atualizada a interface web e a API HTTP.</li> <li>18/12/2023: Atualizada a documenta\u00e7\u00e3o de ajuste fino e exemplos relacionados.</li> <li>17/12/2023: Atualizado o modelo <code>text2semantic</code>, suportando o modo sem fonemas.</li> <li>13/12/2023: Vers\u00e3o beta lan\u00e7ada, incluindo o modelo VQGAN e um modelo de linguagem baseado em LLAMA (suporte apenas a fonemas).</li> </ul>"},{"location":"pt/#agradecimentos","title":"Agradecimentos","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"pt/finetune/","title":"Ajuste Fino","text":"<p>\u00c9 \u00f3bvio que ao abrir esta p\u00e1gina, voc\u00ea n\u00e3o deve estar muito satisfeito com o desempenho do modelo pr\u00e9-treinado com poucos exemplos. Voc\u00ea pode querer ajustar o modelo para melhorar seu desempenho em seu conjunto de dados.</p> <p>Na atual vers\u00e3o, a \u00fanica coisa que voc\u00ea precisa ajustar \u00e9 a parte do 'LLAMA'.</p>"},{"location":"pt/finetune/#ajuste-fino-do-llama","title":"Ajuste Fino do LLAMA","text":""},{"location":"pt/finetune/#1-preparando-o-conjunto-de-dados","title":"1. Preparando o conjunto de dados","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>Voc\u00ea precisa converter seu conjunto de dados para o formato acima e coloc\u00e1-lo em <code>data</code>. O arquivo de \u00e1udio pode ter as extens\u00f5es <code>.mp3</code>, <code>.wav</code> ou <code>.flac</code>, e o arquivo de anota\u00e7\u00e3o deve ter a extens\u00e3o <code>.lab</code>.</p> <p>Info</p> <p>O arquivo de anota\u00e7\u00e3o <code>.lab</code> deve conter apenas a transcri\u00e7\u00e3o do \u00e1udio, sem a necessidade de formata\u00e7\u00e3o especial. Por exemplo, se o arquivo <code>hi.mp3</code> disser \"Ol\u00e1, tchau\", o arquivo <code>hi.lab</code> conter\u00e1 uma \u00fanica linha de texto: \"Ol\u00e1, tchau\".</p> <p>Warning</p> <p>\u00c9 recomendado aplicar normaliza\u00e7\u00e3o de volume ao conjunto de dados. Voc\u00ea pode usar o fish-audio-preprocess para fazer isso.</p> <pre><code>fap loudness-norm data-raw data --clean\n</code></pre>"},{"location":"pt/finetune/#2-extracao-em-lote-de-tokens-semanticos","title":"2. Extra\u00e7\u00e3o em lote de tokens sem\u00e2nticos","text":"<p>Certifique-se de ter baixado os pesos do VQGAN. Se n\u00e3o, execute o seguinte comando:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>Em seguida, voc\u00ea pode executar o seguinte comando para extrair os tokens sem\u00e2nticos:</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p>Voc\u00ea pode ajustar <code>--num-workers</code> e <code>--batch-size</code> para aumentar a velocidade de extra\u00e7\u00e3o, mas certifique-se de n\u00e3o exceder o limite de mem\u00f3ria da sua GPU. \u00a0 Para o formato VITS, voc\u00ea pode especificar uma lista de arquivos usando <code>--filelist xxx.list</code>.</p> <p>Este comando criar\u00e1 arquivos <code>.npy</code> no diret\u00f3rio <code>data</code>, como mostrado abaixo:</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"pt/finetune/#3-empacotar-o-conjunto-de-dados-em-protobuf","title":"3. Empacotar o conjunto de dados em protobuf","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>Ap\u00f3s executar o comando, voc\u00ea dever\u00e1 ver o arquivo <code>quantized-dataset-ft.protos</code> no diret\u00f3rio <code>data</code>.</p>"},{"location":"pt/finetune/#4-e-finalmente-chegamos-ao-ajuste-fino-com-lora","title":"4. E finalmente, chegamos ao ajuste fino com LoRA","text":"<p>Da mesma forma, certifique-se de ter baixado os pesos do <code>LLAMA</code>. Se n\u00e3o, execute o seguinte comando:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>E ent\u00e3o, execute o seguinte comando para iniciar o ajuste fino:</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p>Se quiser, voc\u00ea pode modificar os par\u00e2metros de treinamento, como <code>batch_size</code>, <code>gradient_accumulation_steps</code>, etc., para se ajustar \u00e0 mem\u00f3ria da sua GPU, modificando <code>fish_speech/configs/text2semantic_finetune.yaml</code>.</p> <p>Note</p> <p>Para usu\u00e1rios do Windows, \u00e9 recomendado usar <code>trainer.strategy.process_group_backend=gloo</code> para evitar problemas com <code>nccl</code>.</p> <p>Ap\u00f3s concluir o treinamento, consulte a se\u00e7\u00e3o infer\u00eancia.</p> <p>Info</p> <p>Por padr\u00e3o, o modelo aprender\u00e1 apenas os padr\u00f5es de fala do orador e n\u00e3o o timbre. Ainda pode ser preciso usar prompts para garantir a estabilidade do timbre. Se quiser que ele aprenda o timbre, aumente o n\u00famero de etapas de treinamento, mas isso pode levar ao overfitting (sobreajuste).</p> <p>Ap\u00f3s o treinamento, \u00e9 preciso converter os pesos do LoRA em pesos regulares antes de realizar a infer\u00eancia.</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>\u00c9 poss\u00edvel tamb\u00e9m tentar outros checkpoints. Sugerimos usar o checkpoint que melhor atenda aos seus requisitos, pois eles geralmente t\u00eam um desempenho melhor em dados fora da distribui\u00e7\u00e3o (OOD).</p>"},{"location":"pt/inference/","title":"Infer\u00eancia","text":"<p>Suporte para infer\u00eancia por linha de comando, API HTTP e interface web (WebUI).</p> <p>Note</p> <p>O processo de racioc\u00ednio, em geral, consiste em v\u00e1rias partes:</p> <ol> <li>Codificar cerca de 10 segundos de voz usando VQGAN.</li> <li>Inserir os tokens sem\u00e2nticos codificados e o texto correspondente no modelo de linguagem como um exemplo.</li> <li>Dado um novo trecho de texto, fazer com que o modelo gere os tokens sem\u00e2nticos correspondentes.</li> <li>Inserir os tokens sem\u00e2nticos gerados no VITS / VQGAN para decodificar e gerar a voz correspondente.</li> </ol>"},{"location":"pt/inference/#inferencia-por-linha-de-comando","title":"Infer\u00eancia por Linha de Comando","text":"<p>Baixe os modelos <code>vqgan</code> e <code>llama</code> necess\u00e1rios do nosso reposit\u00f3rio Hugging Face.</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"pt/inference/#1-gerar-prompt-a-partir-da-voz","title":"1. Gerar prompt a partir da voz:","text":"<p>Note</p> <p>Se quiser permitir que o modelo escolha aleatoriamente um timbre de voz, pule esta etapa.</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Voc\u00ea dever\u00e1 obter um arquivo <code>fake.npy</code>.</p>"},{"location":"pt/inference/#2-gerar-tokens-semanticos-a-partir-do-texto","title":"2. Gerar tokens sem\u00e2nticos a partir do texto:","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"O texto que voc\u00ea deseja converter\" \\\n    --prompt-text \"Seu texto de refer\u00eancia\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>Este comando criar\u00e1 um arquivo <code>codes_N</code> no diret\u00f3rio de trabalho, onde N \u00e9 um n\u00famero inteiro come\u00e7ando de 0.</p> <p>Note</p> <p>Use <code>--compile</code> para fundir kernels CUDA para ter uma infer\u00eancia mais r\u00e1pida (~30 tokens/segundo -&gt; ~500 tokens/segundo). Mas, se n\u00e3o planeja usar a acelera\u00e7\u00e3o CUDA, comente o par\u00e2metro <code>--compile</code>.</p> <p>Info</p> <p>Para GPUs que n\u00e3o suportam bf16, pode ser necess\u00e1rio usar o par\u00e2metro <code>--half</code>.</p>"},{"location":"pt/inference/#3-gerar-vocais-a-partir-de-tokens-semanticos","title":"3. Gerar vocais a partir de tokens sem\u00e2nticos:","text":""},{"location":"pt/inference/#decodificador-vqgan","title":"Decodificador VQGAN","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"pt/inference/#inferencia-por-api-http","title":"Infer\u00eancia por API HTTP","text":"<p>Fornecemos uma API HTTP para infer\u00eancia. O seguinte comando pode ser usado para iniciar o servidor:</p> <pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>Para acelerar a infer\u00eancia, adicione o par\u00e2metro <code>--compile</code>.</p> <p>Depois disso, \u00e9 poss\u00edvel visualizar e testar a API em http://127.0.0.1:8080/.</p> <p>Abaixo est\u00e1 um exemplo de envio de uma solicita\u00e7\u00e3o usando <code>tools/post_api.py</code>.</p> <pre><code>python -m tools.post_api \\\n    --text \"Texto a ser inserido\" \\\n    --reference_audio \"Caminho para o \u00e1udio de refer\u00eancia\" \\\n    --reference_text \"Conte\u00fado de texto do \u00e1udio de refer\u00eancia\" \\\n    --streaming True\n</code></pre> <p>O comando acima indica a s\u00edntese do \u00e1udio desejada de acordo com as informa\u00e7\u00f5es do \u00e1udio de refer\u00eancia e a retorna em modo de streaming.</p> <p>Info</p> <p>Para aprender mais sobre par\u00e2metros dispon\u00edveis, voc\u00ea pode usar o comando <code>python -m tools.post_api -h</code></p>"},{"location":"pt/inference/#inferencia-por-webui","title":"Infer\u00eancia por WebUI","text":"<p>Para iniciar a WebUI de Infer\u00eancia execute o seguinte comando:</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>Para acelerar a infer\u00eancia, adicione o par\u00e2metro <code>--compile</code>.</p> <p>Note</p> <p>Voc\u00ea pode salvar antecipadamente o arquivo de r\u00f3tulos e o arquivo de \u00e1udio de refer\u00eancia na pasta <code>references</code> do diret\u00f3rio principal (que voc\u00ea precisa criar), para que possa cham\u00e1-los diretamente na WebUI.</p> <p>Note</p> <p>\u00c9 poss\u00edvel usar vari\u00e1veis de ambiente do Gradio, como <code>GRADIO_SHARE</code>, <code>GRADIO_SERVER_PORT</code>, <code>GRADIO_SERVER_NAME</code>, para configurar a WebUI.</p> <p>Divirta-se!</p>"},{"location":"pt/samples/","title":"Amostras","text":"<p>A demonstra\u00e7\u00e3o da vers\u00e3o 1.4 foi atualizada aqui</p> <p>As amostras da v1.2 est\u00e3o dispon\u00edveis em Bilibili.</p> <p>As seguintes amostras s\u00e3o do modelo v1.1.</p>"},{"location":"pt/samples/#frase-em-chines-1","title":"Frase em Chin\u00eas 1","text":"<pre><code>\u4eba\u95f4\u706f\u706b\u5012\u6620\u6e56\u4e2d\uff0c\u5979\u7684\u6e34\u671b\u8ba9\u9759\u6c34\u6cdb\u8d77\u6d9f\u6f2a\u3002\u82e5\u4ee3\u4ef7\u53ea\u662f\u5b64\u72ec\uff0c\u90a3\u5c31\u8ba9\u8fd9\u4efd\u613f\u671b\u8086\u610f\u6d41\u6dcc\u3002\n\u6d41\u5165\u5979\u6240\u6ce8\u89c6\u7684\u4e16\u95f4\uff0c\u4e5f\u6d41\u5165\u5979\u5982\u6e56\u6c34\u822c\u6f84\u6f88\u7684\u76ee\u5149\u3002\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Nahida (Genshin Impact) Zhongli (Genshin Impact) Furina (Genshin Impact) Orador Aleat\u00f3rio 1  -  Orador Aleat\u00f3rio 2  -"},{"location":"pt/samples/#frase-em-chines-2","title":"Frase em Chin\u00eas 2","text":"<pre><code>\u4f60\u4eec\u8fd9\u4e2a\u662f\u4ec0\u4e48\u7fa4\u554a\uff0c\u4f60\u4eec\u8fd9\u662f\u5bb3\u4eba\u4e0d\u6d45\u554a\u4f60\u4eec\u8fd9\u4e2a\u7fa4\uff01\u8c01\u662f\u7fa4\u4e3b\uff0c\u51fa\u6765\uff01\u771f\u7684\u592a\u8fc7\u5206\u4e86\u3002\u4f60\u4eec\u641e\u8fd9\u4e2a\u7fa4\u5e72\u4ec0\u4e48\uff1f\n\u6211\u513f\u5b50\u6bcf\u4e00\u79d1\u7684\u6210\u7ee9\u90fd\u4e0d\u8fc7\u90a3\u4e2a\u5e73\u5747\u5206\u5450\uff0c\u4ed6\u73b0\u5728\u521d\u4e8c\uff0c\u4f60\u53eb\u6211\u513f\u5b50\u600e\u4e48\u529e\u554a\uff1f\u4ed6\u73b0\u5728\u8fd8\u4e0d\u5230\u9ad8\u4e2d\u554a\uff1f\n\u4f60\u4eec\u5bb3\u6b7b\u6211\u513f\u5b50\u4e86\uff01\u5feb\u70b9\u51fa\u6765\u4f60\u8fd9\u4e2a\u7fa4\u4e3b\uff01\u518d\u8fd9\u6837\u6211\u53bb\u62a5\u8b66\u4e86\u554a\uff01\u6211\u8ddf\u4f60\u4eec\u8bf4\u4f60\u4eec\u8fd9\u4e00\u5e2e\u4eba\u554a\uff0c\u4e00\u5929\u5230\u665a\u554a\uff0c\n\u641e\u8fd9\u4e9b\u4ec0\u4e48\u6e38\u620f\u554a\uff0c\u52a8\u6f2b\u554a\uff0c\u4f1a\u5bb3\u6b7b\u4f60\u4eec\u7684\uff0c\u4f60\u4eec\u6ca1\u6709\u524d\u9014\u6211\u8ddf\u4f60\u8bf4\u3002\u4f60\u4eec\u8fd9\u4e5d\u767e\u591a\u4e2a\u4eba\uff0c\u597d\u597d\u5b66\u4e60\u4e0d\u597d\u5417\uff1f\n\u4e00\u5929\u5230\u665a\u5728\u4e0a\u7f51\u3002\u6709\u4ec0\u4e48\u610f\u601d\u554a\uff1f\u9ebb\u70e6\u4f60\u91cd\u89c6\u4e00\u4e0b\u4f60\u4eec\u7684\u751f\u6d3b\u7684\u76ee\u6807\u554a\uff1f\u6709\u4e00\u70b9\u5b66\u4e60\u76ee\u6807\u884c\u4e0d\u884c\uff1f\u4e00\u5929\u5230\u665a\u4e0a\u7f51\u662f\u4e0d\u662f\u4eba\u554a\uff1f\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Nahida (Genshin Impact) Orador Aleat\u00f3rio  -"},{"location":"pt/samples/#frase-em-chines-3","title":"Frase em Chin\u00eas 3","text":"<pre><code>\u5927\u5bb6\u597d\uff0c\u6211\u662f Fish Audio \u5f00\u53d1\u7684\u5f00\u6e90\u6587\u672c\u8f6c\u8bed\u97f3\u6a21\u578b\u3002\u7ecf\u8fc7\u5341\u4e94\u4e07\u5c0f\u65f6\u7684\u6570\u636e\u8bad\u7ec3\uff0c\n\u6211\u5df2\u7ecf\u80fd\u591f\u719f\u7ec3\u638c\u63e1\u4e2d\u6587\u3001\u65e5\u8bed\u548c\u82f1\u8bed\uff0c\u6211\u7684\u8bed\u8a00\u5904\u7406\u80fd\u529b\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u58f0\u97f3\u8868\u73b0\u5f62\u5f0f\u4e30\u5bcc\u591a\u53d8\u3002\n\u4f5c\u4e3a\u4e00\u4e2a\u4ec5\u6709\u4ebf\u7ea7\u53c2\u6570\u7684\u6a21\u578b\uff0c\u6211\u76f8\u4fe1\u793e\u533a\u6210\u5458\u80fd\u591f\u5728\u4e2a\u4eba\u8bbe\u5907\u4e0a\u8f7b\u677e\u8fd0\u884c\u548c\u5fae\u8c03\uff0c\u8ba9\u6211\u6210\u4e3a\u60a8\u7684\u79c1\u4eba\u8bed\u97f3\u52a9\u624b\u3002\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio  -"},{"location":"pt/samples/#frase-em-ingles-1","title":"Frase em Ingl\u00eas 1","text":"<pre><code>In the realm of advanced technology, the evolution of artificial intelligence stands as a \nmonumental achievement. This dynamic field, constantly pushing the boundaries of what \nmachines can do, has seen rapid growth and innovation. From deciphering complex data \npatterns to driving cars autonomously, AI's applications are vast and diverse.\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio 1  -  Orador Aleat\u00f3rio 2  -"},{"location":"pt/samples/#frase-em-ingles-2","title":"Frase em Ingl\u00eas 2","text":"<pre><code>Hello everyone, I am an open-source text-to-speech model developed by \nFish Audio. After training with 150,000 hours of data, I have become proficient \nin Chinese, Japanese, and English, and my language processing abilities \nare close to human level. My voice is capable of a wide range of expressions. \nAs a model with only hundreds of millions of parameters, I believe community \nmembers can easily run and fine-tune me on their personal devices, allowing \nme to serve as your personal voice assistant.\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio  -"},{"location":"pt/samples/#frase-em-japones-1","title":"Frase em Japon\u00eas 1","text":"<pre><code>\u5148\u9032\u6280\u8853\u306e\u9818\u57df\u306b\u304a\u3044\u3066\u3001\u4eba\u5de5\u77e5\u80fd\u306e\u9032\u5316\u306f\u753b\u671f\u7684\u306a\u6210\u679c\u3068\u3057\u3066\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\u5e38\u306b\u6a5f\u68b0\u304c\u3067\u304d\u308b\u3053\u3068\u306e\u9650\u754c\u3092\n\u62bc\u3057\u5e83\u3052\u3066\u3044\u308b\u3053\u306e\u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u5206\u91ce\u306f\u3001\u6025\u901f\u306a\u6210\u9577\u3068\u9769\u65b0\u3092\u898b\u305b\u3066\u3044\u307e\u3059\u3002\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30d1\u30bf\u30fc\u30f3\u306e\u89e3\u8aad\u304b\n\u3089\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u64cd\u7e26\u307e\u3067\u3001AI\u306e\u5fdc\u7528\u306f\u5e83\u7bc4\u56f2\u306b\u53ca\u3073\u307e\u3059\u3002\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio 1  -  Orador Aleat\u00f3rio 2  -"},{"location":"pt/samples/#frase-em-japones-2","title":"Frase em Japon\u00eas 2","text":"<pre><code>\u7686\u3055\u3093\u3001\u3053\u3093\u306b\u3061\u306f\u3002\u79c1\u306f\u30d5\u30a3\u30c3\u30b7\u30e5\u30aa\u30fc\u30c7\u30a3\u30aa\u306b\u3088\u3063\u3066\u958b\u767a\u3055\u308c\u305f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u30c6\n\u30ad\u30b9\u30c8\u304b\u3089\u97f3\u58f0\u3078\u306e\u5909\u63db\u30e2\u30c7\u30eb\u3067\u3059\u300215\u4e07\u6642\u9593\u306e\u30c7\u30fc\u30bf\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u7d4c\u3066\u3001\n\u4e2d\u56fd\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u82f1\u8a9e\u3092\u719f\u77e5\u3057\u3066\u304a\u308a\u3001\u8a00\u8a9e\u51e6\u7406\u80fd\u529b\u306f\u4eba\u9593\u306b\u8fd1\u3044\u30ec\u30d9\u30eb\u3067\u3059\u3002\n\u58f0\u306e\u8868\u73fe\u3082\u591a\u5f69\u3067\u8c4a\u304b\u3067\u3059\u3002\u6570\u5104\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u3053\u306e\u30e2\u30c7\u30eb\u306f\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\n\u306e\u30e1\u30f3\u30d0\u30fc\u304c\u500b\u4eba\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u7c21\u5358\u306b\u5b9f\u884c\u3057\u3001\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\n\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u79c1\u3092\u500b\u4eba\u306e\u97f3\u58f0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u6d3b\u7528\u3067\u304d\u307e\u3059\u3002\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio  -"},{"location":"ko/","title":"\uc18c\uac1c","text":"<p>Warning</p> <p>\uc774 \ucf54\ub4dc\ubca0\uc774\uc2a4\uc758 \ubd88\ubc95\uc801\uc778 \uc0ac\uc6a9\uc5d0 \ub300\ud574\uc11c\ub294 \ucc45\uc784\uc744 \uc9c0\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. DMCA(Digital Millennium Copyright Act) \ubc0f \ud574\ub2f9 \uc9c0\uc5ed\uc758 \uad00\ub828 \ubc95\ub960\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.  \uc774 \ucf54\ub4dc\ubca0\uc774\uc2a4\uc640 \ubaa8\ub4e0 \ubaa8\ub378\uc740 CC-BY-NC-SA-4.0 \ub77c\uc774\uc120\uc2a4\uc5d0 \ub530\ub77c \ubc30\ud3ec\ub429\ub2c8\ub2e4.</p> <p> </p>"},{"location":"ko/#_2","title":"\uc694\uad6c \uc0ac\ud56d","text":"<ul> <li>GPU \uba54\ubaa8\ub9ac: 4GB (\ucd94\ub860\uc6a9), 8GB (\ud30c\uc778\ud29c\ub2dd\uc6a9)</li> <li>\uc2dc\uc2a4\ud15c: Linux, Windows</li> </ul>"},{"location":"ko/#windows","title":"Windows \uc124\uc815","text":"<p>\uace0\uae09 Windows \uc0ac\uc6a9\uc790\ub294 WSL2 \ub610\ub294 Docker\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucf54\ub4dc\ubca0\uc774\uc2a4\ub97c \uc2e4\ud589\ud558\ub294 \uac83\uc744 \uace0\ub824\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <pre><code># \ud30c\uc774\uc36c 3.10 \uac00\uc0c1 \ud658\uacbd \uc0dd\uc131, virtualenv\ub3c4 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# pytorch \uc124\uce58\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n\n# fish-speech \uc124\uce58\npip3 install -e .\n\n# (\uac00\uc18d \ud65c\uc131\ud654) triton-windows \uc124\uce58\npip install https://github.com/AnyaCoder/fish-speech/releases/download/v0.1.0/triton_windows-0.1.0-py3-none-any.whl\n</code></pre> <p>\ube44\uc804\ubb38 Windows \uc0ac\uc6a9\uc790\ub294 Linux \ud658\uacbd \uc5c6\uc774 \ud504\ub85c\uc81d\ud2b8\ub97c \uc2e4\ud589\ud560 \uc218 \uc788\ub294 \ub2e4\uc74c \uae30\ubcf8 \ubc29\ubc95\uc744 \uace0\ub824\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 (\ubaa8\ub378 \ucef4\ud30c\uc77c \uae30\ub2a5 \ud3ec\ud568, \uc989 <code>torch.compile</code>):</p> <ol> <li>\ud504\ub85c\uc81d\ud2b8 \ud328\ud0a4\uc9c0 \ucd94\ucd9c.</li> <li><code>install_env.bat</code>\uc744 \ud074\ub9ad\ud558\uc5ec \ud658\uacbd \uc124\uce58.</li> <li>\ucef4\ud30c\uc77c \uac00\uc18d\uc744 \ud65c\uc131\ud654\ud558\ub824\uba74 \uc544\ub798 \ub2e8\uacc4\ub97c \ub530\ub974\uc138\uc694:<ol> <li>LLVM \ucef4\ud30c\uc77c\ub7ec \ub2e4\uc6b4\ub85c\ub4dc:<ul> <li>LLVM-17.0.6 (\uacf5\uc2dd \uc0ac\uc774\ud2b8)</li> <li>LLVM-17.0.6 (\ubbf8\ub7ec \uc0ac\uc774\ud2b8)</li> <li><code>LLVM-17.0.6-win64.exe</code>\ub97c \ub2e4\uc6b4\ub85c\ub4dc \ud6c4 \ub354\ube14\ud074\ub9ad\ud558\uc5ec \uc124\uce58\ud558\uace0, \uc124\uce58 \uacbd\ub85c \uc120\ud0dd \uc2dc <code>Add Path to Current User</code> \uc635\uc158\uc744 \uccb4\ud06c\ud558\uc5ec \ud658\uacbd \ubcc0\uc218\ub97c \ucd94\uac00\ud569\ub2c8\ub2e4.</li> <li>\uc124\uce58\uac00 \uc644\ub8cc\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.</li> </ul> </li> <li>Microsoft Visual C++ \uc7ac\ubc30\ud3ec \uac00\ub2a5 \ud328\ud0a4\uc9c0\ub97c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc5ec .dll \ub204\ub77d \ubb38\uc81c \ud574\uacb0:<ul> <li>MSVC++ 14.40.33810.0 \ub2e4\uc6b4\ub85c\ub4dc</li> </ul> </li> <li>Visual Studio Community Edition\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc5ec LLVM\uc758 \ud5e4\ub354 \ud30c\uc77c \uc758\uc874\uc131\uc744 \ud574\uacb0:<ul> <li>Visual Studio \ub2e4\uc6b4\ub85c\ub4dc</li> <li>Visual Studio Installer\ub97c \uc124\uce58\ud55c \ud6c4 Visual Studio Community 2022\ub97c \ub2e4\uc6b4\ub85c\ub4dc.</li> <li><code>Desktop development with C++</code> \uc635\uc158\uc744 \uc120\ud0dd\ud558\uc5ec \uc124\uce58.</li> </ul> </li> <li>CUDA Toolkit 12.x \ub2e4\uc6b4\ub85c\ub4dc \ubc0f \uc124\uce58.</li> </ol> </li> <li><code>start.bat</code>\uc744 \ub354\ube14 \ud074\ub9ad\ud558\uc5ec \ud6c8\ub828 \ucd94\ub860 WebUI \uad00\ub9ac \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc5fd\ub2c8\ub2e4. \ud544\uc694\ud55c \uacbd\uc6b0 \uc544\ub798 \uc9c0\uce68\uc5d0 \ub530\ub77c <code>API_FLAGS</code>\ub97c \uc218\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</li> </ol> <p>Optional</p> <p>\ucd94\ub860\uc744 \uc704\ud574 WebUI\ub97c \uc0ac\uc6a9\ud558\uace0\uc790 \ud558\uc2dc\ub098\uc694?</p> <p>\ud504\ub85c\uc81d\ud2b8 \ub8e8\ud2b8 \ub514\ub809\ud1a0\ub9ac\uc758 <code>API_FLAGS.txt</code> \ud30c\uc77c\uc744 \ud3b8\uc9d1\ud558\uace0 \uccab \uc138 \uc904\uc744 \uc544\ub798\uc640 \uac19\uc774 \uc218\uc815\ud558\uc138\uc694: <pre><code> --infer\n # --api\n # --listen ...\n ...\n</code></pre></p> <p>Optional</p> <p>API \uc11c\ubc84\ub97c \uc2dc\uc791\ud558\uace0 \uc2f6\uc73c\uc2e0\uac00\uc694?</p> <p>\ud504\ub85c\uc81d\ud2b8 \ub8e8\ud2b8 \ub514\ub809\ud1a0\ub9ac\uc758 <code>API_FLAGS.txt</code> \ud30c\uc77c\uc744 \ud3b8\uc9d1\ud558\uace0 \uccab \uc138 \uc904\uc744 \uc544\ub798\uc640 \uac19\uc774 \uc218\uc815\ud558\uc138\uc694:</p> <pre><code># --infer\n--api\n--listen ...\n...\n</code></pre> <p>Optional</p> <p><code>run_cmd.bat</code>\uc744 \ub354\ube14 \ud074\ub9ad\ud558\uc5ec \uc774 \ud504\ub85c\uc81d\ud2b8\uc758 conda/python \uba85\ub839\uc904 \ud658\uacbd\uc5d0 \uc9c4\uc785\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"ko/#linux","title":"Linux \uc124\uc815","text":"<p>pyproject.toml\uc5d0\uc11c \uc790\uc138\ud55c \ub0b4\uc6a9\uc744 \ud655\uc778\ud558\uc138\uc694. <pre><code># \ud30c\uc774\uc36c 3.10 \uac00\uc0c1 \ud658\uacbd \uc0dd\uc131, virtualenv\ub3c4 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# (Ubuntu / Debian \uc0ac\uc6a9\uc790) sox + ffmpeg \uc124\uce58\napt install libsox-dev ffmpeg \n\n# (Ubuntu / Debian \uc0ac\uc6a9\uc790) pyaudio \uc124\uce58\napt install build-essential \\\n    cmake \\\n    libasound-dev \\\n    portaudio19-dev \\\n    libportaudio2 \\\n    libportaudiocpp0\n\n# pytorch \uc124\uce58\npip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n\n# fish-speech \uc124\uce58\npip3 install -e .[stable]\n</code></pre></p>"},{"location":"ko/#macos","title":"macos \uc124\uc815","text":"<p>MPS\uc5d0\uc11c \ucd94\ub860\uc744 \uc218\ud589\ud558\ub824\uba74 <code>--device mps</code> \ud50c\ub798\uadf8\ub97c \ucd94\uac00\ud558\uc138\uc694. \ucd94\ub860 \uc18d\ub3c4 \ube44\uad50\ub294 \uc774 PR\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.</p> <p>Warning</p> <p>Apple Silicon \uc7a5\uce58\uc5d0\uc11c\ub294 <code>compile</code> \uc635\uc158\uc774 \uacf5\uc2dd\uc801\uc73c\ub85c \uc9c0\uc6d0\ub418\uc9c0 \uc54a\uc73c\ubbc0\ub85c \ucd94\ub860 \uc18d\ub3c4\uac00 \ud5a5\uc0c1\ub41c\ub2e4\ub294 \ubcf4\uc7a5\uc740 \uc5c6\uc2b5\ub2c8\ub2e4.</p> <pre><code># \ud30c\uc774\uc36c 3.10 \uac00\uc0c1 \ud658\uacbd \uc0dd\uc131, virtualenv\ub3c4 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n# pytorch \uc124\uce58\npip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n# fish-speech \uc124\uce58\npip install -e .[stable]\n</code></pre>"},{"location":"ko/#docker","title":"Docker \uc124\uc815","text":"<ol> <li> <p>NVIDIA Container Toolkit \uc124\uce58:</p> <p>Docker\uc5d0\uc11c \ubaa8\ub378 \ud6c8\ub828 \ubc0f \ucd94\ub860\uc5d0 GPU\ub97c \uc0ac\uc6a9\ud558\ub824\uba74 NVIDIA Container Toolkit\uc744 \uc124\uce58\ud574\uc57c \ud569\ub2c8\ub2e4:</p> <p>Ubuntu \uc0ac\uc6a9\uc790:</p> <pre><code># \uc800\uc7a5\uc18c \ucd94\uac00\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n# nvidia-container-toolkit \uc124\uce58\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n# Docker \uc11c\ube44\uc2a4 \uc7ac\uc2dc\uc791\nsudo systemctl restart docker\n</code></pre> <p>\ub2e4\ub978 Linux \ubc30\ud3ec\ud310 \uc0ac\uc6a9\uc790\ub294: NVIDIA Container Toolkit \uc124\uce58 \uac00\uc774\ub4dc\ub97c \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.</p> </li> <li> <p>fish-speech \uc774\ubbf8\uc9c0 \uac00\uc838\uc624\uae30 \ubc0f \uc2e4\ud589</p> <pre><code># \uc774\ubbf8\uc9c0 \uac00\uc838\uc624\uae30\ndocker pull fishaudio/fish-speech:latest-dev\n# \uc774\ubbf8\uc9c0 \uc2e4\ud589\ndocker run -it \\\n    --name fish-speech \\\n    --gpus all \\\n    -p 7860:7860 \\\n    fishaudio/fish-speech:latest-dev \\\n    zsh\n# \ub2e4\ub978 \ud3ec\ud2b8\ub97c \uc0ac\uc6a9\ud558\ub824\uba74 -p \ub9e4\uac1c\ubcc0\uc218\ub97c YourPort:7860\uc73c\ub85c \uc218\uc815\ud558\uc138\uc694\n</code></pre> </li> <li> <p>\ubaa8\ub378 \uc885\uc18d\uc131 \ub2e4\uc6b4\ub85c\ub4dc</p> <p>Docker \ucee8\ud14c\uc774\ub108 \ub0b4\ubd80\uc758 \ud130\ubbf8\ub110\uc5d0\uc11c \uc544\ub798 \uba85\ub839\uc5b4\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud544\uc694\ud55c <code>vqgan</code> \ubc0f <code>llama</code> \ubaa8\ub378\uc744 Huggingface \ub9ac\ud3ec\uc9c0\ud1a0\ub9ac\uc5d0\uc11c \ub2e4\uc6b4\ub85c\ub4dc\ud569\ub2c8\ub2e4.</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> </li> <li> <p>\ud658\uacbd \ubcc0\uc218 \uc124\uc815 \ubc0f WebUI \uc811\uadfc</p> <p>Docker \ucee8\ud14c\uc774\ub108 \ub0b4\ubd80\uc758 \ud130\ubbf8\ub110\uc5d0\uc11c <code>export GRADIO_SERVER_NAME=\"0.0.0.0\"</code>\ub97c \uc785\ub825\ud558\uc5ec Docker \ub0b4\ubd80\uc5d0\uc11c Gradio \uc11c\ube44\uc2a4\uc5d0 \uc678\ubd80 \uc811\uadfc\uc744 \ud5c8\uc6a9\ud569\ub2c8\ub2e4. \uc774\ud6c4, \ud130\ubbf8\ub110\uc5d0\uc11c <code>python tools/webui.py</code> \uba85\ub839\uc5b4\ub97c \uc785\ub825\ud558\uc5ec WebUI \uc11c\ube44\uc2a4\ub97c \uc2dc\uc791\ud569\ub2c8\ub2e4.</p> <p>WSL \ub610\ub294 macOS\ub97c \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0 http://localhost:7860\uc5d0\uc11c WebUI \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc5f4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc11c\ubc84\uc5d0 \ubc30\ud3ec\ub41c \uacbd\uc6b0, localhost\ub97c \uc11c\ubc84\uc758 IP\ub85c \uad50\uccb4\ud558\uc138\uc694.</p> </li> </ol>"},{"location":"ko/#_3","title":"\ubcc0\uacbd \uc0ac\ud56d","text":"<ul> <li>2024/09/10: Fish-Speech 1.4 \ubc84\uc804\uc73c\ub85c \uc5c5\ub370\uc774\ud2b8, \ub370\uc774\ud130\uc14b \ud06c\uae30 \uc99d\uac00 \ubc0f \uc591\uc790\ud654\uae30\uc758 n_groups\ub97c 4\uc5d0\uc11c 8\ub85c \ubcc0\uacbd.</li> <li>2024/07/02: Fish-Speech 1.2 \ubc84\uc804\uc73c\ub85c \uc5c5\ub370\uc774\ud2b8, VITS \ub514\ucf54\ub354 \uc81c\uac70 \ubc0f \uc81c\ub85c\uc0f7 \ub2a5\ub825 \ud06c\uac8c \ud5a5\uc0c1.</li> <li>2024/05/10: Fish-Speech 1.1 \ubc84\uc804\uc73c\ub85c \uc5c5\ub370\uc774\ud2b8, WER \uac10\uc18c \ubc0f \uc74c\uc0c9 \uc720\uc0ac\uc131\uc744 \uac1c\uc120\ud558\uae30 \uc704\ud574 VITS \ub514\ucf54\ub354 \uad6c\ud604.</li> <li>2024/04/22: Fish-Speech 1.0 \ubc84\uc804 \uc644\ub8cc, VQGAN \ubc0f LLAMA \ubaa8\ub378 \ub300\ud3ed \uc218\uc815.</li> <li>2023/12/28: <code>lora</code> \ud30c\uc778\ud29c\ub2dd \uc9c0\uc6d0 \ucd94\uac00.</li> <li>2023/12/27: <code>gradient checkpointing</code>, <code>causual sampling</code>, \ubc0f <code>flash-attn</code> \uc9c0\uc6d0 \ucd94\uac00.</li> <li>2023/12/19: WebUI \ubc0f HTTP API \uc5c5\ub370\uc774\ud2b8.</li> <li>2023/12/18: \ud30c\uc778\ud29c\ub2dd \ubb38\uc11c \ubc0f \uad00\ub828 \uc608\uc2dc \uc5c5\ub370\uc774\ud2b8.</li> <li>2023/12/17: <code>text2semantic</code> \ubaa8\ub378 \uc5c5\ub370\uc774\ud2b8, \uc74c\uc18c \uc5c6\ub294 \ubaa8\ub4dc \uc9c0\uc6d0.</li> <li>2023/12/13: \ubca0\ud0c0 \ubc84\uc804 \ucd9c\uc2dc, VQGAN \ubaa8\ub378 \ubc0f LLAMA \uae30\ubc18 \uc5b8\uc5b4 \ubaa8\ub378(\uc74c\uc18c \uc9c0\uc6d0\ub9cc \ud3ec\ud568).</li> </ul>"},{"location":"ko/#_4","title":"\uac10\uc0ac\uc758 \ub9d0","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"ko/finetune/","title":"\ud30c\uc778\ud29c\ub2dd","text":"<p>\uc774 \ud398\uc774\uc9c0\ub97c \uc5f4\uc5c8\ub2e4\ub294 \uac83\uc740, \uc0ac\uc804 \ud559\uc2b5\ub41c \ud4e8\uc0f7(Few-shot) \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ub9cc\uc871\ud558\uc9c0 \ubabb\ud588\ub2e4\ub294 \uc758\ubbf8\uc77c \uac83\uc785\ub2c8\ub2e4. \ub370\uc774\ud130\uc14b\uc758 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \ubaa8\ub378\uc744 \ud30c\uc778\ud29c\ub2dd\ud558\uace0 \uc2f6\uc73c\uc2dc\uaca0\uc8e0.</p> <p>\ud604\uc7ac \ubc84\uc804\uc5d0\uc11c\ub294 'LLAMA' \ubd80\ubd84\ub9cc \ud30c\uc778\ud29c\ub2dd\ud558\uc2dc\uba74 \ub429\ub2c8\ub2e4.</p>"},{"location":"ko/finetune/#llama","title":"LLAMA \ud30c\uc778\ud29c\ub2dd","text":""},{"location":"ko/finetune/#1","title":"1. \ub370\uc774\ud130\uc14b \uc900\ube44","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>\uc704\uc640 \uac19\uc740 \ud615\uc2dd\uc73c\ub85c \ub370\uc774\ud130\uc14b\uc744 \ubcc0\ud658\ud558\uc5ec <code>data</code> \ub514\ub809\ud1a0\ub9ac \uc548\uc5d0 \ubc30\uce58\ud558\uc138\uc694. \uc624\ub514\uc624 \ud30c\uc77c\uc758 \ud655\uc7a5\uc790\ub294 <code>.mp3</code>, <code>.wav</code>, <code>.flac</code> \uc911 \ud558\ub098\uc5ec\uc57c \ud558\uba70, \uc8fc\uc11d \ud30c\uc77c\uc740 <code>.lab</code> \ud655\uc7a5\uc790\ub97c \uc0ac\uc6a9\ud574\uc57c \ud569\ub2c8\ub2e4.</p> <p>\ub370\uc774\ud130\uc14b \ud615\uc2dd</p> <p><code>.lab</code> \uc8fc\uc11d \ud30c\uc77c\uc740 \uc624\ub514\uc624\uc758 \uc804\uc0ac \ub0b4\uc6a9\ub9cc \ud3ec\ud568\ud558\uba74 \ub418\uba70, \ud2b9\ubcc4\ud55c \ud615\uc2dd\uc774 \ud544\uc694\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, <code>hi.mp3</code>\uc5d0\uc11c \"Hello, goodbye\"\ub77c\ub294 \ub300\uc0ac\ub97c \ub9d0\ud55c\ub2e4\uba74, <code>hi.lab</code> \ud30c\uc77c\uc5d0\ub294 \"Hello, goodbye\"\ub77c\ub294 \ud55c \uc904\uc758 \ud14d\uc2a4\ud2b8\ub9cc \uc788\uc5b4\uc57c \ud569\ub2c8\ub2e4.</p> <p>Warning</p> <p>\ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc74c\ub7c9 \uc815\uaddc\ud654(loudness normalization)\ub97c \uc801\uc6a9\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4. \uc774\ub97c \uc704\ud574 fish-audio-preprocess\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <pre><code>fap loudness-norm data-raw data --clean\n</code></pre>"},{"location":"ko/finetune/#2","title":"2. \uc2dc\ub9e8\ud2f1 \ud1a0\ud070 \ubc30\uce58 \ucd94\ucd9c","text":"<p>VQGAN \uac00\uc911\uce58\ub97c \ub2e4\uc6b4\ub85c\ub4dc\ud588\ub294\uc9c0 \ud655\uc778\ud558\uc138\uc694. \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc9c0 \uc54a\uc558\ub2e4\uba74 \uc544\ub798 \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\ud558\uc138\uc694:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\uc774\ud6c4 \uc2dc\ub9e8\ud2f1 \ud1a0\ud070\uc744 \ucd94\ucd9c\ud558\uae30 \uc704\ud574 \uc544\ub798 \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\ud558\uc138\uc694:</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p>\ucd94\ucd9c \uc18d\ub3c4\ub97c \ub192\uc774\uae30 \uc704\ud574 <code>--num-workers</code>\uc640 <code>--batch-size</code> \uac12\uc744 \uc870\uc815\ud560 \uc218 \uc788\uc9c0\ub9cc, GPU \uba54\ubaa8\ub9ac \ud55c\ub3c4\ub97c \ucd08\uacfc\ud558\uc9c0 \uc54a\ub3c4\ub85d \uc8fc\uc758\ud558\uc138\uc694. VITS \ud615\uc2dd\uc758 \uacbd\uc6b0, <code>--filelist xxx.list</code>\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud30c\uc77c \ubaa9\ub85d\uc744 \uc9c0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc774 \uba85\ub839\uc744 \uc2e4\ud589\ud558\uba74 <code>data</code> \ub514\ub809\ud1a0\ub9ac \uc548\uc5d0 <code>.npy</code> \ud30c\uc77c\uc774 \uc0dd\uc131\ub429\ub2c8\ub2e4. \ub2e4\uc74c\uacfc \uac19\uc774 \ud45c\uc2dc\ub429\ub2c8\ub2e4:</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"ko/finetune/#3-protobuf","title":"3. \ub370\uc774\ud130\uc14b\uc744 protobuf\ub85c \ud328\ud0b9","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>\uba85\ub839\uc774 \uc644\ub8cc\ub418\uba74 <code>data</code> \ub514\ub809\ud1a0\ub9ac \uc548\uc5d0 <code>quantized-dataset-ft.protos</code> \ud30c\uc77c\uc774 \uc0dd\uc131\ub429\ub2c8\ub2e4.</p>"},{"location":"ko/finetune/#4-lora","title":"4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, LoRA\ub97c \uc774\uc6a9\ud55c \ud30c\uc778\ud29c\ub2dd","text":"<p>\ub9c8\ucc2c\uac00\uc9c0\ub85c, <code>LLAMA</code> \uac00\uc911\uce58\ub97c \ub2e4\uc6b4\ub85c\ub4dc\ud588\ub294\uc9c0 \ud655\uc778\ud558\uc138\uc694. \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc9c0 \uc54a\uc558\ub2e4\uba74 \uc544\ub798 \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\ud558\uc138\uc694:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uc544\ub798 \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\ud558\uc5ec \ud30c\uc778\ud29c\ub2dd\uc744 \uc2dc\uc791\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p><code>batch_size</code>, <code>gradient_accumulation_steps</code> \ub4f1\uc758 \ud559\uc2b5 \ub9e4\uac1c\ubcc0\uc218\ub97c GPU \uba54\ubaa8\ub9ac\uc5d0 \ub9de\uac8c \uc870\uc815\ud558\ub824\uba74 <code>fish_speech/configs/text2semantic_finetune.yaml</code> \ud30c\uc77c\uc744 \uc218\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>Note</p> <p>Windows \uc0ac\uc6a9\uc790\uc758 \uacbd\uc6b0, <code>nccl</code> \ubb38\uc81c\ub97c \ud53c\ud558\ub824\uba74 <code>trainer.strategy.process_group_backend=gloo</code>\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\ud6c8\ub828\uc774 \uc644\ub8cc\ub418\uba74 \ucd94\ub860 \uc139\uc158\uc744 \ucc38\uace0\ud558\uc5ec \uc74c\uc131\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>Info</p> <p>\uae30\ubcf8\uc801\uc73c\ub85c \ubaa8\ub378\uc740 \ud654\uc790\uc758 \ub9d0\ud558\ub294 \ud328\ud134\ub9cc \ud559\uc2b5\ud558\uace0 \uc74c\uc0c9\uc740 \ud559\uc2b5\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \uc74c\uc0c9\uc758 \uc548\uc815\uc131\uc744 \uc704\ud574 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud574\uc57c \ud569\ub2c8\ub2e4. \uc74c\uc0c9\uc744 \ud559\uc2b5\ud558\ub824\uba74 \ud6c8\ub828 \ub2e8\uacc4\ub97c \ub298\ub9b4 \uc218 \uc788\uc9c0\ub9cc, \uc774\ub294 \uacfc\uc801\ud569\uc758 \uc704\ud5d8\uc744 \ucd08\ub798\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\ud6c8\ub828\uc774 \ub05d\ub098\uba74 LoRA \uac00\uc911\uce58\ub97c \uc77c\ubc18 \uac00\uc911\uce58\ub85c \ubcc0\ud658\ud55c \ud6c4\uc5d0 \ucd94\ub860\uc744 \uc218\ud589\ud574\uc57c \ud569\ub2c8\ub2e4.</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>\ub2e4\ub978 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub3c4 \uc2dc\ub3c4\ud574 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc694\uad6c \uc0ac\ud56d\uc5d0 \ub9de\ub294 \uac00\uc7a5 \ucd08\uae30 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4. \uc774\ub4e4\uc740 \uc885\uc885 \ubd84\ud3ec \ubc16(OOD) \ub370\uc774\ud130\uc5d0\uc11c \ub354 \uc88b\uc740 \uc131\ub2a5\uc744 \ubc1c\ud718\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/inference/","title":"\ucd94\ub860","text":"<p>\ucd94\ub860\uc740 \uba85\ub839\uc904, HTTP API, \uadf8\ub9ac\uace0 \uc6f9 UI\uc5d0\uc11c \uc9c0\uc6d0\ub429\ub2c8\ub2e4.</p> <p>Note</p> <p>\uc804\uccb4 \ucd94\ub860 \uacfc\uc815\uc740 \ub2e4\uc74c\uc758 \uc5ec\ub7ec \ub2e8\uacc4\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4:</p> <ol> <li>VQGAN\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc57d 10\ucd08 \ubd84\ub7c9\uc758 \uc74c\uc131\uc744 \uc778\ucf54\ub529\ud569\ub2c8\ub2e4.</li> <li>\uc778\ucf54\ub529\ub41c \uc2dc\ub9e8\ud2f1 \ud1a0\ud070\uacfc \ud574\ub2f9 \ud14d\uc2a4\ud2b8\ub97c \uc608\uc2dc\ub85c \uc5b8\uc5b4 \ubaa8\ub378\uc5d0 \uc785\ub825\ud569\ub2c8\ub2e4.</li> <li>\uc0c8\ub85c\uc6b4 \ud14d\uc2a4\ud2b8\ub97c \uc785\ub825\ud558\uba74, \ubaa8\ub378\uc774 \ud574\ub2f9\ud558\ub294 \uc2dc\ub9e8\ud2f1 \ud1a0\ud070\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.</li> <li>\uc0dd\uc131\ub41c \uc2dc\ub9e8\ud2f1 \ud1a0\ud070\uc744 VITS / VQGAN\uc5d0 \uc785\ub825\ud558\uc5ec \uc74c\uc131\uc744 \ub514\ucf54\ub529\ud558\uace0 \uc0dd\uc131\ud569\ub2c8\ub2e4.</li> </ol>"},{"location":"ko/inference/#_2","title":"\uba85\ub839\uc904 \ucd94\ub860","text":"<p>\ud544\uc694\ud55c <code>vqgan</code> \ubc0f <code>llama</code> \ubaa8\ub378\uc744 Hugging Face \ub9ac\ud3ec\uc9c0\ud1a0\ub9ac\uc5d0\uc11c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc138\uc694.</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"ko/inference/#1","title":"1. \uc74c\uc131\uc5d0\uc11c \ud504\ub86c\ud504\ud2b8 \uc0dd\uc131:","text":"<p>Note</p> <p>\ubaa8\ub378\uc774 \uc74c\uc0c9\uc744 \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ud558\ub3c4\ub85d \ud558\ub824\uba74 \uc774 \ub2e8\uacc4\ub97c \uac74\ub108\ub6f8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>\uc774 \uba85\ub839\uc744 \uc2e4\ud589\ud558\uba74 <code>fake.npy</code> \ud30c\uc77c\uc744 \uc5bb\uac8c \ub429\ub2c8\ub2e4.</p>"},{"location":"ko/inference/#2","title":"2. \ud14d\uc2a4\ud2b8\uc5d0\uc11c \uc2dc\ub9e8\ud2f1 \ud1a0\ud070 \uc0dd\uc131:","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"\ubcc0\ud658\ud560 \ud14d\uc2a4\ud2b8\" \\\n    --prompt-text \"\ucc38\uace0\ud560 \ud14d\uc2a4\ud2b8\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>\uc774 \uba85\ub839\uc744 \uc2e4\ud589\ud558\uba74 \uc791\uc5c5 \ub514\ub809\ud1a0\ub9ac\uc5d0 <code>codes_N</code> \ud30c\uc77c\uc774 \uc0dd\uc131\ub418\uba70, N\uc740 0\ubd80\ud130 \uc2dc\uc791\ud558\ub294 \uc815\uc218\uc785\ub2c8\ub2e4.</p> <p>Note</p> <p>\ube60\ub978 \ucd94\ub860\uc744 \uc704\ud574 <code>--compile</code> \uc635\uc158\uc744 \uc0ac\uc6a9\ud558\uc5ec CUDA \ucee4\ub110\uc744 \uacb0\ud569\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 (~\ucd08\ub2f9 30 \ud1a0\ud070 -&gt; ~\ucd08\ub2f9 500 \ud1a0\ud070). <code>--compile</code> \ub9e4\uac1c\ubcc0\uc218\ub97c \uc8fc\uc11d \ucc98\ub9ac\ud558\uc5ec \uac00\uc18d\ud654 \uc635\uc158\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc744 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>Info</p> <p>bf16\uc744 \uc9c0\uc6d0\ud558\uc9c0 \uc54a\ub294 GPU\uc758 \uacbd\uc6b0 <code>--half</code> \ub9e4\uac1c\ubcc0\uc218\ub97c \uc0ac\uc6a9\ud574\uc57c \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"ko/inference/#3","title":"3. \uc2dc\ub9e8\ud2f1 \ud1a0\ud070\uc5d0\uc11c \uc74c\uc131 \uc0dd\uc131:","text":""},{"location":"ko/inference/#vqgan","title":"VQGAN \ub514\ucf54\ub354","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"ko/inference/#http-api","title":"HTTP API \ucd94\ub860","text":"<p>\ucd94\ub860\uc744 \uc704\ud55c HTTP API\ub97c \uc81c\uacf5\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc544\ub798\uc758 \uba85\ub839\uc5b4\ub85c \uc11c\ubc84\ub97c \uc2dc\uc791\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>\ucd94\ub860 \uc18d\ub3c4\ub97c \ub192\uc774\uace0 \uc2f6\ub2e4\uba74 <code>--compile</code> \ub9e4\uac1c\ubcc0\uc218\ub97c \ucd94\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc774\ud6c4, http://127.0.0.1:8080/ \uc5d0\uc11c API\ub97c \ud655\uc778\ud558\uace0 \ud14c\uc2a4\ud2b8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc544\ub798\ub294 <code>tools/post_api.py</code>\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc694\uccad\uc744 \ubcf4\ub0b4\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.</p> <pre><code>python -m tools.post_api \\\n    --text \"\uc785\ub825\ud560 \ud14d\uc2a4\ud2b8\" \\\n    --reference_audio \"\ucc38\uace0 \uc74c\uc131 \uacbd\ub85c\" \\\n    --reference_text \"\ucc38\uace0 \uc74c\uc131\uc758 \ud14d\uc2a4\ud2b8 \ub0b4\uc6a9\" \\\n    --streaming True\n</code></pre> <p>\uc704 \uba85\ub839\uc740 \ucc38\uace0 \uc74c\uc131 \uc815\ubcf4\ub97c \ubc14\ud0d5\uc73c\ub85c \uc6d0\ud558\ub294 \uc74c\uc131\uc744 \ud569\uc131\ud558\uace0, \uc2a4\ud2b8\ub9ac\ubc0d \ubc29\uc2dd\uc73c\ub85c \ubc18\ud658\ud569\ub2c8\ub2e4.</p> <p>\ub2e4\uc74c \uc608\uc2dc\ub294 \uc5ec\ub7ec \uac1c\uc758 \ucc38\uace0 \uc74c\uc131 \uacbd\ub85c\uc640 \ud14d\uc2a4\ud2b8\ub97c \ud55c\uaebc\ubc88\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uba85\ub839\uc5d0\uc11c \uacf5\ubc31\uc73c\ub85c \uad6c\ubd84\ud558\uc5ec \uc785\ub825\ud569\ub2c8\ub2e4.</p> <pre><code>python -m tools.post_api \\\n    --text \"\uc785\ub825\ud560 \ud14d\uc2a4\ud2b8\" \\\n    --reference_audio \"\ucc38\uace0 \uc74c\uc131 \uacbd\ub85c1\" \"\ucc38\uace0 \uc74c\uc131 \uacbd\ub85c2\" \\\n    --reference_text \"\ucc38\uace0 \uc74c\uc131 \ud14d\uc2a4\ud2b81\" \"\ucc38\uace0 \uc74c\uc131 \ud14d\uc2a4\ud2b82\"\\\n    --streaming False \\\n    --output \"generated\" \\\n    --format \"mp3\"\n</code></pre> <p>\uc704 \uba85\ub839\uc5b4\ub294 \uc5ec\ub7ec \ucc38\uace0 \uc74c\uc131 \uc815\ubcf4\ub97c \ubc14\ud0d5\uc73c\ub85c <code>MP3</code> \ud615\uc2dd\uc758 \uc74c\uc131\uc744 \ud569\uc131\ud558\uc5ec, \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 <code>generated.mp3</code>\ub85c \uc800\uc7a5\ud569\ub2c8\ub2e4.</p> <p><code>--reference_audio</code>\uc640 <code>--reference_text</code> \ub300\uc2e0\uc5d0 <code>--reference_id</code>(\ud558\ub098\ub9cc \uc0ac\uc6a9 \uac00\ub2a5)\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud504\ub85c\uc81d\ud2b8 \ub8e8\ud2b8 \ub514\ub809\ud1a0\ub9ac\uc5d0 <code>references/&lt;your reference_id&gt;</code> \ud3f4\ub354\ub97c \ub9cc\ub4e4\uc5b4 \ud574\ub2f9 \uc74c\uc131\uacfc \uc8fc\uc11d \ud14d\uc2a4\ud2b8\ub97c \ub123\uc5b4\uc57c \ud569\ub2c8\ub2e4. \ucc38\uace0 \uc74c\uc131\uc740 \ucd5c\ub300 90\ucd08\uae4c\uc9c0 \uc9c0\uc6d0\ub429\ub2c8\ub2e4.</p> <p>Info</p> <p>\uc81c\uacf5\ub418\ub294 \ud30c\ub77c\ubbf8\ud130\ub294 <code>python -m tools.post_api -h</code>\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"ko/inference/#gui","title":"GUI \ucd94\ub860","text":"<p>\ud074\ub77c\uc774\uc5b8\ud2b8 \ub2e4\uc6b4\ub85c\ub4dc</p>"},{"location":"ko/inference/#webui","title":"WebUI \ucd94\ub860","text":"<p>\ub2e4\uc74c \uba85\ub839\uc73c\ub85c WebUI\ub97c \uc2dc\uc791\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>\ucd94\ub860 \uc18d\ub3c4\ub97c \ub192\uc774\uace0 \uc2f6\ub2e4\uba74 <code>--compile</code> \ub9e4\uac1c\ubcc0\uc218\ub97c \ucd94\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>Note</p> <p>\ub77c\ubca8 \ud30c\uc77c\uacfc \ucc38\uace0 \uc74c\uc131 \ud30c\uc77c\uc744 \ubbf8\ub9ac \uba54\uc778 \ub514\ub809\ud1a0\ub9ac\uc758 <code>references</code> \ud3f4\ub354\uc5d0 \uc800\uc7a5\ud574 \ub450\uba74, WebUI\uc5d0\uc11c \ubc14\ub85c \ud638\ucd9c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (\ud574\ub2f9 \ud3f4\ub354\ub294 \uc9c1\uc811 \uc0dd\uc131\ud574\uc57c \ud569\ub2c8\ub2e4.)</p> <p>Note</p> <p>WebUI\ub97c \uad6c\uc131\ud558\uae30 \uc704\ud574 <code>GRADIO_SHARE</code>, <code>GRADIO_SERVER_PORT</code>, <code>GRADIO_SERVER_NAME</code>\uacfc \uac19\uc740 Gradio \ud658\uacbd \ubcc0\uc218\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\uc990\uae30\uc138\uc694!</p>"},{"location":"ko/samples/","title":"\uc0d8\ud50c","text":"<p>ver 1.4</p>"},{"location":"ko/samples/#credits","title":"Credits","text":"<p>Seed-TTS (2024)\uc5d0 \uac10\uc0ac\ub4dc\ub9ac\uba70, \ud3c9\uac00 \ub370\uc774\ud130\ub97c \uc81c\uacf5\ud574 \uc8fc\uc154\uc11c \uc774 \ub370\ubaa8\ub97c \uc644\uc131\ud560 \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.</p> <p>\ubaa8\ub4e0 \ud504\ub86c\ud504\ud2b8 \uc74c\uc131\uc740 Seed-TTS \ud6a8\uacfc \ub370\ubaa8 \ud398\uc774\uc9c0\uc5d0\uc11c \uac00\uc838\uc654\uc73c\uba70, \ubaa8\ub4e0 \uc0dd\uc131\ub41c \uc74c\uc131\uc740 fish-speech \ubc84\uc804 1.4\uc5d0\uc11c \uccab \ubc88\uc9f8\ub85c \uc0dd\uc131\ub41c \uac83\uc785\ub2c8\ub2e4.</p>"},{"location":"ko/samples/#_2","title":"\uc81c\ub85c\uc0f7 \uc778\ucee8\ud14d\uc2a4\ud2b8 \ud559\uc2b5","text":"<ul> <li>TODO: \ud55c\uad6d\uc5b4 \uc81c\ub85c\uc0f7 \uc778\ucee8\ud14d\uc2a4\ud2b8 \ud559\uc2b5 \uc0d8\ud50c \ucd94\uac00. (\ud604\uc7ac\ub294 \uc601\uc5b4\uc640 \uc911\uad6d\uc5b4 \ub370\ubaa8\ub9cc \uc81c\uacf5\ub429\ub2c8\ub2e4.)</li> </ul> \uc5b8\uc5b4 \ud504\ub86c\ud504\ud2b8 \ub3d9\uc77c \uc5b8\uc5b4 \uc0dd\uc131 \uad50\ucc28 \uc5b8\uc5b4 \uc0dd\uc131 EN Your browser does not support the audio element. Your browser does not support the audio element.I don't really care what you call me. I've been a silent spectator, watching species evolve, empires rise and fall. But always remember, I am mighty and enduring. Respect me and I'll nurture you; ignore me and you shall face the consequences. Your browser does not support the audio element.\u987f\u65f6\uff0c\u6c14\u6c1b\u53d8\u5f97\u6c89\u90c1\u8d77\u6765\u3002\u4e4d\u770b\u4e4b\u4e0b\uff0c\u4e00\u5207\u7684\u56f0\u6270\u4eff\u4f5b\u90fd\u56f4\u7ed5\u5728\u6211\u8eab\u8fb9\u3002\u6211\u76b1\u7740\u7709\u5934\uff0c\u611f\u53d7\u7740\u90a3\u4efd\u538b\u529b\uff0c\u4f46\u6211\u77e5\u9053\u6211\u4e0d\u80fd\u653e\u5f03\uff0c\u4e0d\u80fd\u8ba4\u8f93\u3002\u4e8e\u662f\uff0c\u6211\u6df1\u5438\u4e00\u53e3\u6c14\uff0c\u5fc3\u5e95\u7684\u58f0\u97f3\u544a\u8bc9\u6211\uff1a\u201c\u65e0\u8bba\u5982\u4f55\uff0c\u90fd\u8981\u51b7\u9759\u4e0b\u6765\uff0c\u91cd\u65b0\u5f00\u59cb\u3002\u201d Your browser does not support the audio element. Your browser does not support the audio element.Dealing with family secrets is never easy. Yet, sometimes, omission is a form of protection, intending to safeguard some from the harsh truths. One day, I hope you understand the reasons behind my actions. Until then, Anna, please, bear with me. Your browser does not support the audio element.\u5904\u7406\u5bb6\u5ead\u79d8\u5bc6\u4ece\u6765\u90fd\u4e0d\u662f\u4e00\u4ef6\u5bb9\u6613\u7684\u4e8b\u3002\u7136\u800c\uff0c\u6709\u65f6\u5019\uff0c\u9690\u7792\u662f\u4e00\u79cd\u4fdd\u62a4\u5f62\u5f0f\uff0c\u65e8\u5728\u4fdd\u62a4\u4e00\u4e9b\u4eba\u514d\u53d7\u6b8b\u9177\u7684\u771f\u76f8\u4f24\u5bb3\u3002\u6709\u4e00\u5929\uff0c\u6211\u5e0c\u671b\u4f60\u80fd\u7406\u89e3\u6211\u884c\u4e3a\u80cc\u540e\u7684\u539f\u56e0\u3002\u5728\u90a3\u4e4b\u524d\uff0c\u5b89\u5a1c\uff0c\u8bf7\u5bb9\u5fcd\u6211\u3002 Your browser does not support the audio element. Your browser does not support the audio element.The combinations of different textures and flavors create a perfect harmony. The succulence of the steak, the tartness of the cranberries, the crunch of pine nuts, and creaminess of blue cheese make it a truly delectable delight. Enjoy your culinary adventure! Your browser does not support the audio element.\u542c\u7740\u4f60\u7684\u8bdd\uff0c\u6211\u5fc3\u91cc\u4e94\u5473\u6742\u9648\u3002\u867d\u7136\u6211\u613f\u610f\u4e00\u76f4\u5728\u4f60\u8eab\u8fb9\uff0c\u627f\u62c5\u4e00\u5207\u4e0d\u5e78\uff0c\u4f46\u6211\u77e5\u9053\u53ea\u6709\u8ba9\u4f60\u81ea\u5df1\u9762\u5bf9\uff0c\u624d\u80fd\u771f\u6b63\u8ba9\u4f60\u53d8\u5f97\u66f4\u5f3a\u5927\u3002\u6240\u4ee5\uff0c\u4f60\u8981\u8bb0\u5f97\uff0c\u65e0\u8bba\u9762\u5bf9\u4f55\u79cd\u56f0\u96be\uff0c\u90fd\u8bf7\u4f60\u575a\u5f3a\uff0c\u6211\u4f1a\u5728\u5fc3\u91cc\u4e00\u76f4\u652f\u6301\u4f60\u7684\u3002 ZH Your browser does not support the audio element. Your browser does not support the audio element.\u7a81\u7136\uff0c\u8eab\u8fb9\u4e00\u9635\u7b11\u58f0\u3002\u6211\u770b\u7740\u4ed6\u4eec\uff0c\u610f\u6c14\u98ce\u53d1\u5730\u633a\u76f4\u4e86\u80f8\u819b\uff0c\u7529\u4e86\u7529\u90a3\u7a0d\u663e\u8089\u611f\u7684\u53cc\u81c2\uff0c\u8f7b\u7b11\u9053\uff1a\"\u6211\u8eab\u4e0a\u7684\u8089\uff0c\u662f\u4e3a\u4e86\u63a9\u9970\u6211\u7206\u68da\u7684\u9b45\u529b\uff0c\u5426\u5219\uff0c\u5c82\u4e0d\u5413\u574f\u4e86\u4f60\u4eec\u5462\uff1f\" Your browser does not support the audio element.Suddenly, there was a burst of laughter beside me. I looked at them, stood up straight with high spirit, shook the slightly fleshy arms, and smiled lightly, saying, \"The flesh on my body is to hide my bursting charm. Otherwise, wouldn't it scare you?\" Your browser does not support the audio element. Your browser does not support the audio element.\u4ed6\u95ed\u4e0a\u773c\u775b\uff0c\u671f\u671b\u8fd9\u4e00\u5207\u90fd\u80fd\u8fc7\u53bb\u3002\u7136\u800c\uff0c\u5f53\u4ed6\u518d\u6b21\u7741\u5f00\u773c\u775b\uff0c\u773c\u524d\u7684\u666f\u8c61\u8ba9\u4ed6\u4e0d\u7981\u5012\u5438\u4e00\u53e3\u6c14\u3002\u96fe\u6c14\u4e2d\u51fa\u73b0\u7684\u7981\u95ed\u5c9b\uff0c\u964c\u751f\u53c8\u719f\u6089\uff0c\u5145\u6ee1\u672a\u77e5\u7684\u5371\u9669\u3002\u4ed6\u63e1\u7d27\u62f3\u5934\uff0c\u5fc3\u77e5\u4ed6\u7684\u751f\u6d3b\u5373\u5c06\u53d1\u751f\u7ffb\u5929\u8986\u5730\u7684\u6539\u53d8\u3002 Your browser does not support the audio element.He closed his eyes, expecting that all of this could pass. However, when he opened his eyes again, the sight in front of him made him couldn't help but take a deep breath. The closed island that appeared in the fog, strange and familiar, was full of unknown dangers. He tightened his fist, knowing that his life was about to undergo earth-shaking changes. Your browser does not support the audio element. Your browser does not support the audio element.\u987f\u65f6\uff0c\u6c14\u6c1b\u53d8\u5f97\u6c89\u90c1\u8d77\u6765\u3002\u4e4d\u770b\u4e4b\u4e0b\uff0c\u4e00\u5207\u7684\u56f0\u6270\u4eff\u4f5b\u90fd\u56f4\u7ed5\u5728\u6211\u8eab\u8fb9\u3002\u6211\u76b1\u7740\u7709\u5934\uff0c\u611f\u53d7\u7740\u90a3\u4efd\u538b\u529b\uff0c\u4f46\u6211\u77e5\u9053\u6211\u4e0d\u80fd\u653e\u5f03\uff0c\u4e0d\u80fd\u8ba4\u8f93\u3002\u4e8e\u662f\uff0c\u6211\u6df1\u5438\u4e00\u53e3\u6c14\uff0c\u5fc3\u5e95\u7684\u58f0\u97f3\u544a\u8bc9\u6211\uff1a\u201c\u65e0\u8bba\u5982\u4f55\uff0c\u90fd\u8981\u51b7\u9759\u4e0b\u6765\uff0c\u91cd\u65b0\u5f00\u59cb\u3002\u201d Your browser does not support the audio element.Suddenly, the atmosphere became gloomy. At first glance, all the troubles seemed to surround me. I frowned, feeling that pressure, but I know I can't give up, can't admit defeat. So, I took a deep breath, and the voice in my heart told me, \"Anyway, must calm down and start again.\""},{"location":"ko/samples/#_3","title":"\ud654\uc790 \ud30c\uc778\ud29c\ub2dd","text":"\ud14d\uc2a4\ud2b8 \uc0dd\uc131\ub41c \uc74c\uc131 \ud654\uc7901 \u597d\u5440\uff0c\u54c8\u54c8\u54c8\u54c8\u54c8\uff0c\u559c\u6b22\u7b11\u7684\u4eba\u8fd0\u6c14\u90fd\u4e0d\u4f1a\u5dee\u54e6\uff0c\u5e0c\u671b\u4f60\u6bcf\u5929\u7b11\u53e3\u5e38\u5f00~ Your browser does not support the audio element. \u54c7\uff01\u606d\u559c\u4f60\u4e2d\u4e86\u5927\u4e50\u900f\uff0c\u516b\u767e\u4e07\u53ef\u771f\u4e0d\u5c11\u5462\uff01\u6709\u4ec0\u4e48\u7279\u522b\u7684\u8ba1\u5212\u6216\u60f3\u6cd5\u5417\uff1f Your browser does not support the audio element. \u54fc\uff0c\u4f60\u8fd9\u4e48\u95ee\u662f\u60f3\u8bf7\u672c\u5c0f\u59d0\u5403\u996d\u5417\uff1f\u5982\u679c\u5bf9\u8c61\u662f\u4f60\u7684\u8bdd\uff0c\u90a3\u4e5f\u4e0d\u662f\u4e0d\u53ef\u4ee5\u3002 Your browser does not support the audio element. \ud654\uc7902 \u662f\u5440\uff0c\u4ed6\u8fd8\u60f3\u6362\u4e2a\u5730\u7403\u4eea\u54c8\u54c8\u54c8\uff0c\u770b\u6765\u7ed9\u4f60\u79ef\u7d2f\u4e86\u4e00\u4e9b\u5feb\u4e50\u503c\u4e86\uff0c\u4f60\u8fd8\u60f3\u4e0d\u60f3\u518d\u542c\u4e00\u4e2a\u5176\u4ed6\u7684\u7b11\u8bdd\u5440\uff1f Your browser does not support the audio element. \u563f\u563f\uff0c\u4f60\u662f\u4e0d\u662f\u4e5f\u60f3\u62e5\u6709\u751c\u751c\u7684\u604b\u7231\u5462\uff1f\u300a\u5fae\u5fae\u4e00\u7b11\u5f88\u503e\u57ce\u300b\u662f\u4f60\u7684\u4e0d\u4e8c\u9009\u62e9\uff0c\u7537\u5973\u4e3b\u662f\u6821\u82b1\u6821\u8349\u7c7b\u578b\uff0c\u4ed6\u4eec\u901a\u8fc7\u6e38\u620f\u7ed3\u8bc6\uff0c\u518d\u5230\u4e24\u4eba\u89c1\u9762\uff0c\u5168\u7a0b\u6ca1\u6709\u4e00\u70b9\u8bef\u4f1a\uff0c\u771f\u7684\u9f41\u751c\uff0c\u60f3\u60f3\u90fd\u5fcd\u4e0d\u4f4f\u201c\u59e8\u5988\u7b11\u201d~ Your browser does not support the audio element. \u5c0f\u50bb\u74dc\uff0c\u55ef\u2026\u2026\u7b97\u662f\u4e2a\u5f88\u53ef\u7231\u5f88\u4eb2\u5207\u7684\u540d\u5b57\uff0c\u6709\u70b9\u201c\u72ec\u7279\u201d\u54e6\uff0c\u4e0d\u8fc7\u6211\u6709\u4e9b\u597d\u5947\uff0c\u4f60\u4e3a\u4ec0\u4e48\u4f1a\u7ed9\u6211\u9009\u8fd9\u4e2a\u6635\u79f0\u5462\uff1f Your browser does not support the audio element."},{"location":"ko/samples/#_4","title":"\ucf58\ud150\uce20 \ud3b8\uc9d1","text":"\uc5b8\uc5b4 \uc6d0\ubcf8 \ud14d\uc2a4\ud2b8 \uc6d0\ubcf8 \uc74c\uc131 \ubaa9\ud45c \ud14d\uc2a4\ud2b8 \ud3b8\uc9d1\ub41c \uc74c\uc131 EN They can't order me to stop dreaming. If you dream a thing more than once, it's sure to come true. Have faith in your dreams, and someday your rainbow will come shining through. Your browser does not support the audio element. They can't require me to stop imagining. If you envision a thing more than once, it's bound to come about. Have trust in your visions, and someday your radiance will come beaming through. Your browser does not support the audio element. Are you familiar with it? Slice the steak and place the strips on top, then garnish with the dried cranberries, pine nuts, and blue cheese. I wonder how people rationalise the decision? Your browser does not support the audio element. Are you acquainted with it? Cut the pork and place the strips on top, then garnish with the dried cherries, almonds, and feta cheese. I query how people justify the choice? Your browser does not support the audio element. ZH \u81ea\u53e4\u4ee5\u6765\uff0c\u5eb8\u541b\u6700\u6015\u515a\u653f\u4e86\uff0c\u53ef\u5723\u541b\u4ed6\u5c31\u4e0d\u6015\uff0c\u4e0d\u4f46\u4e0d\u6015\uff0c\u53cd\u80fd\u5229\u7528\u3002\u8981\u6211\u8bf4\uff0c\u4f60\u5c31\u8ba9\u660e\u73e0\u7d22\u989d\u56fe\u4e92\u76f8\u4e89\u5ba0\uff0c\u53ea\u8981\u4f60\u5fc3\u91cc\u660e\u767d\uff0c\u5de6\u53f3\u9022\u6e90\uff0c\u4f60\u5c31\u80fd\u7acb\u4e8e\u4e0d\u8d25\u4e4b\u5730\u3002 Your browser does not support the audio element. \u4ece\u53e4\u81f3\u4eca\uff0c\u5eb8\u541b\u6700\u6015\u671d\u7eb2\u4e86\uff0c\u53ef\u660e\u541b\u4ed6\u5c31\u4e0d\u6015\uff0c\u4e0d\u4f46\u4e0d\u6015\uff0c\u53cd\u80fd\u501f\u52a9\u3002\u8981\u6211\u8bf4\uff0c\u4f60\u5c31\u8ba9\u674e\u56db\u5f20\u4e09\u4e92\u76f8\u4e89\u5ba0\uff0c\u53ea\u8981\u4f60\u5fc3\u91cc\u6e05\u695a\uff0c\u5de6\u53f3\u5468\u65cb\uff0c\u4f60\u5c31\u80fd\u5904\u4e8e\u4e0d\u8d25\u4e4b\u5883\u3002 Your browser does not support the audio element. \u5bf9\uff0c\u8fd9\u5c31\u662f\u6211\uff0c\u4e07\u4eba\u656c\u4ef0\u7684\u592a\u4e59\u771f\u4eba\uff0c\u867d\u7136\u6709\u70b9\u5a74\u513f\u80a5\uff0c\u4f46\u4e5f\u63a9\u4e0d\u4f4f\u6211\u903c\u4eba\u7684\u5e05\u6c14\u3002 Your browser does not support the audio element. \u5bf9\uff0c\u8fd9\u5c31\u662f\u6211\uff0c\u4f17\u4eba\u5c0a\u5d07\u7684\u592a\u767d\u91d1\u661f\uff0c\u867d\u7136\u6709\u70b9\u5a03\u5a03\u8138\uff0c\u4f46\u4e5f\u906e\u4e0d\u4f4f\u6211\u8ff7\u4eba\u7684\u9b45\u529b\u3002 Your browser does not support the audio element."}]}